<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Document</title>
  <link rel="stylesheet" href="css/main.css">
</head>

<body>
  <h2><strong>Для студентов с программой Data Science онлайн или в записи</strong></h2>
  <h2><strong>Python</strong></h2>

  <!-- 1 -->
  <details class="details">
    <summary class="details__title">Встроенные типы данных Python. Функция type(). Приведение типов.</summary>
    <div class="details__content">
      <p>Python имеет несколько встроенных типов данных, которые можно разделить на категории:</p>
      <ol>
        <li>
          <p><b>Числовые типы:</b><br><u>int:</u> Целые числа (например, 1, -5, 42)<br><u>float:</u> Числа с плавающей
            запятой (например, 3.14, -0.001, 2.0)<br><u>complex:</u> Комплексные числа (например, 1+2j, 3-4j)</p>
        </li>
        <li>
          <p>
            <b>Логический тип:</b><br><u>bool:</u> Логические значения (True, False)
          </p>
        </li>
        <li>
          <p>
            <b>Последовательности:</b><br><u>str:</u> Строки (например, "hello", "Python")<br><u>list:</u> Списки
            (например, [1, 2, 3], ["a", "b", "c"])<br><u>tuple:</u> Кортежи (например, (1, 2, 3), ("a", "b",
            "c"))<br><u>range:</u> Диапазоны (например, range(10), range(1, 5, 2))
          </p>
        </li>
        <li>
          <b>Коллекции:</b><br><u>set:</u> Множества (например, {1, 2, 3}, {"a", "b", "c"})<br><u>frozenset:</u>
          Неизменяемые множества (например, frozenset([1, 2, 3]))<br><u>dict:</u> Словари (например, {"key": "value",
          "name": "John"})
        </li>
        <li>
          <p>
            <b>Специальные типы:</b><br><u>NoneType:</u> Специальный тип, представляющий отсутствие значения или null
            (например, None)
          </p>
        </li>
      </ol>
      </p>

      <p><br><b>Функция type()</b> используется для определения типа объекта. Также type() может быть использована для создания новых типов (классов) динамически. Пример:</p>
      <code>
        &nbsp;&nbsp;&nbsp;&nbsp;MyClass = type('MyClass', (object,), {'attr': 42})<br>
        &nbsp;&nbsp;&nbsp;&nbsp;obj = MyClass()<br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(obj.attr)  # 42<br>
      </code>

      <p><br><b>Приведение типов (или преобразование типов)</b> — это процесс преобразования значения из одного типа данных в другой. Python предоставляет несколько встроенных функций для приведения типов
      <br>list(), tuple(), set(), dict(), str(), int(), float(), bool()</p>
    </div>
  </details>

  <!-- 2 -->
  <details class="details">
    <summary class="details__title">Условный оператор.</summary>
    <div class="details__content">
      <p>Условный оператор используется для выполнения блока кода в зависимости от выполнения условия. В Python основным условным оператором является if, который можно комбинировать с elif (сокращение от "else if") и else для создания сложных условных конструкций.</p>
      <p><b>Тернарный оператор</b> - Python также поддерживает условные выражения, которые позволяют записывать условные операторы в одну строку.</p>
    </div>
  </details>

  <!-- 3 -->
  <details class="details">
    <summary class="details__title">Арифметические и логические операции.</summary>
    <div class="details__content">
      <p><b>Арифметические операции</b> используются для выполнения математических вычислений. Python поддерживает следующие арифметические операции:</p>
      <ol>
        <li>Сложение (+)</li>
        <li>Вычитание (-)</li>
        <li>Умножение (*)</li>
        <li>Деление (/)</li>
        <li>Целочисленное деление (//)</li>
        <li>Остаток от деления (%)</li>
        <li>Возведение в степень (**)</li>
      </ol>
      <p><b>Логические операции</b> используются для выполнения логических вычислений. В Python есть следующие логические операторы:</p>
      <ol>
        <li>Логическое "и" (and) - Возвращает True, если оба выражения истинн</li>
        <li>Логическое "или" (or) - Возвращает True, если хотя бы одно из выражений истинно.</li>
        <li>Логическое "не" (not) - Возвращает True, если выражение ложно, и False, если выражение истинно.</li>
      </ol>
      <p><b>Сравнительные операторы</b> используются для сравнения значений. Они часто используются в логических выражениях и условных операторах.</p>
      <ol>
        <li>Равно (==)</li>
        <li>Не равно (!=)</li>
        <li>Меньше (<)</li>
        <li>Больше (>)</li>
        <li>Меньше или равно (<=)</li>
        <li>Больше или равно (>=)</li>
      </ol>
    </div>
  </details>

  <!-- 4 -->
  <details class="details">
    <summary class="details__title">Коллекции данных: типы tuple, list, dict,set.</summary>
    <div class="details__content">
      <p>Python предоставляет несколько встроенных типов коллекций, которые позволяют хранить и управлять группами данных. <br>К основным коллекциям данных относятся:<br></p>
      <ol>
        <li>
          <p><b>Кортежи (tuple)</b> - Кортежи представляют собой <b>неизменяемые</b> последовательности. Это означает, что после создания кортежа его элементы нельзя изменять, добавлять или удалять.</p>
          <ul><b>Основные операции</b>
            <li>Конкатенация: <code>new_tuple = my_tuple + another_tuple</code></li>
            <li>Повторение: <code>repeated_tuple = my_tuple * 3</code></li>
            <li>Проверка на наличие элемента: <code>is_in = 2 in my_tuple</code></li>
          </ul>
        </li>
        <li>
          <p><b>Списки (list)</b> - Списки представляют собой <b>изменяемые</b> последовательности. Это означает, что после создания списка его элементы можно изменять, добавлять или удалять.</p>
          <ul><b>Основные операции</b>
            <li>Добавление элемента: <code>my_list.append(4)</code></li>
            <li>Вставка элемента: <code>my_list.insert(1, 10)</code></li>
            <li>Удаление элемента по значению: <code>my_list.remove(2)</code></li>
            <li>Удаление элемента по индексу: <code>del my_list[0]</code> или <code>my_list.pop(0)</code></li>
            <li>Конкатенация: <code>new_list = my_list + another_list</code></li>
            <li>Повторение: repeated_list = <code>my_list * 3</code></li>
            <li>Проверка на наличие элемента: <code>is_in = 2 in my_list</code></li>
          </ul>
        </li>
        <li>
          <p><b>Словари (dict)</b> - Словари представляют собой коллекции пар ключ-значение. Ключи в словаре должны быть уникальными и неизменяемыми (например, строки, числа), а значения могут быть любыми.</p>
          <ul><b>Основные операции</b>
            <li>Добавление пары ключ-значение: <code>my_dict["gender"] = "male"</code></li>
            <li>Удаление пары ключ-значение: <code>del my_dict["age"]</code></li>
            <li>Проверка на наличие ключа: <code>is_in = "name" in my_dict</code></li>
            <li>Получение значения по ключу с значением по умолчанию: <code>value = my_dict.get("address", "unknown")</code></li>
          </ul>
        </li>
        <li>
          <p><b>Множества (set)</b> - Множества представляют собой неупорядоченные коллекции уникальных элементов. Они используются для выполнения математических операций над множествами, таких как объединение, пересечение и разность.</p>
          <ul><b>Основные операции</b>
            <li>Добавление элемента: <code>my_set.add(4)</code></li>
            <li>Удаление элемента: <code>my_set.remove(3)</code></li>
            <li>Объединение множеств: <code>union_set = my_set | another_set</code></li>
            <li>Пересечение множеств: <code>intersection_set = my_set & another_set</code></li>
            <li>Разность множеств: <code>difference_set = my_set - another_set</code></li>
            <li>Проверка на наличие элемента: <code>is_in = 2 in my_set</code></li>
          </ul>
        </li>
      </ol>
    </div>
  </details>

  <!-- 5 -->
  <details class="details">
    <summary class="details__title">Переменные Python. Правила именования переменных.</summary>
    <div class="details__content">
      <p>Переменные в Python используются для хранения данных, которые могут изменяться в течение выполнения программы.<br>
        <b>Переменная</b> — это именованная область памяти, которая содержит значение.<br>
        Для присваивания значения переменной используется оператор <b>`=`</b></p>
        <br>
        <ol><b>Правила именования переменных</b>
          <li>Имя переменной должно начинаться с буквы (a-z, A-Z) или символа подчеркивания (_)</li>
          <li>Остальные символы имени переменной могут быть буквами, цифрами или подчеркиваниями</li>
          <li>Имена переменных чувствительны к регистру. Это значит, что myVariable и myvariable будут разными переменными</li>
          <li>Нельзя использовать зарезервированные слова (ключевые слова) Python в качестве имен переменных. <br><b>Например</b>, такие слова как <u>False, True, None, and, or, if, else, for, while и другие нельзя использовать в качестве имен переменных</u></li>
        </ol>
        <br>
        <ol><b>Соглашения по стилю именования переменных</b>
          <li>Используйте <b>snake_case</b> для имен переменных:
            <ul>
              <li>Слова разделяются подчеркиваниями, все буквы в нижнем регистре.</li>
              <li>Пример: <b>user_age, total_sum, max_value.</b></li>
            </ul>
          </li>
          <li>Используйте <b>UPPER_CASE</b> для имен констант:
            <ul>
              <li>Пример: <b>PI, MAX_SIZE, MIN_VALUE.</b></li>
            </ul>
          </li>
          <li>Используйте <b>описательные имена</b> переменных:
            <ul>
              <li>Имена переменных должны отражать их смысл и предназначение.</li>
              <li>Пример: <b>user_age вместо ua, total_price вместо tp.</b></li>
            </ul>
          </li>
        </ol>
    </div>
  </details>

  <!-- 6 -->
  <details class="details">
    <summary class="details__title">Циклы for и while.</summary>
    <div class="details__content">
      <p>Циклы позволяют повторять блок кода несколько раз, что полезно для обработки коллекций данных, выполнения итераций и автоматизации задач.</p>
      <ol>
        <li>
          <b>Цикл for</b> - используется для итерации по элементам последовательности (например, списка, кортежа, строки, множества или словаря).<br>
          Основной синтаксис:<br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<b>for</b> элемент <b>in</b> последовательность:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;блок_кода
          </code>
        </li>
        <li>
          <b>Цикл while</b> - Цикл while выполняет блок кода до тех пор, пока условие истинно.<br>
          Основной синтаксис:<br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<b>while</b> условие:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;блок_кода
          </code>
        </li>
        <li><b>Операторы итераций циклов</b><br>
          <b>break</b> - Ключевое слово, которое прерывает выполнение текущего цикла. После использования break, остальные блоки кода текущего цикла не будут выполнены.<br>
          <b>continue</b> - Ключевое слово, которое прерывает текущую итерацию цикла
      </ol>
    </div>
  </details>

  <!-- 7 -->
  <details class="details">
    <summary class="details__title">Функции ввода/вывода данных Python (print(), input()).</summary>
    <div class="details__content">
      <p>
        <b>print(*args, sep=' ', end='\n', file=None, flush=False)</b> - Выводит значения в поток, или по умолчанию в sys.stdout.<br><br>
        <b>sep</b> - строка, вставляемая между значениями, по умолчанию пробел.<br>
        <b>end</b> - строка, добавляемая после последнего значения, по умолчанию - новая строка.<br>
        <b>file</b> - файлоподобный объект (поток); по умолчанию - текущий sys.stdout.<br>
        <b>flush</b> -очистка буфера
        </p>
        <br>
        <p>
          <b>input(prompt='')</b> - Чтение строки из стандартного ввода.  Заглавная новая строка удаляется. Строка запроса, если она задана, выводится на стандартный вывод без завершающей новой строки перед чтением ввода.
        </p>
    </div>
  </details>

  <!-- 8 -->
  <details class="details">
    <summary class="details__title">Пользовательские функции. Параметры функций.</summary>
    <div class="details__content">
      <p>Функции в Python позволяют структурировать код, улучшая его читаемость и повторное использование. Функции могут принимать параметры и возвращать значения.</p>
      <ol><b>Виды параметров</b>
        <li><b>Обязательные параметры:</b> Параметры, которые должны быть переданы функции.</li>
        <li><b>Необязательные параметры (с параметрами по умолчанию):</b> Параметры, которые могут быть пропущены. Если они пропущены, используется значение по умолчанию.</li>
        <li><b>Произвольное количество параметров:</b> Параметры, позволяющие передавать неопределенное количество аргументов.</li>
      </ol>
      <p><br><b>Область видимости переменных</b><br>Переменные, объявленные внутри функции, имеют локальную область видимости и недоступны за пределами функции. Переменные, объявленные вне функции, имеют глобальную область видимости.</b>
      <p><br><b>Вложенные функции</b> - Функции могут быть определены внутри других функций. Вложенные функции могут захватывать переменные из объемлющей области видимости.</p>
      <p><br><b>Анонимные функции (lambda)</b> - Python поддерживает создание анонимных функций с использованием ключевого слова lambda. Lambda-функции ограничены одним выражением и часто используются для создания небольших, одноразовых функций.</p>
      <p><br><b>Документация функций</b> - Для документирования функций в Python используется строка документации (docstring), которая помещается сразу после определения функции.</p>
    </div>
  </details>

  <!-- 9 -->
  <details class="details">
    <summary class="details__title">Библиотека Numpy. Индексация. Срезы.</summary>
    <div class="details__content">
      <p><b>NumPy (Numerical Python)</b> — это фундаментальная библиотека для научных вычислений в Python, которая предоставляет поддержку для массивов и матриц, а также высокоуровневые математические функции для работы с ними. <b>Все элементы в массиве NumPy должны быть однородными.</b></p>
      <p><b>Массив</b> — это центральная структура данных библиотеки NumPy. Массив представляет собой сетку значений и содержит информацию о необработанных данных, о том, как найти элемент и как его интерпретировать. Он имеет сетку элементов, которые можно индексировать различными способами . Все элементы одного типа, называемые массивом "dtype".</p>
      <br>
      <ol><b>Основные особенности NumPy</b>
        <li><b>Массивы (ndarray):</b> Основная структура данных в NumPy, которая позволяет работать с многомерными массивами.</li>
        <li><b>Высокопроизводительные операции:</b> NumPy оптимизирован для выполнения математических операций.</li>
        <li><b>Интеграция:</b> NumPy хорошо интегрируется с другими библиотеками, такими как SciPy, Matplotlib и pandas.</li>
      </ol>
      <br>
      <p>
        arr = np.array([1, 2, 3, 4, 5]) <span style="color: rgb(4, 93, 14); font-weight: bold;"># Создание массива из списка</span><br>
        zeros = np.zeros((2, 3))  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 2x3 массив нулей</span><br>
        ones = np.ones((2, 3))  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 2x3 массив единиц</span><br>
        eye = np.eye(3)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 3x3 единичная матрица</span><br>
        linspace = np.linspace(0, 1, 5)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 5 значений от 0 до 1 включительно</span><br>
        random_array = np.random.rand(2, 3)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 2x3 массив случайных значений</span><br>
      </p>
      <br>
      <p><b>Проверка типа данных: </b><span style="color: rgb(4, 93, 14); font-weight: bold;">print(arr.dtype)  # float32</span></p>
      <br>
      <table><tbody><tr><th data-colwidth="117" width="117"><p><strong>Тип данных</strong></p></th><th><p><strong>Описание</strong></p></th></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>bool</code></p></td><td><p align="left">Булевы значения (<code>True</code>&nbsp;или&nbsp;<code>False</code>) хранятся в виде байтов</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int</code></p></td><td><p align="left">Тип по умолчанию — целое число (то же, что&nbsp;<code>long</code>&nbsp;в C; обычно&nbsp;<code>int64</code>&nbsp;или&nbsp;<code>int32</code>)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>intc</code></p></td><td><p align="left">Идентичный&nbsp;<code>int</code>&nbsp;в C (обычно&nbsp;<code>int32</code>&nbsp;или&nbsp;<code>int64</code>)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>intp</code></p></td><td><p align="left">Целое число для использования в качестве индексов (то же, что и&nbsp;<code>size_t</code>&nbsp;в C, обычно&nbsp;<code>int32</code>&nbsp;или&nbsp;<code>int64</code>)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int8</code></p></td><td><p align="left">Байт (от — 128 до 127)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int16</code></p></td><td><p align="left">Целое число (от -32768 до 32767)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int32</code></p></td><td><p align="left">Целое число (от -2147483648 до 2147483647)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int64</code></p></td><td><p align="left">Целое число (от -9223372036854775808 до 9223372036854775807)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>uint8</code></p></td><td><p align="left">Целое число без знака (от 0 до 255)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>uint16</code></p></td><td><p align="left">Целое число без знака (от 0 до 65535)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>uint32</code></p></td><td><p align="left">Целое число без знака (от 0 до 4294967295)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>uint64</code></p></td><td><p align="left">Целое число без знака (от 0 до 18446744073709551615)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>float</code></p></td><td><p align="left">Обозначение&nbsp;<code>float64</code></p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>float16</code></p></td><td><p align="left">Число с плавающей точкой половинной точности; бит на знак, 5-битная экспонента, 10-битная мантисса</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>float32</code></p></td><td><p align="left">Число с плавающей точкой единичной точности; бит на знак, 8-битная экспонента, 23-битная мантисса</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>float64</code></p></td><td><p align="left">Число с плавающей точкой двойной точности; бит на знак, 11-битная экспонента, 52-битная мантисса</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>complex</code></p></td><td><p align="left">Обозначение complex128</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>complex64</code></p></td><td><p align="left">Комплексное число, представленное двумя 32-битными&nbsp;<code>float</code>&nbsp;(с действительной и мнимой частями)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>complex128</code></p></td><td><p align="left">Комплексное число, представленное двумя 64-битными&nbsp;<code>float</code>&nbsp;(с действительной и мнимой частями)</p></td></tr></tbody></table>      
      <br>
      <p>
        <b>Размерности массивов - </b>Массивы в NumPy могут иметь произвольное количество измерений. Размерности массива можно проверить с помощью атрибутов .ndim, .shape и .size.<br>
        &nbsp;&nbsp;&nbsp;&nbsp;arr = np.array([[1, 2, 3], [4, 5, 6]])<br>
        <br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(arr.ndim)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 2 (двумерный массив)</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(arr.shape)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># (2, 3) (2 строки, 3 столбца)</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(arr.size)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 6 (всего элементов)</span><br>
      </p>
      <br>
      <p>
        <b>Основные методы и операции</b><br>
        Арифметические операции - NumPy поддерживает векторизованные операции, которые выполняются над массивами элемент-wise <br>
        Универсальные функции (ufunc) - NumPy предоставляет множество универсальных функций, таких как np.sqrt, np.exp, np.sin и другие <br>
        <br><b>Методы для изменения формы массива</b> <br>
        &nbsp;&nbsp;&nbsp;&nbsp;arr = np.array([[1, 2, 3], [4, 5, 6]])<br>

        &nbsp;&nbsp;&nbsp;&nbsp;<span style="color: rgb(4, 93, 14); font-weight: bold;"># Транспонирование</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(arr.T)  # [[1 4]<br>
                      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#  [2 5]<br>
                      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#  [3 6]]<br>

        &nbsp;&nbsp;&nbsp;&nbsp;<span style="color: rgb(4, 93, 14); font-weight: bold;"># Изменение формы массива</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;reshaped = arr.reshape(3, 2)<br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(reshaped)  # [[1 2]<br>
                         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#  [3 4]<br>
                         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#  [5 6]]<br>
      </p>
      <br>
      <p>
        <b>Маскирование</b> - Маскирование позволяет извлекать или изменять элементы массива, соответствующие определенным условиям.<br><br>
        &nbsp;&nbsp;&nbsp;&nbsparr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])<br>
        &nbsp;&nbsp;&nbsp;&nbspmask = arr % 2 == 0  <span style="color: rgb(4, 93, 14); font-weight: bold;"># Маска для четных чисел</span><br>
        &nbsp;&nbsp;&nbsp;&nbspprint(arr[mask])  <span style="color: rgb(4, 93, 14); font-weight: bold;"># [2 4 6 8 10]</span><br><br>

        &nbsp;&nbsp;&nbsp;&nbsp<span style="color: rgb(4, 93, 14); font-weight: bold;"># Изменение элементов по маске</span><br>
        &nbsp;&nbsp;&nbsp;&nbsparr[mask] = -1<br>
        &nbsp;&nbsp;&nbsp;&nbspprint(arr)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># [ 1 -1  3 -1  5 -1  7 -1  9 -1]</span>
      </p>
      <p>Также очень много полезных методов: сортировка, максимальное, минимальное, среднее, сумма и многие другие</p>
      <br><br>
      <p>
        <b>Срезы (Slicing) в NumPy</b> - Срезы в NumPy позволяют работать с подмассивами и являются мощным инструментом для обработки данных. Они обеспечивают гибкость и производительность, необходимые для эффективного анализа и манипуляции данными.<br>
        Синтаксис срезов аналогичен срезам в стандартных списках Python и имеет следующий формат: <br>
        <span style="color: rgb(4, 93, 14); font-weight: bold;">arr[start:stop:step]</span><br><br>
        <b>Срезы многомерных массивов</b> - Срезы в многомерных массивах работают аналогично, но позволяют задавать срезы для каждого измерения. (если двумерный - то, отдельно для строк, отдельно для столбцов)
      </p>
    </div>
  </details>

  <!-- 10 -->
  <details class="details">
    <summary class="details__title">Библиотека Numpy. Модуль random.</summary>
    <div class="details__content">
      <p>Модуль random в NumPy предоставляет широкий набор инструментов для генерации случайных чисел, создания массивов случайных чисел и выполнения различных операций, связанных со случайностью. Эти функции являются важным компонентом для научных вычислений, моделирования, статистического анализа и других приложений.</p>
      <p>Функции модуля random могут быть использованы для выполнения различных статистических операций и моделирования. Например, генерация данных для моделирования или тестирования алгоритмов.</p>
      <br>
      <p>Модуль random в NumPy предоставляет мощные инструменты для генерации случайных чисел и выполнения операций, связанных со случайностью. Его использование включает генерацию случайных чисел с различными распределениями, создание массивов случайных чисел, фиксирование начального состояния генератора для воспроизводимости результатов, перемешивание массивов и выборку случайных элементов. Это делает его неотъемлемой частью экосистемы научных вычислений и анализа данных</p><br>
      <br><p><b>Основные функции модуля random (Генерация случайных чисел)</b></p><br>
      <ol>
        <li>
          <b>Случайные числа из равномерного распределения -</b> Функция rand генерирует случайные числа с равномерным распределением в диапазоне от 0 до 1.<br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_numbers = np.random.rand(5)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_numbers)  <b># Пример вывода: [0.69354293 0.82465574 0.54501156 0.43842065 0.82866434]</b>
          </code><br>
        </li>
        <li>
          Можно создавать массивы любой размерности, передавая нужные размеры в качестве аргументов: <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_matrix = np.random.rand(2, 3)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_matrix)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Пример вывода:</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># [[0.27937511 0.71589188 0.79248445]</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b>#  [0.48757711 0.92242775 0.68666152]]</b>
          </code><br>
        </li>
        <li>
          <b>Случайные целые числа -</b> Функция randint генерирует случайные целые числа в заданном диапазоне. <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_integers = np.random.randint(1, 10, size=5) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_integers)  <b># Пример вывода: [3 6 9 2 7]</b>
          </code>
          <br>
          <p>Размерность массива случайных целых чисел можно задать с помощью параметра size.</p>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_integer_matrix = np.random.randint(1, 100, size=(2, 3)) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_integer_matrix) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Пример вывода:</b> <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># [[54 29 95]</b> <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b>#  [70 12  5]]</b>
          </code>
        </li>
        <li>
          <p><b>Случайные числа с заданным распределением -</b> Функция uniform генерирует случайные числа с равномерным распределением в заданном диапазоне.</p>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_uniform_numbers = np.random.uniform(low=1.0, high=5.0, size=5) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_uniform_numbers)  <b># Пример вывода: [2.3196554  1.24903198 4.49587546 3.77022684 4.02202499]</b>
          </code>
        </li>
        <li>
          <p><b>Выборка случайных элементов -</b> метод choice достает из нашей последовательности случайное значение</p>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;lst = ['красный', "зеленый", "синий"] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print('random:', random.choice(lst)) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print('numpy:', np.random.choice(lst, size=2, replace=False, <span style="color: rebeccapurple;">p=[0.25, 0.05, 0.7]</span>)) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># random: синий</b> <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># numpy: ['синий' 'красный']</b>
          </code>
        </li>
      </ol>
    </div>
  </details>

  <!-- 11 -->
  <details class="details">
    <summary class="details__title">Библиотека Matplotlib. Методы .plot(), .bar(), .hist().</summary>
    <div class="details__content">
      <p>Matplotlib — это одна из самых популярных библиотек для визуализации данных в Python. Она позволяет создавать разнообразные графики и диаграммы, обеспечивая широкий набор инструментов для настройки их внешнего вида. В этом ответе мы подробно рассмотрим методы .plot(), .bar(), и .hist().</p>
      <p>Библиотека Matplotlib и её методы .plot(), .bar(), и .hist() предоставляют мощные инструменты для создания разнообразных графиков и диаграмм. Эти методы позволяют визуализировать данные в различных формах, что является важной частью анализа данных. Подробные примеры и возможности настройки позволяют создавать визуализации, соответствующие конкретным потребностям и требованиям анализа.</p>
      <br>
      <ul>
        <li>
          <p><b>Метод .plot()</b> - используется для создания линейных графиков. Он может отображать одномерные массивы данных и их зависимости друг от друга.</p><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;import matplotlib.pyplot as plt <br>
            &nbsp;&nbsp;&nbsp;&nbsp;import numpy as np <br><br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Создание данных</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;x = np.linspace(0, 10, 100)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;y = np.sin(x) <br><br>

            &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение графика</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.plot(x, y)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Simple Line Plot')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('x')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('sin(x)')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
          </code>
          <br><br>
          <p><b>Метод .plot() поддерживает множество параметров для настройки внешнего вида графика.</b></p><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение графика с настройками</b> <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.plot(x, y, label='sin(x)', color='blue', linestyle='--', linewidth=2, marker='o') <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Styled Line Plot') <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('x') <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('sin(x)') <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.legend() <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.grid(True) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
          </code>
          <br><br>
        </li>
        <li>
          <p><b>Метод .bar()</b> - Метод .bar() используется для построения столбчатых диаграмм, которые представляют данные в виде прямоугольников, где длина каждого прямоугольника пропорциональна значению.</p>
          <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Создание данных</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;categories = ['A', 'B', 'C', 'D']<br>
            &nbsp;&nbsp;&nbsp;&nbsp;values = [3, 7, 5, 9]<br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение столбчатой диаграммы</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(categories, values)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Simple Bar Plot')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('Categories')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('Values')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
          </code>
          <br><br>
          <p><b>Сгруппированные и сложенные столбчатые диаграммы</b> - Для создания более сложных столбчатых диаграмм, таких как сгруппированные и сложенные, используются дополнительные настройки.</p>
          <ol>
            <li>
              Сгруппированная столбчатая диаграмма<br><br>
              <code>
                &nbsp;&nbsp;&nbsp;&nbsp;<b># Создание данных</b><br>
                &nbsp;&nbsp;&nbsp;&nbsp;bar_width = 0.35 <br>
                &nbsp;&nbsp;&nbsp;&nbsp;index = np.arange(len(categories)) <br>
                &nbsp;&nbsp;&nbsp;&nbsp;values2 = [2, 6, 4, 8] <br>
                <br>              
                &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение сгруппированной столбчатой диаграммы </b><br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(index, values, bar_width, label='Group 1', color='b') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(index + bar_width, values2, bar_width, label='Group 2', color='r') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('Categories') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('Values') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Grouped Bar Plot') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.xticks(index + bar_width / 2, categories) <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.legend() <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
              </code><br><br>
            </li>
            <li>
              Сложенная столбчатая диаграмма <br><br>
              <code>
                &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение сложенной столбчатой диаграммы</b><br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(categories, values, label='Group 1', color='b') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(categories, values2, bottom=values, label='Group 2', color='r') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('Categories') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('Values') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Stacked Bar Plot') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.legend() <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
              </code>
            </li>
          </ol><br><br>
        </li>
        <li>
          <p><b>Метод .hist()</b> - Метод .hist() используется для создания гистограмм, которые отображают распределение данных. Гистограмма разбивает данные на интервалы (бинсы) и показывает количество данных в каждом интервале.</p>
          <br>
          <p>Аргументы и параметры</p>
              <ol>
                <li>
                  data <br>
                  Описание: Массив числовых данных, который будет использоваться для построения гистограммы. Тип: array-like (например, список, массив NumPy и т.д.)
                </li>
                <li>
                  bins <br>
                  Количество интервалов (бинсов), на которые будут разделены данные. Бинсы определяют, как данные будут группироваться. Тип: int или sequence
                </li>
                <li>
                  density <br>
                  Описание: Если True, то гистограмма будет нормализована так, что площадь под гистограммой будет равна 1 (показывает плотность вероятности). Тип: bool
                </li>
                <li>
                  color <br>
                  Описание: Цвет прямоугольников гистограммы. Тип: str или sequence
                </li>
                <li>
                  edgecolor <br>
                  Описание: Цвет границ прямоугольников. Тип: str или sequence
                </li>
                <li>
                  alpha <br>
                  Описание: Прозрачность прямоугольников гистограммы. Значение должно быть в диапазоне от 0 (полностью прозрачный) до 1 (полностью непрозрачный). Тип: float
                </li>
              </ol>
        </li>
      </ul>
    </div>
  </details>

  <!-- 12 -->
  <details class="details">
    <summary class="details__title">Модули. Модуль os.</summary>
    <div class="details__content">
      <p><b>Модуль</b> — это файл, содержащий код на Python, который может включать определения функций, классов и переменных. Модули позволяют структурировать программу, разделяя код на логические части, которые могут быть многократно использованы в разных программах.</p>
      <br>
      <p>Модули и пакеты являются важными компонентами Python, позволяющими организовывать и многократно использовать код. Модуль os предоставляет множество полезных функций для взаимодействия с операционной системой, что делает его незаменимым инструментом для выполнения различных системных операций. Понимание и умение работать с модулями и модулем os позволяет создавать более гибкие и мощные программы.</p>
      <br>
      <ul><b>Зачем нужны модули?</b>
        <li><b>Организация кода:</b> Разделение большого кода на более мелкие и понятные части.</li>
        <li><b>Повторное использование:</b> Код, написанный в одном модуле, может быть импортирован и использован в других программах или модулях.</li>
        <li><b>Изоляция:</b> Модули позволяют изолировать код, чтобы избежать конфликтов имен переменных и функций.</li>
        <li><b>Упрощение тестирования и отладки:</b> Меньшие и более изолированные части кода легче тестировать и отлаживать.</li>
      </ul>
      <br><p><b>Чтобы использовать функции, классы или переменные из модуля, его нужно импортировать в другой файл</b></p>
      <br><p>Пакет — это коллекция модулей, организованная в директории, которая содержит файл __init__.py. Пакеты позволяют создавать многоуровневую структуру модулей.</p>
      <br><p><b>Модуль os</b></p>
      <p>Модуль os в Python предоставляет функции для взаимодействия с операционной системой. Он позволяет выполнять операции, такие как управление файлами и директориями, работа с путями, получение информации о системе и многого другого.</p>
      <br>
      <ol>Основные функции модуля os
        <li>
          Работа с текущей директорией
          <ul>
            <li><b>os.getcwd():</b> Возвращает текущую рабочую директорию.</li>
            <li><b>os.chdir(path):</b> Меняет текущую рабочую директорию</li>
          </ul>
        </li>
        <li>
          Работа с файлами и директориями
          <ul>
            <li><b>os.listdir(path='.'):</b> Возвращает список файлов и директорий в указанной директории.</li>
            <li><b>os.mkdir(path):</b> Создает новую директорию</li>
            <li><b>os.makedirs(path):</b> Создает директорию и все промежуточные директории</li>
            <li><b>os.remove(path):</b> Удаляет файл.</li>
            <li><b>os.rmdir(path):</b> Удаляет пустую директорию.</li>
            <li><b>os.removedirs(path):</b> Удаляет директорию и все промежуточные пустые директории.</li>
          </ul>
        </li>
        <li>
          Работа с путями
          <ul>
            <li><b>os.path.join(path, *paths):</b> Соединяет один или несколько компонентов пути.</li>
            <li><b>os.path.exists(path):</b> Проверяет, существует ли указанный путь.</li>
            <li><b>os.path.isfile(path):</b> Проверяет, является ли указанный путь файлом.</li>
            <li><b>os.path.isdir(path):</b> Проверяет, является ли указанный путь директорией.</li>
            <li><b>os.path.basename(path):</b> Возвращает базовое имя пути.</li>
            <li><b>os.path.dirname(path):</b> Возвращает имя директории пути.</li>
            <li><b>os.path.abspath(path):</b> Возвращает абсолютный путь.</li>
          </ul>
        </li>
        <li>
          Получение информации о системе
          <ul>
            <li><b>os.name:</b> Имя операционной системы.</li>
            <li><b>os.environ:</b> Словарь переменных окружения.</li>
            <li><b>os.getlogin():</b> Имя текущего пользователя.</li>
            <li><b>os.getpid():</b> ID текущего процесса.</li>
          </ul>
        </li>
        <li>
          Выполнение системных команд
          <ul>
            <li><b>os.system(command):</b> Выполняет команду в оболочке операционной системы.</li>
          </ul>
        </li>
        <li>
          Работа с процессами
          <ul>
            <li><b>os.fork():</b> Создает новый процесс (только для Unix).</li>
            <li><b>os.execv(path, args):</b> Заменяет текущий процесс новым.</li>
            <li><b>os._exit(status):</b> Завершает текущий процесс.</li>
          </ul>
        </li>
      </ol>
    </div>
  </details>

  <!-- 13 -->
  <details class="details">
    <summary class="details__title">Работа с файлами. Функция open(). Контекстный менеджер with.</summary>
    <div class="details__content">
      <p>Работа с файлами — это одна из ключевых задач в программировании. Python предоставляет удобные инструменты для чтения и записи файлов, а также для управления их контекстом. Основными инструментами для этого являются функция open() и контекстный менеджер with.</p>
      <br><p>Работа с файлами является важным аспектом программирования на Python. Использование функции open() в сочетании с контекстным менеджером with обеспечивает надежное и эффективное управление файлами. Контекстный менеджер автоматически заботится о закрытии файлов, что уменьшает риск утечек ресурсов и улучшает читаемость кода. Понимание различных режимов открытия файлов и возможностей управления ими позволяет создавать более гибкие и мощные программы.</p>
      <br><p><b>Функция open()</b> - Функция open() используется для открытия файлов. Она возвращает объект файла, который может быть использован для чтения, записи или других операций. Формат вызова функции open() выглядит следующим образом:</p>
      <code>
        open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)
      </code>
      <br><br>
      <ul><b>Основные параметры функции open()</b>
        <li><b>file:</b> Имя файла, который необходимо открыть. Это обязательный параметр.</li>
        <li>
          <b>mode:</b> Режим открытия файла. По умолчанию 'r' (чтение). <b>Варианты:</b>
          <ul>
            <li><b>'r'</b> – чтение (по умолчанию)</li>
            <li><b>'w'</b> – запись (создает новый файл или очищает существующий)</li>
            <li><b>'a'</b> – добавление (добавляет данные в конец файла)</li>
            <li><b>'b'</b> – бинарный режим (например, 'rb' для чтения в бинарном режиме)</li>
            <li><b>'t'</b> – текстовый режим (по умолчанию, например, 'rt' для чтения в текстовом режиме)</li>
            <li><b>'+'</b> – чтение и запись (например, 'r+' для чтения и записи)</li>
          </ul>
        </li>
      </ul>
      <br><br>
      <p><b>Контекстный менеджер with</b> - Контекстный менеджер with предоставляет удобный способ работы с файлами, обеспечивая автоматическое закрытие файла после завершения блока with. Это помогает избежать утечек ресурсов и ошибок, связанных с незакрытыми файлами.</p>
      <br>
      <p><b>Основная структура использования контекстного менеджера with</b></p>
      <code>
        &nbsp;&nbsp;&nbsp;&nbsp;with open('filename', 'mode') as file: <br>
        &nbsp;&nbsp;&nbsp;&nbsp;<b># Операции с файлом</b> <br>
        &nbsp;&nbsp;&nbsp;&nbsp;pass
      </code>
      <br><br>
      <ol><b>Преимущества использования контекстного менеджера with</b>
        <li><b>Автоматическое закрытие файлов:</b> Файл автоматически закрывается по завершении блока with, что уменьшает риск утечки ресурсов.</li>
        <li><b>Обработка исключений:</b> В случае возникновения исключения файл все равно будет корректно закрыт.</li>
        <li><b>Более чистый и читаемый код:</b> Уменьшается необходимость явного вызова метода close().</li>
      </ol>
    </div>
  </details>

  <!-- 14 -->
  <details class="details">
    <summary class="details__title">Библиотека Pandas. Базовые методы.</summary>
    <div class="details__content">
      <p><b>Pandas</b> — это мощная и широко используемая библиотека Python для анализа данных. Она предоставляет высокоуровневые структуры данных и функции, предназначенные для упрощения работы с метко-ориентированными данными, включая табличные данные, временные ряды и другие формы данных</p>
      <br>
      <ol><b>Основные структуры данных Pandas</b>
        <li><b>Series:</b> Одномерный массив, который может содержать любые данные (интегрированные с индексами).</li>
        <li><b>DataFrame:</b> Двумерная таблица с метками строк и столбцов, представляющая собой наиболее часто используемую структуру данных в Pandas.</li>
      </ol>
      <br>
      <p><b>Базовые методы Pandas</b></p><br>
      <ol><b>Методы для работы с DataFrame</b>
        <li>
          <b>Чтение данных</b>
          <ul>
            <li>pd.read_csv(): Чтение данных из CSV файла.</li>
            <li>pd.read_excel(): Чтение данных из Excel файла.</li>
            <li>pd.read_json(): Чтение данных из JSON файла.</li>
          </ul>
        </li>
        <li>
          <b>Запись данных</b>
          <ul>
            <li>df.to_csv(): Запись DataFrame в CSV файл.</li>
            <li>df.to_excel(): Запись DataFrame в Excel файл.</li>
            <li>df.to_json(): Запись DataFrame в JSON файл.</li>
          </ul>
        </li>
        <li>
          <b>Информация о DataFrame</b>
          <ul>
            <li>df.head(n): Возвращает первые n строк DataFrame.</li>
            <li>df.tail(n): Возвращает последние n строк DataFrame.</li>
            <li>df.info(): Отображает краткую информацию о DataFrame, включая индекс, тип данных и ненулевые значения.</li>
            <li>df.describe(): Выводит основные статистические характеристики DataFrame.</li>
          </ul>
        </li>
        <li>
          <b>Индексация и фильтрация</b>
          <ul>
            <li>Индексация по метке <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df['Name'])  # Возвращает Series <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df[['Name', 'Age']])  # Возвращает DataFrame
            </li>
            <li>Логическая индексация <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;adults = df[df['Age'] > 30]
            </li>
            <li>Локатор по метке <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df.loc[0])  # Первая строка DataFrame <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df.loc[:, 'Name'])  # Все строки столбца 'Name'
            </li>
            <li>Локатор по позиции <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df.iloc[0])  # Первая строка DataFrame <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df.iloc[:, 0])  # Все строки первого столбца
            </li>
          </ul>
        </li>
        <li>
          <b>Добавление и удаление данных</b>
          <ul>
            <li>Добавление нового столбца <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df['Salary'] = [50000, 60000, 70000]</li>
            <li>Удаление столбца <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.drop('Salary', axis=1, inplace=True)</li>
            <li>Удаление строки <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.drop(1, axis=0, inplace=True)  # Удаляет вторую строку</li>
          </ul>
        </li>
        <li>
          <b>Обработка отсутствующих данных</b>
          <ul>
            <li>Проверка наличия пропущенных данных <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.isna()</li>
            <li>Удаление пропущенных данных <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.dropna(inplace=True)</li>
            <li>Заполнение пропущенных данных <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.fillna(0, inplace=True)</li>
          </ul>
        </li>
        <li>
          <b>Группировка данных</b>
          <ul>
            <li>Группировка и агрегирование <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grouped = df.groupby('City') <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(grouped['Age'].mean())  # Средний возраст по городам
            </li>
          </ul>
        </li>
        <br><br>
        <ol><b><h3>Методы для работы с Series</h3></b>
          <li>
            <b>Базовые операции</b>
            <ul>
              <li>Получение значения по индексу <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s[0])  # Первое значение</li>
              <li>Фильтрация <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s[s > 2])  # Все значения больше 2</li>
              <li>Операции с индексами <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s.index = ['a', 'b', 'c', 'd', 'e']</li>
            </ul>
          </li>
          <li>
            <b>Статистические методы</b>
            <ul>
              <li>
                Основные статистические характеристики <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.mean())  # Среднее значение <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.sum())  # Сумма всех значений <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.max())  # Максимальное значение <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.min())  # Минимальное значение <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.std())  # Стандартное отклонение
              </li>
            </ul>
          </li>
        </ol>
      </ol>
    </div>
  </details>

  <!-- 15 -->
  <details class="details">
    <summary class="details__title">Библиотека Pandas. Статистические методы.</summary>
    <div class="details__content">
      <p>Pandas — это мощная библиотека для анализа данных на языке Python, которая включает в себя множество встроенных методов для вычисления статистических характеристик. Эти методы позволяют быстро и эффективно анализировать и обрабатывать данные.</p>
      <br><p><b>Основные статистические методы Pandas</b></p>
      <p>Большинство статистических методов можно применять как к Series, так и к DataFrame. При применении к DataFrame методы по умолчанию вычисляют статистику по столбцам, но можно изменить поведение с помощью параметра axis.</p>
      <br><br>
      <ol><b>Часто используемые статистические методы</b>
        <li>Метод count() - Возвращает количество ненулевых значений в каждом столбце (или строке, если axis=1).</li>
        <li>Метод sum() - Возвращает сумму значений по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод mean() - Возвращает среднее значение по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод median() - Возвращает медиану значений по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод std() - Возвращает стандартное отклонение значений по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод var() - Возвращает дисперсию значений по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод min() - Возвращает минимальное значение по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод max() - Возвращает максимальное значение по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод idxmin() - Возвращает индекс минимального значения по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод idxmax() - Возвращает индекс максимального значения по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод describe() - Возвращает основные статистические характеристики DataFrame или Series: количество ненулевых значений, среднее, стандартное отклонение, минимум, 25-й перцентиль, медиана, 75-й перцентиль и максимум.</li>
        <li>Метод corr() - Возвращает коэффициент корреляции Пирсона между столбцами DataFrame.</li>
        <li>Метод cov() - Возвращает ковариацию между столбцами DataFrame.</li>
      </ol>
    </div>
  </details>

  <!-- 16 -->
  <details class="details">
    <summary class="details__title">Генераторы списков.</summary>
    <div class="details__content">
      <p>Генераторы списков (list comprehensions) в Python предоставляют удобный и элегантный способ создания списков. Они позволяют создавать новые списки, применяя выражение к каждому элементу последовательности (например, списка или диапазона) и могут включать условные выражения для фильтрации элементов.</p>
      <br>
      <code>[expression for item in iterable if condition]</code><br><br>
      <ul><b>Базовый синтаксис генератора списков выглядит следующим образом:</b>
        <li><b>expression:</b> Выражение, применяемое к каждому элементу.</li>
        <li><b>item:</b> Переменная, представляющая текущий элемент из последовательности.</li>
        <li><b>iterable:</b> Последовательность (например, список или диапазон), по которой происходит итерация.</li>
        <li><b>condition:</b> (необязательно) Условие для фильтрации элементов.</li>
      </ul>
      <br>
      <ol><b>Преимущества генераторов списков</b>
        <li>
          <b>Краткость и читабельность:</b> Генераторы списков позволяют создавать списки в одну строку, делая код более компактным и понятным.
        </li>
        <li>
          <b>Производительность:</b> Генераторы списков часто работают быстрее, чем эквивалентные конструкции с использованием циклов.
        </li>
        <li>
          <b>Функциональность:</b> Возможность включать выражения и условия в генераторы списков делает их мощным инструментом для обработки данных.
        </li>
      </ol>
      <br>
      <ol><b>Примеры использования генераторов списков</b>
        <li>
          <b>Создание списка квадратов чисел</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;squares = [x**2 for x in range(10)] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(squares) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
          </code>
        </li>
        <li>
          <b>Создание списка четных чисел</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;evens = [x for x in range(20) if x % 2 == 0] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(evens) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
          </code>
        </li>
        <li>
          <b>Преобразование строки в список символов</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;chars = [char for char in "hello"] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(chars) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: ['h', 'e', 'l', 'l', 'o']
          </code>
        </li>
        <li>
          <b>Создание списка пар (число, его квадрат)</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;pairs = [(x, x**2) for x in range(10)] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(pairs) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: [(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25), (6, 36), (7, 49), (8, 64), (9, 81)]
          </code>
        </li>
        <li>
          <b>Использование вложенных циклов в генераторах списков</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;matrix = [[i * j for j in range(5)] for i in range(5)] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(matrix) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: [[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8], [0, 3, 6, 9, 12], [0, 4, 8, 12, 16]]
          </code>
        </li>
      </ol>
    </div>
  </details>

  <h2><strong>Нейронные сети</strong></h2>

  <!-- 1 -->
  <details class="details">
    <summary class="details__title">Fast API. Создание и запуск приложения с помощью данного фреймворка</summary>
    <div class="details__content">
      <p>FastAPI — это современный, высокопроизводительный веб-фреймворк для создания API с Python 3.6+ на основе стандартов OpenAPI и JSON Schema. Он разработан для быстрого написания кода и создания API, которые могут работать с высокой скоростью и эффективностью.</p>
      <br>
      <ol><b>Основные преимущества FastAPI:</b>
        <li><b>Высокая производительность:</b> Сравнима с производительностью NodeJS и Go (благодаря Starlette и Pydantic).</li>
        <li><b>Автоматическая документация:</b> Генерирует интерактивную документацию для API с помощью Swagger UI и ReDoc.</li>
        <li><b>Типизация: </b>Полная поддержка аннотаций типов Python, что помогает в создании надежного и проверенного кода</li>
        <li><b>Простота использования:</b> Быстрое и простое создание API.</li>
      </ol>
      <br>
      <ol><b>Создание базового приложения</b>
        <li>
          Для начала необходимо установить FastAPI и Uvicorn, ASGI сервер для запуска приложения: <b><code>pip install fastapi "uvicorn[standard]"</code></b>
        </li>
        <li>
          Импорт необходимых модулей: <b><code>from fastapi import FastAPI</code></b>
        </li>
        <li>
          Создание экземпляра FastAPI: <b><code>app = FastAPI()</code></b>
        </li>
        <li>
          Определение маршрутов (endpoints) <br>
          Маршруты определяются с помощью декораторов. Декораторы указывают, какой HTTP метод используется для маршрута (GET, POST, PUT, DELETE и т.д.) и путь к маршруту. <br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<span style="color: orange">@app.get("/")</span><br>
            &nbsp;&nbsp;&nbsp;&nbsp;def read_root(): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"Hello": "World"} <br>
          </code><br><p>Этот код создает простой маршрут, который возвращает JSON-объект {"Hello": "World"} при обращении к корневому URL (/).</p>
        </li>
        <li>
          Запуск приложения осуществляется с помощью Uvicorn: <b><code>uvicorn main:app --reload --port 8000 --host 0.0.0.0 &</code></b><br>
          <p>Здесь main — это имя файла Python (без .py), app — это экземпляр FastAPI, а --reload включает режим перезагрузки, чтобы изменения в коде автоматически обновлялись.</p>
        </li>
      </ol>
      <br><br><p><b>Пример: Создание более сложного API</b></p><br>
      <ol>
        <li>
          <b>Определение маршрутов с параметрами</b> <br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;from typing import Optional <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;@app.get("/items/{item_id}") <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def read_item(item_id: int, q: Optional[str] = None): <br>
               &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"item_id": item_id, "q": q}
          </code>
          <br><br><p>Этот маршрут принимает путь параметра item_id и необязательный параметр запроса q.</p><br>
        </li>
        <li>
          <b>Обработка POST-запросов с телом запроса</b> (Для обработки данных в теле запроса мы используем Pydantic модели.) <br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;from pydantic import BaseModel <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;class Item(BaseModel): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name: str <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description: Optional[str] = None <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;price: float <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tax: Optional[float] = None <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;@app.post("/items/") <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def create_item(item: Item): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return item
          </code>
          <br><br><p>Здесь мы определяем Pydantic модель Item и используем её в маршруте для обработки POST-запроса.</p><br>
        </li>
      </ol>
      <br>
      <ol><b>Работа с запросами и ответами</b>
        <li>
          <b>Параметры пути и запроса</b> - FastAPI автоматически парсит параметры пути и запросов и проверяет их типы. <br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;@app.get("/users/{user_id}") <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def read_user(user_id: int, name: Optional[str] = None): <br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"user_id": user_id, "name": name}
          </code><br><br>
        </li>
        <li>
          <b>Валидация и обработка данных</b> - Использование Pydantic моделей обеспечивает валидацию данных и автоматическую документацию<br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;class User(BaseModel): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;username: str <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;email: str <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;age: Optional[int] = None <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;@app.post("/users/") <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def create_user(user: User): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return user
          </code>
        </li>
      </ol>
      <br>
      <ol><b>Автоматическая документация</b> - FastAPI автоматически генерирует документацию для всех маршрутов. Вы можете получить доступ к ней по следующим URL:
        <li>Swagger UI: <b><code>http://127.0.0.1:8000/docs</code></b></li>
        <li>ReDoc: <b><code>http://127.0.0.1:8000/redoc</code></b></li>
      </ol><br><br>
      <p><b>Асинхронное программирование -</b> FastAPI поддерживает асинхронное программирование с помощью async def.</p>
      <br>
      <code>
        &nbsp;&nbsp;&nbsp;&nbsp;import asyncio <br>
        <br>
        &nbsp;&nbsp;&nbsp;&nbsp;@app.get("/async") <br>
        &nbsp;&nbsp;&nbsp;&nbsp;async def get_async(): <br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await asyncio.sleep(1) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"message": "Hello, async world!"}
      </code><br><br>
      <p>FastAPI — мощный инструмент для создания API с Python, который обеспечивает высокую производительность и удобство использования. Он предлагает множество возможностей для работы с запросами, ответами, асинхронным программированием, а также предоставляет автоматическую документацию и валидацию данных с помощью Pydantic. Быстрый старт с FastAPI позволяет разработчикам быстро и эффективно создавать API, сохраняя при этом высокие стандарты качества и производительности.</p>
    </div>
  </details>

  <!-- 2 -->
  <details class="details">
    <summary class="details__title">Активационные функции.</summary>
    <div class="details__content">
      <p>Активационные функции играют ключевую роль в работе нейронных сетей, определяя, как сигналы нейронов передаются дальше в сеть. Они вводят нелинейность в модель, что позволяет нейронным сетям решать сложные задачи, которые не могут быть решены линейными моделями.</p>
      <p>Можно сказать, что это ключевой компонент нейронных сетей, который позволяет моделям решать нелинейные задачи. Понимание их свойств и влияние на процесс обучения помогает выбирать правильные функции для конкретных задач и оптимизировать работу нейронных сетей.</p>
      <br>
      <ol><b>Основные активационные функции</b>
        <li>
          <b>Линейная активационная функция (Linear Activation Function)</b><br>
          Функция просто возвращает входное значение без изменений: <b>f(x)=x</b>
          <ul>
            <li><b>Преимущества:</b> Простота.</li>
            <li><b>Недостатки:</b> Не вводит нелинейности, что ограничивает возможности модели.</li>
          </ul>
        </li>
        <li>
          <b>Функция сигмоиды (Sigmoid Activation Function)</b><br>
          Сигмоидальная функция (логистическая функция) сжимает входные значения в диапазон от 0 до 1
          <ul>
            <li><b>Преимущества:</b> Используется для моделирования вероятностей.</li>
            <li><b>Недостатки:</b> Может вызывать проблему исчезающего градиента, замедляя обучение глубоких сетей.</li>
          </ul>
        </li>
        <li>
          <b>Гиперболический тангенс (Hyperbolic Tangent, Tanh)</b><br>
          Функция тангенса сжимает значения в диапазон от -1 до 1
          <ul>
            <li><b>Преимущества:</b> Значения центрированы вокруг нуля, что может ускорить обучение.</li>
            <li><b>Недостатки:</b> Также подвержена проблеме исчезающего градиента.</li>
          </ul>
        </li>
        <li>
          <b>Прямолинейная активационная функция (Rectified Linear Unit, ReLU)</b><br>
          Функция ReLU устанавливает все отрицательные значения на ноль, а положительные значения оставляет без изменений
          <ul>
            <li><b>Преимущества:</b> Простота и эффективность, решает проблему исчезающего градиента.</li>
            <li><b>Недостатки:</b> Может возникать проблема «мертвых» нейронов, когда градиент равен нулю для отрицательных входных значений.</li>
          </ul>
        </li>
        <li>
          <b>Леченная ReLU (Leaky ReLU)</b><br>
          Модификация ReLU, которая позволяет небольшое отрицательное значение для отрицательных входов
          <ul>
            <li><b>Преимущества:</b> Снижает вероятность возникновения «мертвых» нейронов.</li>
            <li><b>Недостатки:</b> Несколько сложнее, чем обычная ReLU.</li>
          </ul>
        </li>
        <li>
          <b>Функция ELU (Exponential Linear Unit)</b><br>
          Функция ELU похожа на ReLU, но для отрицательных значений применяет экспоненциальное преобразование:
          <ul>
            <li><b>Преимущества:</b> Уменьшает смещение, поддерживает положительные значения.</li>
            <li><b>Недостатки:</b> Более сложная функция.</li>
          </ul>
        </li>
        <li>
          <b>Функция Softmax</b><br>
          Функция Softmax используется в выходном слое классификационных моделей для многоклассовых задач. Она преобразует вектор входных значений в вероятности:
          <ul>
            <li><b>Преимущества:</b> Позволяет моделировать многоклассовую классификацию.</li>
            <li><b>Недостатки:</b> Затрудняет обучение при больших значениях.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <ol><b>Влияние активационных функций на обучение</b>
        <li>
          <b>Нелинейность</b> - Основная роль активационных функций — введение нелинейности. Без этого нейронные сети будут работать как линейные модели, неспособные моделировать сложные зависимости в данных.
        </li>
        <li>
          <b>Градиенты и обучение</b> - Активационные функции влияют на процесс обучения через обратное распространение. Проблема исчезающего и взрывающегося градиента связана с выбором активационных функций. Например, сигмоид и tanh могут сильно уменьшить градиенты, замедляя обучение.
        </li>
      </ol>
      <br><br>
      <ol><b>Выбор активационной функции</b><br>Выбор активационной функции зависит от конкретной задачи и структуры модели. В практике чаще всего используются следующие комбинации:
        <li>
          <b>Внутренние слои:</b> ReLU или её вариации (Leaky ReLU, ELU) из-за их эффективности и способности решать проблему исчезающего градиента.
        </li>
        <li>
          <b>Выходные слои для классификации:</b>
          <ul>
            <li><b>Двухклассовая классификация:</b> Сигмоида.</li>
            <li><b>Многоклассовая классификация:</b> Softmax.</li>
          </ul>
        </li>
        <li>
          <b>Выходные слои для регрессии:</b> Линейная активационная функция.
        </li>
      </ol>
    </div>
  </details>

  <!-- 3 -->
  <details class="details">
    <summary class="details__title">Функция ошибки. Стандартные функции ошибок keras.</summary>
    <div class="details__content">
      <p>Функция ошибки, или функция потерь, играет ключевую роль в обучении моделей машинного обучения и нейронных сетей. Она измеряет, насколько хорошо или плохо модель делает свои прогнозы, предоставляя метрику для оптимизации модели во время обучения. Цель обучения заключается в минимизации функции потерь, что означает улучшение точности прогнозов модели.</p>
      <br>
      <ol><b>Основные функции ошибок</b>
        <li>
          <b>Среднеквадратичная ошибка (Mean Squared Error, MSE)</b><br>
          Среднеквадратичная ошибка — это наиболее часто используемая функция потерь для задач регрессии. Она измеряет среднее значение квадратов ошибок между прогнозируемыми и истинными значениями:
          <ul>
            <li>Преимущества: Простота вычисления и интерпретации.</li>
            <li>Недостатки: Чувствительность к выбросам, поскольку квадратичные ошибки увеличиваются экспоненциально.</li>
          </ul>
        </li>
        <li>
          <b>Средняя абсолютная ошибка (Mean Absolute Error, MAE)</b><br>
          Средняя абсолютная ошибка измеряет среднее значение абсолютных ошибок между прогнозируемыми и истинными значениями:
          <ul>
            <li>Преимущества: Менее чувствительна к выбросам по сравнению с MSE</li>
            <li>Недостатки: Меньше наказывает за большие ошибки, чем MSE.</li>
          </ul>
        </li>
        <li>
          <b>Кросс-энтропия (Cross-Entropy)</b><br>
          Кросс-энтропия используется для задач классификации. Она измеряет разницу между двумя вероятностными распределениями: истинным распределением и прогнозируемым распределением модели.
          <ul>
            <li>Бинарная кросс-энтропия (Binary Cross-Entropy): Используется для двоичной классификации.</li>
            <li>Категориальная кросс-энтропия (Categorical Cross-Entropy): Используется для многоклассовой классификации.</li>
          </ul>
        </li>
        <li>
          <b>Hinge Loss</b><br>
          Hinge Loss используется для задач классификации, особенно в методе опорных векторов (SVM): <br>
          набор схожих алгоритмов обучения с учителем, использующихся для задач классификации и регрессионного анализа. Принадлежит семейству линейных классификаторов и может также рассматриваться как частный случай регуляризации по Тихонову. Особым свойством метода опорных векторов является непрерывное уменьшение эмпирической ошибки классификации и увеличение зазора, поэтому метод также известен как метод классификатора с максимальным зазором.
        </li>
      </ol><br>
      <ol><b>Функции ошибок в Keras</b><br>Keras предоставляет набор стандартных функций потерь, которые можно легко использовать при определении модели. <br>
        <code><b>from tensorflow.keras.losses import ...</b></code>
        <br>Вот некоторые из них:
        <li><b>Mean Squared Error (MSE)</b></li>
        <li><b>Mean Absolute Error (MAE)</b></li>
        <li><b>Binary Cross-Entropy</b></li>
        <li><b>Categorical Cross-Entropy</b></li>
        <li>
          <b>Sparse Categorical Cross-Entropy</b> - Используется для многоклассовой классификации, когда метки классов представлены целыми числами, а не в виде one-hot кодирования.
        </li>
        <li><b>Hinge</b></li>
      </ol><br>
      <ul><b>Пользовательские функции потерь</b>
        <li>
          В Keras также можно определять собственные функции потерь. Например: <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;import tensorflow as tf <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def custom_loss(y_true, y_pred): <br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return tf.reduce_mean(tf.square(y_true - y_pred)) <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;model.compile(optimizer='adam', loss=custom_loss)
          </code>
        </li>
      </ul><br>
      <p>Функции потерь играют критически важную роль в обучении моделей машинного обучения и нейронных сетей. Выбор правильной функции потерь зависит от задачи, которую необходимо решить (регрессия, классификация и т.д.), и структуры данных. Keras предоставляет удобные и легко настраиваемые инструменты для работы с различными функциями потерь, а также позволяет создавать собственные функции для специфических требований.</p>
    </div>
  </details>

  <!-- 4 -->
  <details class="details">
    <summary class="details__title">Оптимизаторы. Стандартные оптимизаторы keras.</summary>
    <div class="details__content">
      <p>
        Оптимизаторы играют ключевую роль в процессе обучения нейронных сетей, регулируя обновление весов на основе градиента функции потерь. Они определяют, как модель будет корректировать свои параметры для минимизации ошибки и улучшения предсказательной способности
      </p><br>
      <code><b>from tensorflow.keras.optimizers import ...</b></code><br><br>
      <ol><b>Основные оптимизаторы</b>
        <li>
          <b>Градиентный спуск (Gradient Descent)</b><br>Градиентный спуск обновляет параметры модели по направлению противоположному градиенту функции потерь:<b> θ=θ−η∇J(θ) </b><br>
          где:
          <ul>
            <li>θ — параметры модели,</li>
            <li>η — скорость обучения (learning rate),</li>
            <li>∇J(θ) — градиент функции потерь.</li>
          </ul>
          <br>
          <ul><b>Вариации градиентного спуска:</b>
            <li><b>Градиентный спуск с нулевой мини-партией (Batch Gradient Descent):</b> Использует весь обучающий набор данных для каждого шага обновления.</li>
            <li><b>Стохастический градиентный спуск (SGD):</b> Использует один случайный пример из обучающего набора данных для каждого шага обновления.</li>
            <li><b>Мини-пакетный градиентный спуск (Mini-Batch Gradient Descent):</b> Использует небольшие случайные подмножества данных для каждого шага обновления.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <ol><b>Стандартные оптимизаторы в Kera</b><br>Keras предоставляет несколько популярных оптимизаторов, которые можно использовать для обучения моделей.
        <li>
          <b>SGD (Stochastic Gradient Descent)</b> - Стохастический градиентный спуск с возможностью настройки момента (momentum) и затухания (decay).
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>momentum:</b> Параметр, который помогает ускорить SGD в правильном направлении и сгладить осцилляции.</li>
            <li><b>nesterov:</b> Логическое значение для использования Нестерова ускоренного градиента.</li>
          </ul>
        </li>
        <li>
          <b>Adam (Adaptive Moment Estimation)</b> - Adam — это популярный оптимизатор, который объединяет преимущества Adagrad и RMSProp. Он поддерживает индивидуальные скорости обучения для каждого параметра.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>beta_1:</b> Параметр экспоненциального затухания для первого момента (по умолчанию 0.9).</li>
            <li><b>beta_2:</b> Параметр экспоненциального затухания для второго момента (по умолчанию 0.999).</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>RMSprop</b> - RMSprop оптимизирует градиентный спуск, поддерживая переменную скорость обучения для каждого параметра.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>rho:</b> Параметр затухания для вычисления движущегося среднего квадратов градиентов.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>Adagrad</b> - Adagrad адаптирует скорости обучения для каждого параметра, уменьшая скорость обучения по мере увеличения количества обновлений параметра.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>Adadelta</b> - Adadelta — расширение Adagrad, которое стремится уменьшить его агрессивное уменьшение скорости обучения.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Начальная скорость обучения.</li>
            <li><b>rho:</b> Параметр затухания для вычисления движущегося среднего квадратов градиентов.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>Adamax</b> - Adamax — это вариант оптимизатора Adam на основе нормы 𝐿∞
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>beta_1:</b> Параметр экспоненциального затухания для первого момента.</li>
            <li><b>beta_2:</b> Параметр экспоненциального затухания для второго момента.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>Nadam</b> - Nadam — это комбинация Adam и Nesterov ускоренного градиента.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>beta_1:</b> Параметр экспоненциального затухания для первого момента.</li>
            <li><b>beta_2:</b> Параметр экспоненциального затухания для второго момента.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
      </ol><br>
      <p>Оптимизаторы играют важную роль в процессе обучения нейронных сетей, регулируя обновление параметров модели на основе градиента функции потерь. Выбор правильного оптимизатора и его гиперпараметров может существенно повлиять на производительность и скорость обучения модели. Keras предоставляет широкий спектр стандартных оптимизаторов, а также позволяет настраивать их параметры для различных задач и архитектур нейронных сетей.</p>
    </div>
  </details>

  <!-- 5 -->
  <details class="details">
    <summary class="details__title">Обучение нейронной сети. Выборки. Валидация данных.</summary>
    <div class="details__content">
      <p>Обучение нейронной сети — это процесс, в ходе которого модель настраивает свои параметры для минимизации функции ошибки и максимизации точности предсказаний. Этот процесс включает в себя несколько ключевых этапов, таких как разделение данных на выборки, обучение модели, валидация и тестирование.</p>
      <br>
      <ol><b>Выборки данных</b>
        <li>
          <b>Обучающая выборка (Training Set)</b><br>
          Обучающая выборка используется для непосредственного обучения модели. В этот этап модель настраивает свои параметры (веса и смещения) на основе данных и соответствующих им меток (labels).
          <ul>
            <li><b>Размер обучающей выборки:</b> Обычно составляет 70-80% от всех доступных данных</li>
            <li><b>Задача:</b> Минимизация функции потерь на обучающих данных.</li>
          </ul>
        </li>
        <li>
          <b>Валидационная выборка (Validation Set)</b><br>
          Валидационная выборка используется для оценки модели во время процесса обучения. Эти данные не используются для обновления параметров модели, а служат для мониторинга производительности модели и настройки гиперпараметров (например, скорости обучения, структуры сети).
          <ul>
            <li><b>Размер валидационной выборки:</b> Обычно составляет 10-15% от всех доступных данных.</li>
            <li><b>Задача:</b> Предотвращение переобучения и оптимизация гиперпараметров</li>
          </ul>
        </li>
        <li>
          <b>Тестовая выборка (Test Set)</b><br>
          Тестовая выборка используется для окончательной оценки модели после завершения обучения. Эти данные полностью отделены от процесса обучения и валидации.
          <ul>
            <li><b>Размер тестовой выборки:</b> Обычно составляет 10-15% от всех доступных данных.</li>
            <li><b>Задача:</b> Оценка обобщающей способности модели на новых, невиданных данных.</li>
          </ul>
        </li>
      </ol>
      <br>
      <ol><b>Валидация данных</b>
        <li>
          <b>Кросс-валидация (Cross-Validation)</b><br>
          Кросс-валидация — это метод оценки модели, при котором данные делятся на несколько частей (folds). Модель обучается на нескольких частях и проверяется на оставшихся, этот процесс повторяется несколько раз с различными частями данных.
          <ul>
            <li><b>K-fold кросс-валидация:</b> Данные делятся на K частей. Модель обучается на K-1 частях и проверяется на оставшейся части. Процесс повторяется K раз, и результаты усредняются.</li>
            <li><b>Преимущества:</b> Обеспечивает более надежную оценку модели, снижает влияние случайности в разделении данных.</li>
            <li><b>Недостатки:</b> Требует больше вычислительных ресурсов и времени.</li>
          </ul>
        </li>
        <li>
          <b>Рандомизированное разделение (Randomized Split)</b><br>
          Данные случайным образом разделяются на обучающую и валидационную выборки. Этот метод прост и эффективен, но может быть подвержен случайным отклонениям.
          <ul>
            <li><b>Преимущества:</b> Легкость реализации.</li>
            <li><b>Недостатки:</b> Может привести к неравномерному распределению данных, особенно при небольших выборках.</li>
          </ul>
        </li>
      </ol>
      <br>
      <ul><b>Обучение модели</b>
        <li>
          <b>Этапы обучения модели</b>
          <ol>
            <li><b>Инициализация:</b> Задание начальных значений параметров модели.</li>
            <li><b>Прямое распространение (Forward Propagation):</b> Вычисление предсказаний модели для данных.</li>
            <li><b>Вычесление ошибки (Loss Calculation):</b> Оценка разницы между предсказаниями модели и истинными значениями.</li>
            <li><b>Обратное распространение (Backpropagation):</b> Вычисление градиентов функции потерь по параметрам модели.</li>
            <li><b>Обновление параметров (Parameter Update):</b> Регулировка параметров модели с использованием оптимизатора.</li>
            <li><b>Повторение:</b> Процесс повторяется для каждой итерации (эпохи) обучения до достижения заданного числа эпох или остановки по другим критериям.</li>
          </ol>
        </li>
        <li>
          <b>Мониторинг процесса обучения</b>
          <ol>
            <li><b>Функция потерь (Loss Function):</b> Оценка ошибки модели на каждой эпохе обучения</li>
            <li><b>Метрики (Metrics):</b> Дополнительные метрики, такие как точность (accuracy), F1-score, ROC-AUC и другие, для оценки качества модели.</li>
          </ol>
        </li>
      </ul>
      <br><br>
      <p>Обучение нейронной сети включает в себя правильное разделение данных на выборки, оптимизацию модели с использованием функции потерь и оптимизаторов, а также мониторинг процесса обучения с помощью метрик и валидации. Эти этапы позволяют создать модель, которая хорошо обобщает на новых данных и минимизирует ошибки на обучающих данных.</p>
    </div>
  </details>

  <!-- 6 -->
  <details class="details">
    <summary class="details__title">Задача классификации. Формирование выборки, особенности построения архитектур НС.
    </summary>
    <div class="details__content">
      <p>Задача классификации — это один из основных типов задач в машинном обучении, где цель состоит в том, чтобы определить метку класса для входных данных. Классификация находит применение в таких областях, как распознавание образов, медицинская диагностика, фильтрация спама, анализ текста и многие другие.</p>
      <br>
      <ol><b>Формирование выборки</b><br>Для успешного решения задачи классификации необходимо правильно сформировать выборку данных. Процесс включает несколько этапов:
        <li>
          <b>Сбор данных</b><br>Данные могут быть получены из различных источников, таких как базы данных, веб-скрейпинг, сенсоры и т.д. Важно, чтобы данные были репрезентативными и содержали достаточное количество примеров для каждого класса.
        </li>
        <li>
          <b>Подготовка данных</b><br>На этом этапе данные обрабатываются для приведения их к виду, пригодному для обучения модели:
          <ul>
            <li><b>Очистка данных:</b> Удаление или коррекция пропущенных, аномальных и дублирующихся значений.</li>
            <li><b>Нормализация и стандартизация:</b> Приведение значений признаков к одному масштабу для улучшения сходимости алгоритма.</li>
            <li><b>Кодирование категориальных признаков:</b> Преобразование категориальных данных в числовые (например, с помощью one-hot encoding).</li>
          </ul>
        </li>
        <li>
          <b>Разделение данных</b><br>Для оценки производительности модели данные делятся на обучающую, валидационную и тестовую выборки:
          <ul>
            <li><b>Обучающая выборка:</b> Используется для обучения модели (обычно 70-80% данных).</li>
            <li><b>Валидационная выборка:</b> Используется для настройки гиперпараметров и предотвращения переобучения (10-15% данных).</li>
            <li><b>Тестовая выборка:</b> Используется для окончательной оценки модели (10-15% данных).</li>
          </ul>
        </li>
        <li>
          <b>Балансировка данных</b><br>В случае несбалансированных классов необходимо принять меры для улучшения производительности модели:
          <ul>
            <li><b>Увеличение выборки (Oversampling):</b> Искусственное увеличение количества примеров меньшего класса (например, с помощью SMOTE).</li>
            <li><b>Уменьшение выборки (Undersampling):</b> Уменьшение количества примеров большего класса.</li>
            <li><b>Создание синтетических данных:</b> Генерация новых примеров данных.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <ol><b>Особенности построения архитектур нейронных сетей для классификации</b><br>При построении архитектуры нейронной сети для задачи классификации необходимо учитывать несколько ключевых аспектов.
        <li>
          <b>Выбор типа нейронной сети</b>
          <ul>
            <li><b>Полносвязные сети (Dense или Fully Connected Layers):</b> Подходят для работы с табличными данными.</li>
            <li><b>Сверточные нейронные сети (CNN):</b> Эффективны для задач, связанных с изображениями.</li>
            <li><b>Рекуррентные нейронные сети (RNN) и их варианты (LSTM, GRU):</b> Используются для последовательных данных, таких как текст или временные ряды.</li>
          </ul>
        </li>
        <li>
          <b>Структура сети</b>
          <ul>
            <li><b>Количество слоев:</b> Глубина сети определяется сложностью задачи. Для простых задач может быть достаточно нескольких слоев, в то время как для более сложных задач требуется более глубокая сеть.</li>
            <li><b>Количество нейронов:</b> Количество нейронов в каждом слое также влияет на способность модели к обучению. Оно должно быть достаточно большим для захвата важной информации, но не слишком большим, чтобы избежать переобучения.</li>
          </ul>
        </li>
        <li>
          <b>Активационные функции</b>
          <ul>
            <li><b>ReLU (Rectified Linear Unit):</b> Часто используется в скрытых слоях, поскольку помогает справляться с проблемой исчезающего градиента.</li>
            <li><b>Sigmoid и Softmax:</b> Используются в выходном слое для бинарной и многоклассовой классификации соответственно.</li>
          </ul>
        </li>
        <li>
          <b>Регуляризация</b><br>Регуляризация помогает предотвратить переобучение и улучшает обобщающую способность модели:
          <ul>
            <li><b>Dropout:</b> Случайное выключение нейронов во время обучения.</li>
            <li><b>L1 и L2 регуляризация:</b> Добавление штрафов к функции потерь за большие веса.</li>
          </ul>
        </li>
        <li>
          <b>Оптимизаторы</b>
          <ul>
            <li><b>Adam:</b> Популярный оптимизатор, который адаптирует скорость обучения для каждого параметра.</li>
            <li><b>SGD (Stochastic Gradient Descent):</b> Классический метод, который может быть улучшен с помощью момента или адаптивных методов.</li>
          </ul>
        </li>
        <li>
          <b>Гиперпараметры</b>
          <ul>
            <li><b>Скорость обучения (Learning Rate):</b> Определяет размер шага при обновлении параметров модели.</li>
            <li><b>Размер пакета (Batch Size):</b> Количество примеров, используемых для одного шага обновления параметров.</li>
          </ul>
        </li>
      </ol>
      <br><br><p>Решение задачи классификации включает в себя правильное формирование выборки данных и построение соответствующей архитектуры нейронной сети. Важными аспектами являются балансировка данных, выбор типа нейронной сети, структура сети, активационные функции, регуляризация, оптимизаторы и настройка гиперпараметров. Правильное выполнение всех этих шагов позволяет создать эффективную модель, способную точно классифицировать новые данные.</p>
    </div>
  </details>

  <!-- 7 -->
  <details class="details">
    <summary class="details__title">Переобучение нейронной сети. Причины. Способы борьбы.</summary>
    <div class="details__content">
      <p>Переобучение (overfitting) — это ситуация, когда нейронная сеть слишком хорошо подстраивается под обучающие данные, включая шум и случайные колебания, и демонстрирует плохую обобщающую способность на новых, невиданных данных. Это приводит к высокой точности на обучающих данных, но низкой на валидационных и тестовых.</p>
      <br>
      <ol><b>Причины переобучения</b>
        <li><b>Сложность модели:</b> Слишком сложная модель с большим числом параметров может запомнить обучающие данные, включая шум.</li>
        <li><b>Недостаток данных:</b> Малое количество обучающих данных увеличивает риск запоминания вместо обобщения.</li>
        <li><b>Шум в данных:</b> Наличие шумовых или нерепрезентативных данных в обучающей выборке.</li>
        <li><b>Неправильная регуляризация:</b> Отсутствие или недостаточная регуляризация может позволить модели слишком точно подстраиваться под обучающие данные</li>
      </ol>
      <br><br>
      <ol><b>Способы борьбы с переобучением</b>
        <li>
          <b>Увеличение объема данных</b>
          <ul><b>Сбор дополнительных данных:</b> Больше данных позволяет модели лучше обобщать.<br>Методы:
            <li><b>Сбор новых данных:</b> Добавление новых примеров из различных источников.</li>
            <li><b>Аугментация данных (Data Augmentation):</b> Создание новых примеров из существующих данных (особенно в задачах компьютерного зрения).</li>
          </ul>
        </li>
        <li>
          <b>Регуляризация</b>
          <ul><b>L1 и L2 регуляризация:</b> Добавление штрафов за большие значения весов к функции потерь.
            <li>L2 регуляризация (Ridge): Loss = Loss + 𝜆∑𝑤^2</li>
            <li>L1 регуляризация (Lasso): Loss = Loss + λ∑|w|</li>
          </ul>
          <ul><b>Dropout:</b> Случайное отключение нейронов в слое во время обучения.
            <li>Пример: В каждом обновлении случайно выключается определенный процент нейронов, предотвращая их совместное использование.</li>
          </ul>
        </li>
        <li>
          <b>Уменьшение сложности модели</b>
          <ul><b>Сокращение числа параметров:</b> Уменьшение числа слоев или нейронов в сети.
            <li><b>Меньше слоев:</b> Уменьшение глубины сети.</li>
            <li><b>Меньше нейронов:</b> Уменьшение числа нейронов в каждом слое.</li>
          </ul>
        </li>
        <li>
          <b>Ранняя остановка (Early Stopping)</b>
          <ul><b>Остановка обучения при ухудшении валидационной ошибки:</b> Мониторинг валидационной ошибки и остановка, если она начинает увеличиваться.
            <li>Использование колбэка EarlyStopping в Keras: <code>early_stopping = EarlyStopping(monitor='val_loss', patience=5)</code></li>
          </ul>
        </li>
        <li>
          <b>Кросс-валидация (Cross-Validation)</b>
          <ul><b>Разделение данных на несколько частей:</b> Использование разных частей данных для обучения и валидации на каждом этапе.
            <li><b>K-fold кросс-валидация:</b> Данные делятся на K частей, и модель обучается K раз, каждый раз используя разные части для обучения и валидации.</li>
            <li>
              <code>
                &nbsp;&nbsp;&nbsp;&nbsp;from sklearn.model_selection import KFold <br>
                <br>
                &nbsp;&nbsp;&nbsp;&nbsp;kf = KFold(n_splits=5) <br>
                &nbsp;&nbsp;&nbsp;&nbsp;for train_index, val_index in kf.split(X): <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X_train, X_val = X[train_index], X[val_index] <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y_train, y_val = y[train_index], y[val_index] <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.fit(X_train, y_train, validation_data=(X_val, y_val))
              </code>
            </li>
          </ul>
        </li>
        <li>
          <b>Добавление шума к данным</b>
          <ul><b>Шум в обучающих данных:</b> Добавление шума к входным данным для увеличения их вариативности.
            <li><b>Гауссов шум (Gaussian Noise):</b> Добавление случайного шума к входным данным.</li>
            <li>
              <code>
                &nbsp;&nbsp;&nbsp;&nbsp;from tensorflow.keras.layers import GaussianNoise <br>
                <br>
                &nbsp;&nbsp;&nbsp;&nbsp;model.add(GaussianNoise(0.1))  # Добавление шума с стандартным отклонением 0.1
              </code>
            </li>
          </ul>
        </li>
      </ol>
      <br><br>
      <p>Переобучение является одной из главных проблем в обучении нейронных сетей, однако существует множество методов для его предотвращения. Ключевыми методами являются увеличение объема данных, регуляризация, уменьшение сложности модели, ранняя остановка и кросс-валидация. Применение этих методов помогает улучшить обобщающую способность модели и добиться лучшего качества предсказаний на новых данных.</p>
    </div>
  </details>

  <!-- 8 -->
  <details class="details">
    <summary class="details__title">Особенности построения моделей с помощью Sequential и FunctionalAPI.</summary>
    <div class="details__content">
      <p><b>Sequential API</b></p>
      <p>Sequential API в Keras предоставляет простой и интуитивно понятный способ создания моделей, где слои следуют друг за другом. Этот метод удобен для построения простых моделей, таких как многослойные перцептроны или базовые сверточные сети. Sequential API идеально подходит для тех случаев, когда структура модели является линейной, то есть данные проходят через слои последовательно без разветвлений и объединений. Этот подход прост в использовании и хорошо подходит для начинающих, так как требует минимальных усилий для понимания и реализации.</p>
      <br>
      <p><b>Functional API</b></p>
      <p>Functional API предлагает большую гибкость и позволяет создавать сложные модели с нелинейными структурами, включая модели с несколькими входами и выходами, а также с ветвлениями и объединениями. В отличие от Sequential API, Functional API позволяет точно контролировать потоки данных и связи между слоями, что делает его идеальным для сложных архитектур. С Functional API вы можете свободно комбинировать слои и определять, как данные будут проходить через модель. Этот подход особенно полезен для реализации таких сложных архитектур, как остаточные сети (ResNet), сетевые сети (Inception) и других сложных структур.</p>
      <br>
      <p><b>Применение и гибкость</b></p>
      <p>Functional API позволяет реализовывать сложные архитектуры, что делает его более гибким инструментом по сравнению с Sequential API. Например, вы можете легко создать модель с несколькими входами и выходами, объединить или разветвить потоки данных, а также повторно использовать один и тот же слой в нескольких местах модели. Однако, если ваша задача требует построения простой линейной модели, такой как многослойный перцептрон или простая сверточная нейронная сеть, Sequential API будет более подходящим выбором из-за его простоты и удобства.</p>
      <br>
      <p><b>Заключение</b></p>
      <p>Sequential API и Functional API в Keras предоставляют различные уровни гибкости для построения нейронных сетей. Sequential API является отличным выбором для простых, линейных моделей благодаря своей простоте и интуитивно понятному интерфейсу. В то время как Functional API предоставляет мощные инструменты для создания сложных, нелинейных архитектур и позволяет реализовывать более гибкие и продвинутые модели. Понимание этих двух подходов поможет вам выбрать наиболее подходящий инструмент для решения конкретной задачи машинного обучения.</p>
      <br><br>
      <ol><b>Практические примеры использования</b>
        <li>
          <b>Sequential API:</b>
          <ul>
            <li>Простые модели классификации изображений с несколькими сверточными и плотными слоями.</li>
            <li>Многослойные перцептроны для задач регрессии и классификации.</li>
          </ul>
        </li>
        <li>
          <b>Functional API:</b>
          <ul>
            <li>Сложные архитектуры, такие как ResNet, где необходимы остаточные соединения.</li>
            <li>Модели внимания, где требуется динамическое взвешивание частей входных данных.</li>
            <li>Автоэнкодеры для задач сжатия данных и аномалий.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <p><b>Совместное использование Sequential и Functional API</b></p><p>Иногда может быть полезно комбинировать Sequential и Functional API. Например, можно создать части модели с помощью Sequential API и затем интегрировать их в более сложную архитектуру с Functional API. Это позволяет достичь баланса между простотой и гибкостью.</p>
      <br>
      <ol><b>Примеры из реальной жизни</b>
        <li><b>Sequential API</b> часто используется для обучения студентов и начинающих исследователей, предоставляя им простой способ изучения основных концепций нейронных сетей.</li>
        <li><b>Functional API</b> используется в промышленных приложениях и исследовательских проектах, где требуется высокая гибкость и способность адаптироваться к сложным и нестандартным задачам.</li>
      </ol>
    </div>
  </details>

  <!-- 9 -->
  <details class="details">
    <summary class="details__title">Линейный слой Dense. Устройство слоя.</summary>
    <div class="details__content">
      <p><b>Основы линейного слоя Dense</b></p>
      <p>Линейный слой, также известный как плотный слой (Dense), является одним из основных строительных блоков нейронных сетей. В Keras и других библиотеке машинного обучения слой Dense выполняет линейное преобразование входных данных с добавлением смещения (bias) и применением функции активации.</p>
      <br>
      <p>Основное уравнение, описывающее операцию слоя Dense, можно представить следующим образом: <br><code>y = f(W*x + b)</code></p>
      <p>где:</p>
      <ul>
        <li>x — входной вектор,</li>
        <li>W — матрица весов,</li>
        <li>b — вектор смещений,</li>
        <li>f — функция активации,</li>
        <li>y — выходной вектор.</li>
      </ul>
      <br><br>
      <ol><b>Устройство слоя Dense</b>
        <li><b>Входные данные:</b> <br>Входные данные слоя Dense могут быть вектором или матрицей. Вектор используется для работы с одномерными данными, такими как числовые признаки, тогда как матрица применяется для двумерных данных, таких как изображения (после предварительной обработки).</li>
        <li><b>Матрица весов:</b> <br>Матрица весов W представляет собой набор параметров, которые обучаются в процессе тренировки модели. Размерность матрицы зависит от числа входных и выходных нейронов. Для слоя Dense с n входами и m выходами матрица весов имеет размерность n*m.</li>
        <li><b>Вектор смещений:</b> <br>Вектор смещений b добавляется к результату умножения входных данных на матрицу весов. Этот вектор также является параметром, который обучается. Размерность вектора смещений соответствует числу выходных нейронов.</li>
        <li><b>Функция активации:</b> <br>Функция активации f применяется к линейному преобразованию входных данных. Она добавляет нелинейность в модель, что позволяет решать более сложные задачи. Наиболее часто используемые функции активации включают ReLU (Rectified Linear Unit), сигмоидальную функцию и гиперболический тангенс (tanh).</li>
      </ol>
      <br><br>
      <p><b>Работа слоя Dense в нейронной сети</b></p>
      <p>Когда входной вектор поступает на слой Dense, он умножается на матрицу весов W, затем к результату добавляется вектор смещений b. Полученное значение передается через функцию активации f, которая вводит нелинейность. Выходные значения этого процесса передаются на следующий слой или являются окончательным результатом сети.</p>
      <br>
      <p><b>Обучение слоя Dense</b></p>
      <p>В процессе обучения нейронной сети значения матрицы весов W и вектора смещений b корректируются таким образом, чтобы минимизировать функцию потерь, которая измеряет расхождение между предсказанными и истинными значениями. Для этого используются различные оптимизационные алгоритмы, такие как градиентный спуск.</p>
      <br><p><b>Роль слоя Dense в нейронной сети</b></p>
      <p>Слой Dense играет ключевую роль в нейронных сетях, особенно в многослойных перцептронах и глубоких нейронных сетях. Он обеспечивает связь между нейронами и позволяет модели захватывать сложные зависимости в данных. В сочетании с различными функциями активации и другими слоями, такими как сверточные или рекуррентные, слой Dense помогает строить мощные модели для решения широкого спектра задач, включая классификацию, регрессию и кластеризацию.</p>
      <br>
      <p>Линейный слой Dense является фундаментальным компонентом нейронных сетей. Он выполняет линейное преобразование входных данных, добавляет смещение и применяет функцию активации, создавая сложные нелинейные модели. Понимание устройства и работы слоя Dense является важным шагом в изучении и разработке нейронных сетей.</p>
    </div>
  </details>

  <!-- 10 -->
  <details class="details">
    <summary class="details__title">Сверточный слой Conv2D. Основные параметры слоя.</summary>
    <div class="details__content">
      <p>Сверточный слой (Conv2D) является основным компонентом сверточных нейронных сетей (CNN), которые широко используются для обработки изображений и других двумерных данных. Слой Conv2D выполняет свертку входных данных с набором фильтров (ядра), что позволяет извлекать локальные особенности из данных, такие как края, текстуры и паттерны.</p>
      <br>
      <ol><b>Основные параметры слоя Conv2D</b>
        <li>
          <b>filters (фильтры):</b>
          <ul>
            <li><b>Описание:</b> Количество фильтров (ядер свертки) в слое</li>
            <li><b>Значение:</b> Положительное целое число.</li>
            <li><b>Роль:</b> Каждый фильтр извлекает различные особенности из входных данных. Большее количество фильтров позволяет извлекать большее количество разнообразных признаков, но также увеличивает вычислительную сложность.</li>
          </ul>
        </li>
        <li>
          <b>kernel_size (размер ядра):</b>
          <ul>
            <li><b>Описание:</b> Размер каждого фильтра (ядра свертки).</li>
            <li><b>Значение:</b> Кортеж из двух целых чисел (высота, ширина) или одно целое число (если высота и ширина равны).</li>
            <li><b>Роль:</b> Размер ядра определяет область восприятия фильтра. Меньшие ядра лучше подходят для извлечения мелких особенностей, тогда как большие ядра могут захватывать более глобальные паттерны.</li>
          </ul>
        </li>
        <li>
          <b>strides (шаги):</b>
          <ul>
            <li><b>Описание:</b> Шаги свертки по высоте и ширине.</li>
            <li><b>Значение:</b> Кортеж из двух целых чисел (вертикальный шаг, горизонтальный шаг) или одно целое число (если шаги одинаковы).</li>
            <li><b>Роль:</b> Шаг определяет, насколько далеко перемещается ядро свертки по входным данным. Большие шаги уменьшают размер выходного тензора, но могут пропускать некоторые особенности.</li>
          </ul>
        </li>
        <li>
          <b>padding (отступы):</b>
          <ul>
            <li><b>Описание:</b> Способ обработки краев входных данных.</li>
            <li><b>Значение:</b> Строка 'valid' (без отступов) или 'same' (с отступами, чтобы сохранить размер входа).</li>
            <li><b>Роль:</b> 'valid' приводит к уменьшению размера выходного тензора, тогда как 'same' сохраняет размер, добавляя нулевые отступы по краям.</li>
          </ul>
        </li>
        <li>
          <b>activation (функция активации):</b>
          <ul>
            <li><b>Описание:</b> Функция активации, применяемая к выходу свертки.</li>
            <li><b>Значение:</b> Строка, определяющая тип активации (например, 'relu', 'sigmoid', 'tanh').</li>
            <li><b>Роль:</b> Добавление нелинейности в модель, что позволяет извлекать более сложные особенности.</li>
          </ul>
        </li>
        <li>
          <b>input_shape (форма входных данных):</b>
          <ul>
            <li><b>Описание:</b> Форма входных данных.</li>
            <li><b>Значение:</b> Кортеж, определяющий размерность входных данных (высота, ширина, количество каналов).</li>
            <li><b>Роль:</b> Указывается только для первого слоя в модели, чтобы определить размерность входного тензора.</li>
          </ul>
        </li>
        <li>
          <b>kernel_initializer (инициализация весов):</b>
          <ul>
            <li><b>Описание:</b> Метод инициализации весов ядра свертки.</li>
            <li><b>Значение:</b> Строка, определяющая метод инициализации (например, 'glorot_uniform', 'he_normal').</li>
            <li><b>Роль:</b> Выбор подходящего метода инициализации помогает улучшить сходимость и качество обучения модели.</li>
          </ul>
        </li>
        <li>
          <b>bias_initializer (инициализация смещений):</b>
          <ul>
            <li><b>Описание:</b> Метод инициализации смещений.</li>
            <li><b>Значение:</b> Строка, определяющая метод инициализации (например, 'zeros', 'ones').</li>
            <li><b>Роль:</b> Инициализация смещений влияет на начальные значения смещений, которые затем корректируются в процессе обучения.</li>
          </ul>
        </li>
        <li>
          <b>kernel_regularizer (регуляризация весов):</b>
          <ul>
            <li><b>Описание:</b> Регуляризатор, применяемый к весам ядра свертки.</li>
            <li><b>Значение:</b> Объект регуляризации (например, tf.keras.regularizers.l2(0.01)).</li>
            <li><b>Роль:</b> Регуляризация помогает предотвратить переобучение, добавляя штраф за сложность модели.</li>
          </ul>
        </li>
        <li>
          <b>bias_regularizer (регуляризация смещений):</b>
          <ul>
            <li><b>Описание:</b> Регуляризатор, применяемый к смещениям.</li>
            <li><b>Значение:</b> Объект регуляризации.</li>
            <li><b>Роль:</b> Аналогично регуляризации весов, помогает предотвратить переобучение.</li>
          </ul>
        </li>
      </ol><br><br>
      <p><b>Работа слоя Conv2D в нейронной сети</b></p>
      <p>Слой Conv2D обрабатывает входные данные, применяя свертку с заданными фильтрами. Для каждого фильтра ядро перемещается по входному тензору, вычисляя свертку (линейное преобразование с последующей нелинейностью) для каждой позиции. Результаты сверток для всех фильтров объединяются, образуя выходной тензор.</p>
      <br>
      <p><b>Применение сверточных слоев</b></p>
      <p>Сверточные слои широко используются в задачах компьютерного зрения, таких как распознавание образов, классификация изображений, сегментация, детекция объектов и многие другие. Они также находят применение в обработке сигналов, аудио и текстовых данных.</p>
      <br>
      <p>Сверточный слой Conv2D является мощным инструментом для извлечения особенностей из двумерных данных. Понимание основных параметров слоя Conv2D, таких как количество фильтров, размер ядра, шаги, отступы и функции активации, позволяет эффективно настраивать и использовать этот слой в нейронных сетях для решения различных задач.</p>
    </div>
  </details>

  <!-- 11 -->
  <details class="details">
    <summary class="details__title">Pooling-слои.(Определения, назначения, принцип работы, основные параметры, варианты и правила применения, основные параметры)</summary>
    <div class="details__content">
      <p><b>Определение и назначение</b></p>
      <p>Pooling-слои (слои подвыборки) используются в сверточных нейронных сетях (CNN) для уменьшения размерности входных данных, уменьшения вычислительной сложности и извлечения устойчивых признаков. Эти слои снижают пространственные размеры (высоту и ширину) входных данных, сохраняя наиболее важную информацию. Pooling помогает делать модель более инвариантной к небольшим сдвигам и искажениям.</p>
      <br>
      <p><b>Принцип работы</b></p>
      <p>Pooling-слои выполняют подвыборку на входных данных с использованием фиксированного окна, которое перемещается по входному тензору. В каждом положении окна вычисляется агрегатное значение, например, максимальное значение (max pooling) или среднее значение (average pooling), которое затем становится частью выходного тензора.</p>
      <br>
      <ol><b>Основные параметры</b>
        <li>
          <b>pool_size (размер окна подвыборки):</b>
          <ul>
            <li><b>Описание:</b> Размер окна подвыборки по высоте и ширине.</li>
            <li><b>Значение:</b> Кортеж из двух целых чисел (высота, ширина) или одно целое число (если высота и ширина равны).</li>
            <li><b>Роль:</b> Определяет область, в которой будет производиться подвыборка. Например, размер (2, 2) означает, что окно подвыборки охватывает 2x2 области входного тензора.</li>
          </ul>
        </li>
        <li>
          <b>strides (шаги):</b>
          <ul>
            <li><b>Описание:</b> Шаги перемещения окна подвыборки по высоте и ширине.</li>
            <li><b>Значение:</b> Кортеж из двух целых чисел (вертикальный шаг, горизонтальный шаг) или одно целое число (если шаги одинаковы).</li>
            <li><b>Роль:</b> Определяет, насколько далеко окно подвыборки перемещается по входным данным. Если шаги меньше размера окна, происходит перекрытие подвыборки.</li>
          </ul>
        </li>
        <li>
          <b>padding (отступы):</b>
          <ul>
            <li><b>Описание:</b> Способ обработки краев входных данных.</li>
            <li><b>Значение:</b> Строка 'valid' (без отступов) или 'same' (с отступами, чтобы сохранить размер входа).</li>
            <li><b>Роль:</b> 'valid' приводит к уменьшению размера выходного тензора, тогда как 'same' сохраняет размер, добавляя нулевые отступы по краям.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Варианты и правила применения</b>
        <li>
          <b>Max Pooling (максимальная подвыборка):</b>
          <ul>
            <li><b>Описание:</b> В каждой области окна подвыборки выбирается максимальное значение.</li>
            <li><b>Применение:</b> Часто используется для извлечения ярко выраженных признаков, таких как края и углы.</li>
            <li><b>Пример:</b> MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')</li>
          </ul>
        </li>
        <li>
          <b>Average Pooling (средняя подвыборка):</b>
          <ul>
            <li><b>Описание:</b> В каждой области окна подвыборки вычисляется среднее значение.</li>
            <li><b>Применение:</b> Используется для уменьшения шумов и более гладкой подвыборки признаков.</li>
            <li><b>Пример:</b> AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')</li>
          </ul>
        </li>
        <li>
          <b>Global Pooling (глобальная подвыборка):</b>
          <ul>
            <li><b>Описание:</b> Применяется ко всему тензору, вычисляя одно агрегатное значение для каждой карты признаков.</li>
            <li><b>Применение:</b> Часто используется перед полностью связанными (Dense) слоями для уменьшения размерности и подготовки признаков к классификации.</li>
            <li><b>Пример:</b> GlobalMaxPooling2D(), GlobalAveragePooling2D()</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Принципы применения</b>
        <li><b>Уменьшение размерности:</b> Pooling-слои помогают уменьшить пространственные размеры данных, снижая вычислительную сложность последующих слоев.</li>
        <li><b>Извлечение устойчивых признаков:</b> Pooling делает модель более инвариантной к небольшим сдвигам и искажениям, улучшая способность модели к обобщению.</li>
        <li><b>Комбинирование со сверточными слоями:</b> Pooling-слои часто чередуются со сверточными слоями, чтобы последовательно уменьшать размерность данных и извлекать признаки на различных уровнях абстракции.</li>
        <li><b>Регулирование размеров данных:</b> Правильный выбор размеров окна подвыборки и шагов помогает контролировать степень уменьшения размерности и избегать чрезмерного уменьшения.</li>
      </ol><br><br>
      <p>Pooling-слои являются важным компонентом сверточных нейронных сетей, обеспечивая уменьшение размерности и извлечение устойчивых признаков из входных данных. Понимание различных типов pooling-слоев, их параметров и принципов применения помогает эффективно использовать эти слои для построения мощных моделей для обработки изображений и других задач, связанных с анализом двумерных данных.</p>
    </div>
  </details>

  <!-- 12 -->
  <details class="details">
    <summary class="details__title">Tokenizer. Применение, основные параметры.</summary>
    <div class="details__content">
      <p>`Tokenizer` — это инструмент, предоставляемый библиотекой Keras для предварительной обработки текстовых данных перед подачей их в модели машинного обучения. Он решает задачу преобразования текста в числовые последовательности, которые могут быть использованы нейронными сетями. Токенизатор помогает подготовить текстовые данные для обучения, обработки и анализа в рамках задач обработки естественного языка (NLP).</p>
      <br>
      <ol><b>Основные этапы применения Tokenizer</b>
        <li>
          <b>Токенизация</b>
          <ul>
            <li>Разделение текста на отдельные слова или символы (токены).</li>
            <li>Преобразование этих токенов в числовые значения.</li>
          </ul>
        </li>
        <li>
          <b>Создание словаря</b>
          <ul>
            <li>Построение словаря, содержащего уникальные токены и их соответствующие числовые представления</li>
            <li>Словарь сопоставляет каждому слову (или символу) уникальный индекс</li>
          </ul>
        </li>
        <li>
          <b>Преобразование текста</b>
          <ul>
            <li>Преобразование текстовых данных в последовательности чисел на основе словаря</li>
            <li>Применение паддинга и усечения для приведения всех последовательностей к одной длине</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Основные параметры</b>
        <li>
          <b>num_words:</b>
          <ul>
            <li><b>Описание:</b> Максимальное количество слов, которые будут учитываться в словаре.</li>
            <li><b>Значение:</b> Положительное целое число.</li>
            <li><b>Роль:</b> Ограничивает размер словаря, сохраняя только наиболее часто встречающиеся слова. Это помогает избежать работы с редкими словами, которые могут увеличить вычислительную сложность и снизить качество модели.</li>
          </ul>
        </li>
        <li>
          <b>filters:</b>
          <ul>
            <li><b>Описание:</b> Строка, содержащая символы, которые будут удалены из текста.</li>
            <li><b>Значение:</b> По умолчанию !"#$%&()*+,-./:;<=>?@[\\]^_{|}~\t\n`.</li>
            <li><b>Роль:</b> Удаляет указанные символы из текста перед токенизацией, что помогает очистить данные от ненужных знаков препинания и специальных символов.</li>
          </ul>
        </li>
        <li>
          <b>lower:</b>
          <ul>
            <li><b>Описание:</b> Преобразовывать ли текст в нижний регистр.</li>
            <li><b>Значение:</b> Булево значение (True или False).</li>
            <li><b>Роль:</b> Приведение текста к нижнему регистру для обеспечения консистентности. Это полезно, чтобы слова, написанные в разном регистре (например, "Пример" и "пример"), не считались разными токенами.</li>
          </ul>
        </li>
        <li>
          <b>split:</b>
          <ul>
            <li><b>Описание:</b> Символ, используемый для разделения слов.</li>
            <li><b>Значение:</b> Строка (по умолчанию пробел ' ').</li>
            <li><b>Роль:</b> Определяет разделитель для токенизации текста. Можно использовать другой символ, например, запятую, если текст представляет собой список значений, разделенных запятыми.</li>
          </ul>
        </li>
        <li>
          <b>char_level:</b>
          <ul>
            <li><b>Описание:</b> Токенизировать ли на уровне символов.</li>
            <li><b>Значение:</b> Булево значение (True или False).</li>
            <li><b>Роль:</b> Определяет, будет ли токенизация проводиться на уровне символов вместо слов. Это полезно для задач, где необходимо анализировать структуру слов, такие как морфологический анализ или задачи распознавания именованных сущностей.</li>
          </ul>
        </li>
        <li>
          <b>oov_token:</b>
          <ul>
            <li><b>Описание:</b> Токен для слов, отсутствующих в словаре (out-of-vocabulary).</li>
            <li><b>Значение:</b> Строка или None.</li>
            <li><b>Роль:</b> Специальный токен для слов, которые не были встречены при обучении токенизатора. Это помогает модели справляться с новыми или редкими словами, которые не встречались в обучающем наборе данных.</li>
          </ul>
        </li>
      </ol><br>
      <p><b>Работа с Tokenizer</b></p>
      <br>
      <ol><b>Шаги использования Tokenizer</b>
        <li>
          <b>Создание объекта Tokenizer с заданными параметрами.</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;from keras.preprocessing.text import Tokenizer <br>
            &nbsp;&nbsp;&nbsp;&nbsp;tokenizer = Tokenizer(num_words=10000)
          </code>
        </li>
        <li>
          <b>Обучение токенизатора на текстовых данных:</b> Токенизатор анализирует текст и строит словарь частотности слов. <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;texts = ["Пример текста для токенизации", "Еще один пример текста"] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;tokenizer.fit_on_texts(texts)
          </code>
        </li>
        <li>
          <b>Преобразование текстов в последовательности чисел: </b>Текстовые данные преобразуются в последовательности чисел на основе словаря. <br>
          <code>&nbsp;&nbsp;&nbsp;&nbsp;sequences = tokenizer.texts_to_sequences(texts)</code>
        </li>
        <li>
          <b>Преобразование последовательностей обратно в текст: </b>Восстановление текстов из числовых последовательностей (для отладки и анализа). <br>
          <code>&nbsp;&nbsp;&nbsp;&nbsp;texts_back = tokenizer.sequences_to_texts(sequences)</code>
        </li>
      </ol><br><br>
      <ol><b>Дополнительные возможности и детали Tokenizer</b>
        <li>
          <b>Методы Tokenizer:</b>
          <ul>
            <li><b>fit_on_texts(texts):</b> Анализирует список текстов и строит внутренний словарь токенов. Этот метод создает индексы для каждого слова, основываясь на их частоте в текстах.</li>
            <li><b>texts_to_sequences(texts):</b> Преобразует список текстов в список последовательностей чисел, где каждое число представляет индекс токена в словаре.</li>
            <li><b>texts_to_matrix(texts, mode='binary'):</b> Преобразует тексты в матрицу (например, частотную или бинарную), где строки представляют тексты, а столбцы — токены.</li>
            <li><b>sequences_to_texts(sequences):</b> Преобразует список последовательностей чисел обратно в список текстов.</li>
            <li><b>sequences_to_matrix(sequences, mode='binary'):</b> Преобразует последовательности в матрицу аналогично texts_to_matrix.</li>
          </ul>
        </li>
        <li>
          <b>Типы матриц в методе texts_to_matrix:</b>
          <ul>
            <li><b>binary:</b> Матрица, где присутствие слова обозначается 1, а его отсутствие — 0.</li>
            <li><b>count:</b> Матрица с подсчетом количества появлений каждого слова в тексте.</li>
            <li><b>tfidf:</b> Матрица с TF-IDF значениями, где учитывается частота появления слова и обратная частота документа.</li>
            <li><b>freq:</b> Матрица с частотой появления слов в тексте.</li>
          </ul>
        </li>
        <li>
          <b>Работа с различными языками и кодировками:</b>
          <ul>
            <li>Токенизатор может работать с текстами на разных языках и с различными кодировками. Это важно для многокультурных и многоязычных приложений.</li>
          </ul>
        </li>
        <li>
          <b>Учет последовательностей слов:</b>
          <ul>
            <li>Tokenizer может использоваться для обработки не только отдельных слов, но и фраз или последовательностей слов, что полезно в задачах анализа последовательностей и временных рядов.</li>
          </ul>
        </li>
        <li>
          <b>Совместимость с другими инструментами NLP:</b>
          <ul>
            <li>Tokenizer легко интегрируется с другими библиотеками и инструментами для обработки естественного языка, такими как NLTK и spaCy. Это позволяет комбинировать его возможности с более продвинутыми техниками NLP.</li>
          </ul>
        </li>
        <li>
          <b>Обработка больших данных:</b>
          <ul>
            <li>Tokenizer можно применять для обработки больших корпусов текстов. Важно оптимизировать процесс, используя параметры num_words и oov_token, чтобы уменьшить размер словаря и ускорить обработку.</li>
          </ul>
        </li>
        <li>
          <b>Обратная совместимость и обновления:</b>
          <ul>
            <li>Keras и TensorFlow регулярно обновляют свои библиотеки, добавляя новые возможности и улучшая производительность. Текущие и будущие версии могут включать дополнительные параметры и методы для токенизации.</li>
          </ul>
        </li>
        <li>
          <b>Примеры практического использования:</b>
          <ul>
            <li><b>Анализ настроений:</b> Преобразование текстов отзывов пользователей в числовые последовательности для дальнейшего анализа настроений с использованием нейронных сетей.</li>
            <li><b>Чат-боты:</b> Обработка пользовательских запросов и генерация ответов в текстовом формате.</li>
            <li><b>Классификация текстов:</b> Подготовка текстовых данных для задач классификации, таких как определение темы или категории текста.</li>
            <li><b>Машинный перевод:</b> Преобразование текстов на одном языке в последовательности для дальнейшего перевода на другой язык с использованием моделей Seq2Seq.</li>
          </ul>
        </li>
      </ol><br>
      <p>Tokenizer в Keras — это мощный инструмент для предварительной обработки текстовых данных. Он предоставляет множество возможностей для гибкой и эффективной работы с текстами, что делает его незаменимым в задачах обработки естественного языка и машинного обучения. Разнообразие параметров и методов позволяет адаптировать его под конкретные нужды и задачи, обеспечивая высокое качество подготовки данных для моделей.</p>
    </div>
  </details>

  <!-- 13 -->
  <details class="details">
    <summary class="details__title">Параметризация текста BagOfWords.</summary>
    <div class="details__content">
      <p>Bag of Words (BoW) — это один из самых простых и широко используемых методов представления текстов в числовой форме, применяемый в задачах обработки естественного языка (NLP) и машинного обучения. Основная идея BoW заключается в том, чтобы представить текст как "мешок" слов, игнорируя порядок слов, синтаксис и даже грамматику. BoW используется для преобразования текстов в векторы фиксированной длины, что позволяет использовать их в моделях машинного обучения.</p>
      <ol><b>Основные этапы метода BoW</b>
        <li>
          <b>Токенизация текста:</b>
          <ul>
            <li>Процесс разбиения текста на отдельные слова или токены.</li>
            <li>Токены могут быть словами, символами или фразами в зависимости от задачи.</li>
            <li>Пример: предложение "машинное обучение это круто" будет токенизировано в ["машинное", "обучение", "это", "круто"].</li>
          </ul>
        </li>
        <li>
          <b>Создание словаря:</b>
          <ul>
            <li>Словарь (или лексикон) содержит все уникальные слова, найденные в корпусе текстов.</li>
            <li>Каждому уникальному слову присваивается уникальный индекс.</li>
            <li>Словарь может включать или исключать слова на основе их частоты (например, исключение редких слов или слов, встречающихся слишком часто, как стоп-слова)</li>
          </ul>
        </li>
        <li>
          <b>Построение векторов признаков:</b>
          <ul>
            <li>Каждое предложение или документ преобразуется в вектор, длина которого равна размеру словаря.</li>
            <li>Значения в векторе обычно представляют собой частоты появления слов в тексте, хотя возможны и другие варианты, такие как бинарные значения (присутствие/отсутствие слова).</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Модификации и улучшения BoW</b>
        <li>
          <b>Бинарное представление:</b>
          <ul>
            <li>Вместо подсчета частот слов используется бинарное значение: 1, если слово присутствует в тексте, и 0, если отсутствует.</li>
            <li>Это может быть полезно, когда важен факт наличия слова, а не его частота.</li>
          </ul>
        </li>
        <li>
          <b>TF-IDF (Term Frequency-Inverse Document Frequency):</b>
          <ul>
            <li>Модификация BoW, которая учитывает не только частоту слова в тексте, но и его значимость в корпусе.</li>
            <li><b>TF (частота термина):</b> количество появлений слова в документе.</li>
            <li><b>IDF (обратная частота документа):</b> логарифм от общего числа документов в корпусе, деленный на количество документов, содержащих это слово.</li>
            <li>TF-IDF помогает уменьшить влияние часто встречающихся слов, таких как "и", "в", "на", которые могут быть менее информативными.</li>
          </ul>
        </li>
      </ol><br><br>
      <ul><b>Преимущества и недостатки метода BoW</b>
        <li>
          <ul><b>Преимущества:</b>
            <li><b>Простота реализации:</b> BoW легко понять и внедрить, не требует сложных вычислений.</li>
            <li><b>Прозрачность:</b> Результирующие векторы легко интерпретировать.</li>
            <li><b>Совместимость:</b> Подходит для множества алгоритмов машинного обучения, таких как логистическая регрессия, SVM, наивный Байес и т.д.</li>
          </ul>
        </li>
        <li>
          <ul><b>Недостатки:</b>
            <li><b>Игнорирование порядка слов:</b> BoW не учитывает порядок слов, что может быть критическим для понимания контекста.</li>
            <li><b>Высокая размерность:</b> Размер векторов равен размеру словаря, что может приводить к проблемам с памятью и вычислительными ресурсами при работе с большими корпусами.</li>
            <li><b>Проблема синонимов и полисемии:</b> BoW не учитывает синонимы (разные слова с одинаковым значением) и полисемию (одно слово с разными значениями).</li>
            <li><b>Разреженность данных:</b> Большинство векторов будут содержать много нулей, так как в каждом тексте используется лишь небольшая часть словаря</li>
          </ul>
        </li>
      </ul><br><br>
      <ol><b>Применение BoW в реальных задачах</b>
        <li>
          <b>Классификация текстов:</b>
          <ul>
            <li>BoW часто используется для классификации текстов, таких как определение тематики, спам-фильтры и анализ настроений.</li>
            <li><b>Пример:</b> использование BoW для классификации новостей по категориям (спорт, политика, экономика и т.д.).</li>
          </ul>
        </li>
        <li>
          <b>Анализ настроений:</b>
          <ul>
            <li>Преобразование отзывов пользователей в векторы признаков для анализа положительных или отрицательных эмоций.</li>
            <li><b>Пример:</b> классификация отзывов на продукты как положительные или отрицательные.</li>
          </ul>
        </li>
        <li>
          <b>Информационный поиск:</b>
          <ul>
            <li>Представление документов и запросов в виде векторов для вычисления сходства и ранжирования результатов поиска.</li>
            <li><b>Пример:</b> поисковые системы используют BoW для индексации и поиска релевантных документов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Современные альтернативы BoW</b>
        <li>
          <b>Word Embeddings (встраивания слов):</b>
          <ul>
            <li>Методы, такие как Word2Vec, GloVe и FastText, создают плотные векторы для слов, которые учитывают семантические отношения между словами</li>
            <li>Встраивания слов представляют слова в многомерных пространствах, где семантически похожие слова имеют близкие вектора.</li>
          </ul>
        </li>
        <li>
          <b>Contextual Embeddings:</b>
          <ul>
            <li>Модели, такие как BERT и GPT, создают векторы для слов, учитывая их контекст в предложении.</li>
            <li>Эти методы позволяют моделям лучше понимать значения слов в зависимости от их окружения.</li>
          </ul>
        </li>
        <li>
          <b>N-grams:</b>
          <ul>
            <li>Вместо отдельных слов анализируются последовательности из N слов (биграммы, триграммы и т.д.), что позволяет учитывать некоторые аспекты порядка слов.</li>
            <li><b>Пример:</b> "машинное обучение" как биграмма будет представлено как отдельный токен, что помогает сохранить некоторый контекст.</li>
          </ul>
        </li>
      </ol><br>
      <p>Bag of Words (BoW) является фундаментальным методом параметризации текстов, который, несмотря на свои ограничения, остается важным и полезным инструментом в арсенале специалистов по обработке естественного языка и машинному обучению. Понимание его принципов, достоинств и недостатков, а также знание современных альтернатив позволяет эффективно решать широкий спектр задач, связанных с анализом текстов.</p>
    </div>
  </details>

  <!-- 14 -->
  <details class="details">
    <summary class="details__title">Embedding-слой. Основные параметры слоя.</summary>
    <div class="details__content">
      <p>Embedding-слой в нейронных сетях — это слой, который преобразует категориальные данные, такие как слова, в плотные векторы фиксированной размерности. Этот слой часто используется в задачах обработки естественного языка (NLP) для представления слов в виде векторов в многомерном пространстве, что позволяет моделям учитывать семантическую информацию.</p>
      <br>
      <p><b>Основная идея</b></p>
      <p>Embedding-слой берет на вход последовательность индексов (например, индексов слов) и отображает каждый индекс в плотный вектор фиксированной размерности. Эти векторы обычно обучаются вместе с нейронной сетью и оптимизируются таким образом, чтобы кодировать семантическую информацию о словах.</p>
      <br>
      <ol><b>Принцип работы</b>
        <li><b>Вход:</b> Последовательность индексов, представляющих слова.</li>
        <li><b>Выход:</b> Плотные векторы фиксированной размерности для каждого входного индекса.</li>
      </ol><br><br>
      <ol><b>Основные параметры Embedding-слоя</b>
        <li>
          <b>input_dim (размер входного словаря):</b>
          <ul>
            <li>Определяет количество уникальных слов или токенов, которые могут быть закодированы в векторы.</li>
            <li>Это число обычно равно размеру словаря + 1, где 1 добавляется для учета возможного токена "неизвестное слово".</li>
            <li>Например, если словарь содержит 10 000 уникальных слов, input_dim будет равно 10 001.</li>
          </ul>
        </li>
        <li>
          <b>output_dim (размерность векторов):</b>
          <ul>
            <li>Определяет размерность выходных векторов.</li>
            <li>Это число указывает, сколько чисел будет в векторе, представляющем каждое слово.</li>
            <li>Обычно выбирается в диапазоне от 50 до 300, в зависимости от задачи и объема данных.</li>
          </ul>
        </li>
        <li>
          <b>input_length (длина входной последовательности):</b>
          <ul>
            <li>Длина последовательности, которую будет принимать Embedding-слой.</li>
            <li>Это число указывает, сколько слов будет в каждой входной последовательности.</li>
            <li>Например, если модель принимает предложения длиной до 100 слов, input_length будет равно 100.</li>
          </ul>
        </li>
        <li>
          <b>embeddings_initializer (инициализация векторов):</b>
          <ul>
            <li>Способ инициализации весов Embedding-слоя.</li>
            <li>Можно использовать стандартные методы инициализации, такие как 'uniform' или 'normal', или специальные методы, разработанные для векторов встраивания, такие как Glorot или He.</li>
          </ul>
        </li>
        <li>
          <b>embeddings_regularizer (регуляризация векторов):</b>
          <ul>
            <li>Регуляризатор для векторов встраивания.</li>
            <li>Может использоваться для предотвращения переобучения</li>
            <li>Например, L1 или L2 регуляризация.</li>
          </ul>
        </li>
        <li>
          <b>embeddings_constraint (ограничения на векторы):</b>
          <ul>
            <li>Ограничения, накладываемые на векторы встраивания.</li>
            <li>Например, можно ограничить нормы векторов, чтобы они не росли слишком большими.</li>
          </ul>
        </li>
        <li>
          <b>mask_zero (маскирование нулей):</b>
          <ul>
            <li>Булевый параметр, который указывает, должны ли нулевые значения быть замаскированы.</li>
            <li>Это полезно при работе с последовательностями переменной длины, где нули используются для выравнивания последовательностей до одинаковой длины.</li>
            <li>Если mask_zero=True, слой будет игнорировать нулевые значения при обучении.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Пример использования Embedding-слоя</b>
        <li>
          <b>Входной слой:</b>
          <ul>
            <li>Embedding-слой используется сразу после слоя ввода, принимая индексы слов и преобразуя их в векторы.</li>
          </ul>
        </li>
        <li>
          <b>Включение в модель:</b>
          <ul>
            <li>Embedding-слой можно интегрировать в более сложные модели, такие как рекуррентные нейронные сети (RNN) или сверточные нейронные сети (CNN) для обработки текстов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Преимущества Embedding-слоя</b>
        <li>
          <b>Уменьшение размерности:</b>
          <ul>
            <li>Векторы встраивания позволяют представлять слова в пространстве меньшей размерности по сравнению с one-hot кодированием, что уменьшает размерность входных данных и улучшает производительность модели.</li>
          </ul>
        </li>
        <li>
          <b>Обучение полезных признаков:</b>
          <ul>
            <li>Векторы встраивания обучаются так, чтобы близкие по смыслу слова имели похожие векторы, что позволяет моделям лучше понимать семантические связи между словами.</li>
          </ul>
        </li>
        <li>
          <b>Универсальность:</b>
          <ul>
            <li>Embedding-слой можно использовать для любой категории данных, а не только для слов, что делает его универсальным инструментом для работы с категориальными признаками.</li>
          </ul>
        </li>
      </ol>
      <br>
      <p>Embedding-слой является важным компонентом современных моделей обработки естественного языка, предоставляя эффективный и гибкий способ представления категориальных данных. Понимание его параметров и принципов работы позволяет создавать мощные модели для анализа текстов и других задач, требующих представления категориальных данных в виде плотных векторов.</p>
    </div>
  </details>

  <!-- 15 -->
  <details class="details">
    <summary class="details__title">Задача регрессии. Примеры. Подготовка данных, принцип построения архитектур НС для решения задачи.</summary>
    <div class="details__content">
      <p>Регрессия — это тип задачи машинного обучения, где целью является предсказание непрерывного значения на основе входных данных. В отличие от классификации, где предсказываются категории, регрессия направлена на предсказание числовых величин.</p>
      <br>
      <ol><b>Примеры задач регрессии</b>
        <li>
          <b>Прогнозирование цен на недвижимость:</b>
          <ul>
            <li><b>Цель:</b> Предсказать стоимость дома на основе его характеристик (площадь, число комнат, расположение и т.д.).</li>
          </ul>
        </li>
        <li>
          <b>Прогнозирование спроса:</b>
          <ul>
            <li><b>Цель:</b> Оценить будущий спрос на продукт на основе исторических данных продаж, сезонности и других факторов.</li>
          </ul>
        </li>
        <li>
          <b>Анализ фондового рынка:</b>
          <ul>
            <li><b>Цель:</b> Предсказать будущую цену акции на основе исторических данных и макроэкономических показателей</li>
          </ul>
        </li>
        <li>
          <b>Предсказание погодных условий:</b>
          <ul>
            <li><b>Цель:</b> Прогнозировать температуру, осадки и другие метеорологические параметры.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Подготовка данных для регрессии</b>
        <li>
          <b>Сбор данных:</b>
          <ul>
            <li>Сбор релевантных данных, которые могут помочь в решении задачи регрессии.</li>
            <li>Источники данных могут быть разнообразными: базы данных, API, файлы CSV и т.д.</li>
          </ul>
        </li>
        <li>
          <b>Очистка данных:</b>
          <ul>
            <li>Обработка пропущенных значений.</li>
            <li>Удаление дубликатов.</li>
            <li>Исправление ошибок в данных.</li>
          </ul>
        </li>
        <li>
          <b>Обработка категориальных признаков:</b>
          <Ul>
            <li>Кодирование категориальных признаков с помощью методов, таких как one-hot кодирование или встраивание (embeddings).</li>
          </Ul>
        </li>
        <li>
          <b>Масштабирование данных:</b>
          <ul>
            <li>Приведение числовых признаков к одному масштабу с использованием методов нормализации или стандартизации.</li>
            <li>Это помогает ускорить обучение и улучшить сходимость модели.</li>
          </ul>
        </li>
        <li>
          <b>Разделение данных:</b>
          <ul>
            <li>Разделение данных на обучающую и тестовую выборки для оценки производительности модели.</li>
            <li>Часто используется также валидационная выборка для настройки гиперпараметров.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Принцип построения архитектур нейронных сетей для регрессии</b>
        <li>
          <b>Выбор модели:</b>
          <ul>
            <li>В зависимости от сложности задачи и объема данных можно выбрать простую линейную модель или более сложную нейронную сеть.</li>
          </ul>
        </li>
        <li>
          <b>Входной слой:</b>
          <ul>
            <li>Входной слой должен соответствовать размерности признаков.</li>
            <li>Если входные данные имеют n признаков, входной слой будет иметь n нейронов.</li>
          </ul>
        </li>
        <li>
          <b>Скрытые слои:</b>
          <ul>
            <li>Обычно используются один или несколько скрытых слоев с различными активационными функциями (ReLU, tanh и т.д.).</li>
            <li>Количество нейронов в скрытых слоях и количество слоев подбирается экспериментально.</li>
          </ul>
        </li>
        <li>
          <b>Выходной слой:</b>
          <ul>
            <li>Выходной слой состоит из одного нейрона, так как задача регрессии предполагает предсказание одного числового значения.</li>
            <li>Активационная функция выходного слоя обычно линейная, так как нам нужно предсказать непрерывное значение.</li>
          </ul>
        </li>
        <li>
          <b>Функция потерь:</b>
          <ul>
            <li>Для задачи регрессии часто используется функция среднеквадратичной ошибки (Mean Squared Error, MSE) или среднеабсолютной ошибки (Mean Absolute Error, MAE).</li>
          </ul>
        </li>
        <li>
          <b>Оптимизатор:</b>
          <ul>
            <li>Популярные оптимизаторы включают Adam, RMSprop и SGD.</li>
            <li>Выбор оптимизатора зависит от задачи и объема данных.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Пример архитектуры нейронной сети для регрессии</b>
        <li><b>Входной слой:</b> Принимает n признаков.</li>
        <li><b>Первый скрытый слой:</b> Полносвязный слой с m нейронами и функцией активации ReLU.</li>
        <li><b>Второй скрытый слой:</b> Полносвязный слой с k нейронами и функцией активации ReLU.</li>
        <li><b>Выходной слой:</b> Полносвязный слой с одним нейроном и линейной функцией активации</li>
      </ol><br>
      <p>Задача регрессии является важной и широко применяемой в различных областях науки и техники. Умение правильно подготавливать данные и строить эффективные архитектуры нейронных сетей для решения задач регрессии позволяет достигать высоких результатов и создавать мощные модели для предсказания непрерывных значений.</p>
      <br>
      <ol><b>Можно добавить следующие аспекты</b>
        <li>
          <b>Особенности данных:</b>
          <ul>
            <li><b>bКорреляция признаков:</b> Описание важности анализа корреляции между признаками и целевым значением, чтобы избежать проблем мультиколлинеарности.</li>
            <li><b>bАнализ выбросов:</b> Пояснение необходимости обработки выбросов в данных, так как они могут сильно влиять на производительность модели.</li>
          </ul>
        </li>
        <li>
          <b>Метрики оценки модели:</b>
          <ul>
            <li>Помимо MSE и MAE, можно упомянуть другие метрики, такие как RMSE (корень из среднеквадратичной ошибки) и R² (коэффициент детерминации), и объяснить, в каких случаях каждая из них наиболее полезна.</li>
          </ul>
        </li>
        <li>
          <b>Регуляризация:</b>
          <ul>
            <li>Объяснение применения методов регуляризации (L1, L2 и Dropout) для предотвращения переобучения модели.</li>
          </ul>
        </li>
        <li>
          <b>Техника кросс-валидации:</b>
          <ul>
            <li>Подробное описание кросс-валидации (например, K-Fold кросс-валидация) для более надежной оценки производительности модели и настройки гиперпараметров.</li>
          </ul>
        </li>
        <li>
          <b>Фиче инжиниринг:</b>
          <ul>
            <li>Важность создания новых признаков и преобразования существующих признаков для улучшения модели. <br><b>Примеры техник:</b> полиномиальные признаки, взаимодействие признаков, логарифмическое преобразование.</li>
          </ul>
        </li>
        <li>
          <b>Гиперпараметрическая оптимизация:</b>
          <ul>
            <li>Методы настройки гиперпараметров, такие как Grid Search и Random Search, а также более продвинутые методы, такие как Bayesian Optimization.</li>
          </ul>
        </li>
        <li>
          <b>Интерпретируемость модели:</b>
          <ul>
            <li>Методы интерпретации модели, такие как SHAP (SHapley Additive exPlanations) и LIME (Local Interpretable Model-agnostic Explanations), которые помогают понять, как модель принимает решения.</li>
          </ul>
        </li>
        <li>
          <b>Применение предобученных моделей:</b>
          <ul>
            <li>Возможности использования предобученных моделей и их адаптации к новым задачам, например, Transfer Learning для регрессионных задач</li>
          </ul>
        </li>
      </ol>
    </div>
  </details>

  <!-- 16 -->
  <details class="details">
    <summary class="details__title">Способы сохранения/загрузки модели нейронной сети.</summary>
    <div class="details__content">
      <p>Сохранение и загрузка моделей нейронных сетей — это ключевые этапы в цикле разработки, развертывания и эксплуатации моделей машинного обучения. Эти процессы позволяют сохранять результаты долгого и ресурсоемкого обучения, что значительно экономит время и вычислительные ресурсы. Существуют различные способы сохранения и загрузки моделей, в зависимости от используемого фреймворка, таких как TensorFlow/Keras и PyTorch. Рассмотрим эти процессы подробнее.</p>
      <br>
      <ol><b>Сохранение и загрузка модели в TensorFlow/Keras</b><br>TensorFlow и его высокоуровневое API Keras предоставляют несколько методов для сохранения и загрузки моделей.
        <li>
          <b>Сохранение и загрузка всей модели:</b><br>Этот метод сохраняет всю модель целиком, включая её архитектуру, веса и конфигурацию обучения (оптимизатор, функции потерь и метрики)
          <ul>
            <li>
              <b>Сохранение:</b><br>
              <code>model.save('path_to_my_model') <b># Этот метод создает директорию, в которой сохраняются файлы модели.</b></code>
            </li>
            <li>
              <b>Загрузка:</b><br>
              <code>
                from tensorflow.keras.models import load_model <br><br>
                model = load_model('path_to_my_model')
              </code>
            </li>
          </ul>
        </li>
        <li>
          <b>Сохранение и загрузка только весов модели:</b><br>Этот метод сохраняет только веса модели, что позволяет повторно использовать их в любой архитектуре, соответствующей сохраненным весам.
          <ul>
            <li>
              <b>Сохранение:</b><br>
              <code>model.save_weights('path_to_my_weights')</code>
            </li>
            <li>
              <b>Загрузка:</b>
              <code>model.load_weights('path_to_my_weights')  <b># Для этого способа загрузки необходимо сначала определить архитектуру модели, в которую будут загружены веса.</b></code>
            </li>
          </ul>
        </li>
        <li>
          <b>Сохранение архитектуры модели:</b><br>Архитектура модели может быть сохранена в формате JSON.
          <ul>
            <li>
              <b>Сохранение:</b><br>
              <code>
                json_config = model.to_json() <br>
                with open('model_config.json', 'w') as json_file: <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;json_file.write(json_config)
              </code>
            </li>
            <li>
              <b>Загрузка:</b><br>
              <code>
                from tensorflow.keras.models import model_from_json <br> <br>
                with open('model_config.json', 'r') as json_file: <br>
                &nbsp;&nbsp;&nbsp;&nbsp;json_config = json_file.read() <br>
                model = model_from_json(json_config) <br>
                model.load_weights('path_to_my_weights')
              </code>
            </li>
          </ul>
        </li>
        <li>
          <b>Формат SavedModel:</b><br>SavedModel — это стандартный формат для сохранения моделей в TensorFlow, который поддерживается различными инструментами и средами выполнения.
          <ul>
            <li>
              <b>Сохранение:</b><br>
              <code>model.save('path_to_saved_model', save_format='tf') <b># Этот формат сохраняет модель в виде директории, которая содержит метаданные и веса модели.</b></code>
            </li>
            <li>
              <b>Загрузка:</b><br>
              <code>
                from tensorflow.keras.models import load_model <br><br>
                model = load_model('path_to_saved_model')
              </code>
            </li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Сохранение и загрузка модели в PyTorch</b><br>PyTorch предоставляет несколько способов для сохранения и загрузки моделей.
        <li>
          <b>Сохранение и загрузка всей модели:</b><br>Сохраняется вся модель, включая её архитектуру и веса.
          <ul>
            <li>
              <b>Сохранение:</b><br>
              <code>torch.save(model, 'model.pth')</code>
            </li>
            <li>
              <b>Загрузка:</b><br>
              <code>
                model = torch.load('model.pth')
                model.eval()  <b># Установка режима оценки</b>
              </code>
            </li>
          </ul>
        </li>
        <li>
          <b>Сохранение и загрузка состояния модели:</b><br>Этот метод сохраняет состояние модели, что включает только веса, а не архитектуру.
          <ul>
            <li>
              <b>Сохранение:</b><br>
              <code>torch.save(model.state_dict(), 'model_weights.pth')</code>
            </li>
            <li>
              <b>Загрузка:</b><br><i>В этом случае важно иметь определение класса модели TheModelClass при загрузке весов.</i><br>
              <code>
                model = TheModelClass(*args, **kwargs) <br>
                model.load_state_dict(torch.load('model_weights.pth')) <br>
                model.eval()  <b># Установка режима оценки</b>
              </code>
            </li>
          </ul>
        </li>
        <li>
          <b>Сохранение и загрузка состояния оптимизатора:</b><br>Для продолжения обучения модели с сохраненными параметрами оптимизатора.
          <ul>
            <li>
              <b>Сохранение:</b><br>
              <code>
                torch.save({ <br>
                  &nbsp;&nbsp;&nbsp;&nbsp;'model_state_dict': model.state_dict(), <br>
                  &nbsp;&nbsp;&nbsp;&nbsp;'optimizer_state_dict': optimizer.state_dict(), <br>
                  &nbsp;&nbsp;&nbsp;&nbsp;'epoch': epoch, <br>
                  &nbsp;&nbsp;&nbsp;&nbsp;'loss': loss, <br>
                }, 'checkpoint.pth')
              </code>
            </li>
            <li>
              <b>Загрузка:</b><br>
              <code>
                checkpoint = torch.load('checkpoint.pth') <br>
                model.load_state_dict(checkpoint['model_state_dict']) <br>
                optimizer.load_state_dict(checkpoint['optimizer_state_dict']) <br>
                epoch = checkpoint['epoch'] <br>
                loss = checkpoint['loss']
              </code>
            </li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Рекомендации и лучшие практики</b>
        <li><b>Версионность моделей:</b>
          <ul>
            <li>Хранение различных версий моделей позволяет отслеживать изменения и улучшения.</li>
          </ul>
        </li>
        <li><b>Проверка целостности данных:</b>
          <ul>
            <li>Проверка целостности файлов после сохранения и перед загрузкой помогает избежать ошибок.</li>
          </ul>
        </li>
        <li><b>Документация и комментарии:</b>
          <ul>
            <li>Ведение подробной документации об экспериментальных настройках и версиях моделей.</li>
          </ul>
        </li>
        <li><b>Автоматизация процесса:</b>
          <ul>
            <li>Автоматизация сохранения и загрузки моделей с помощью скриптов для обеспечения непрерывного процесса разработки.</li>
          </ul>
        </li>
        <li><b>Совместимость версий:</b>
          <ul>
            <li>Убедитесь, что версии библиотек, используемые для сохранения и загрузки моделей, совместимы, чтобы избежать проблем.</li>
          </ul>
        </li>
      </ol><br>
      <p>Сохранение и загрузка моделей — это критически важные процессы, которые обеспечивают гибкость и надежность в цикле разработки и эксплуатации моделей машинного обучения. Понимание и правильное использование этих методов позволяет эффективно управлять моделями, улучшая производительность и ускоряя разработку приложений машинного обучения.</p>
    </div>
  </details>

  <!-- 17 -->
  <details class="details">
    <summary class="details__title">Временный ряды. Инструмент TimeSeriesGenerator. Особенности формирования выборки.</summary>
    <div class="details__content">
      <p>Временные ряды играют важную роль в анализе данных, особенно в областях, где данные поступают в последовательном временном порядке, таких как экономика, финансы, метеорология и многие другие. Работа с временными рядами требует специальных методов и подходов для подготовки данных и моделирования. Одним из таких инструментов для работы с временными рядами в Keras является TimeSeriesGenerator.</p>
      <br>
      <p><b>Временные ряды</b></p>
      <p>Временной ряд — это последовательность данных, собранных через равные интервалы времени. Основные характеристики временных рядов включают тренд, сезонность, цикличность и случайные колебания. Для успешного моделирования временных рядов важно учитывать эти характеристики и правильно подготавливать данные.</p>
      <br>
      <p><b>TimeSeriesGenerator</b></p>
      <p>TimeSeriesGenerator — это класс в библиотеке Keras, предназначенный для удобного создания батчей из временных рядов для обучения моделей. Он позволяет автоматически генерировать входные и целевые последовательности из временного ряда, что значительно упрощает процесс подготовки данных.</p>
      <br>
      <ul><b>Основные параметры TimeSeriesGenerator</b>
        <li><b>data:</b> Исходный временной ряд.</li>
        <li><b>targets:</b> Целевые значения.</li>
        <li><b>length:</b> Длина входной последовательности (количество временных шагов).</li>
        <li><b>sampling_rate:</b> Шаг сэмплирования временных шагов.</li>
        <li><b>stride:</b> Шаг между началом последовательных последовательностей.</li>
        <li><b>start_index и end_index:</b> Границы интервала исходного ряда для генерации последовательностей.</li>
        <li><b>batch_size:</b> Размер батча.</li>
        <li><b>shuffle:</b> Перемешивание данных.</li>
        <li><b>reverse:</b> Перевернуть входные последовательности.</li>
      </ul><br><br>
      <ol><b>Особенности формирования выборки</b>
        <li><b>Выбор длины входной последовательности (length):</b>
          <ul>
            <li>Длина входной последовательности определяет, сколько предыдущих временных шагов будет использоваться для предсказания следующего значения. Это зависит от природы данных и задачи. Например, для прогнозирования погоды может потребоваться более длинная последовательность, чем для прогнозирования продаж.</li>
          </ul>
        </li>
        <li><b>Шаг сэмплирования (sampling_rate):</b>
          <ul>
            <li>Этот параметр определяет, с каким шагом брать данные из исходного временного ряда. Например, если шаг равен 2, будут использоваться каждые вторые данные.</li>
          </ul>
        </li>
        <li><b>Шаг между последовательностями (stride):</b>
          <ul>
            <li>Определяет, насколько смещены начальные точки последовательных последовательностей. Малый шаг может привести к большим накладным расходам на вычисления из-за значительного перекрытия последовательностей, в то время как большой шаг может уменьшить количество обучающих данных.</li>
          </ul>
        </li>
        <li><b>Перемешивание данных (shuffle):</b>
          <ul>
            <li>Перемешивание данных может быть полезно для предотвращения переобучения, особенно если данные имеют сильные временные зависимости. Однако, при работе с временными рядами часто важно сохранить порядок данных, поэтому этот параметр должен использоваться с осторожностью.</li>
          </ul>
        </li>
        <li><b>Границы интервала (start_index и end_index):</b>
          <ul>
            <li>Позволяют исключить из рассмотрения начальные или конечные данные временного ряда, что может быть полезно, например, для исключения аномалий или подготовки валидационной выборки.</li>
          </ul>
        </li>
        <li><b>Размер батча (batch_size):</b>
          <ul>
            <li>Определяет количество последовательностей в одном батче. Оптимальный размер батча зависит от объемов данных и доступных вычислительных ресурсов.</li>
          </ul>
        </li>
      </ol><br>
      <p>Работа с временными рядами требует учета специфических особенностей данных, таких как временные зависимости, сезонные и трендовые компоненты. TimeSeriesGenerator в Keras предоставляет удобный способ автоматического формирования обучающих и целевых последовательностей, что упрощает процесс подготовки данных и позволяет сосредоточиться на построении и настройке моделей. Правильное использование этого инструмента, а также тщательный выбор параметров генерации последовательностей играют ключевую роль в успешном решении задач прогнозирования временных рядов.</p>
    </div>
  </details>

  <!-- 18 -->
  <details class="details">
    <summary class="details__title">Аугментация изображений. Инструмент ImageDataGenerator.</summary>
    <div class="details__content">
      <p>Аугментация изображений — это важный процесс в машинном обучении, особенно в задачах компьютерного зрения, который заключается в искусственном увеличении объема данных путем применения различных трансформаций к исходным изображениям. Это помогает моделям лучше обобщать данные и снижает риск переобучения. В Keras для аугментации изображений используется инструмент ImageDataGenerator.</p>
      <br>
      <ol><b>Зачем нужна аугментация изображений?</b>
        <li><b>Увеличение объема данных:</b> В реальных сценариях часто существует ограничение на количество данных для обучения. Аугментация позволяет создавать дополнительные данные на основе уже имеющихся изображений, увеличивая общий объем обучающей выборки.</li>
        <li><b>Улучшение обобщающей способности модели:</b> Модели, обученные на аугментированных данных, становятся более устойчивыми к различным изменениям и шумам в данных. Это повышает их способность обобщать на новые, невиданные данные.</li>
        <li><b>Уменьшение переобучения:</b> Аугментация создает разнообразные варианты изображений, что предотвращает модель от запоминания конкретных примеров и учит ее выделять общие закономерности в данных.</li>
      </ol><br><br>
      <ol><b>Основные методы аугментации изображений</b><br>Аугментация изображений включает в себя применение различных трансформаций к исходным изображениям. <br>Основные методы включают:
        <li><b>Повороты (rotation):</b> Изображение поворачивается на случайный угол в пределах заданного диапазона, что помогает модели быть устойчивой к ориентации объектов на изображении.</li>
        <li><b>Сдвиги (width_shift, height_shift):</b> Изображение сдвигается по горизонтали или вертикали на случайное значение в пределах заданного диапазона, что помогает модели быть устойчивой к положению объектов на изображении.</li>
        <li><b>Масштабирование (zoom):</b> Изображение масштабируется (увеличивается или уменьшается) случайным образом, что помогает модели обрабатывать объекты разных размеров.</li>
        <li><b>Горизонтальные и вертикальные отзеркаливания (horizontal_flip, vertical_flip):</b> Изображение случайным образом отражается по горизонтали или вертикали, что помогает модели быть устойчивой к отражениям объектов.</li>
        <li><b>Сдвиг цветового канала (channel_shift):</b> Изменяется интенсивность цветового канала, что помогает модели быть устойчивой к изменению освещения и цветовых условий.  </li>
        <li><b>Яркость (brightness):</b> Изображение случайным образом изменяет яркость, что помогает модели обрабатывать изображения с разными уровнями освещенности.</li>
        <li><b>Изменение контраста, насыщенности и оттенка:</b> Эти трансформации изменяют визуальные характеристики изображения, делая его более разнообразным для модели.</li>
      </ol><br>
      <p><b>Инструмент ImageDataGenerator</b></p>
      <p>ImageDataGenerator — это мощный инструмент Keras, который предоставляет методы для генерации увеличенных изображений в реальном времени во время обучения модели. Этот инструмент позволяет автоматизировать процесс аугментации и интегрировать его непосредственно в процесс обучения, что особенно полезно для больших наборов данных и сложных моделей.</p>
      <br>
      <ol><b>Основные параметры ImageDataGenerator</b>
        <li><b>rotation_range:</b> Задает диапазон случайных поворотов изображения в градусах. Например, rotation_range=40 означает, что изображение может быть повернуто на случайный угол до 40 градусов.</li>
        <li><b>width_shift_range и height_shift_range:</b> Задают диапазон случайных сдвигов изображения по горизонтали и вертикали соответственно, в долях от ширины и высоты изображения. <br>Например, width_shift_range=0.2 означает сдвиг изображения до 20% от его ширины.</li>
        <li><b>shear_range:</b> Задает диапазон преобразований сдвига изображения (в радианах). Это трансформация, которая изменяет форму изображения, сдвигая его части в разных направлениях.</li>
        <li><b>zoom_range:</b> Задает диапазон случайных масштабирований изображения. <br>Например, zoom_range=[0.8, 1.2] означает, что изображение может быть уменьшено до 80% или увеличено до 120% от исходного размера.</li>
        <li><b>horizontal_flip и vertical_flip:</b> Флаги, указывающие на применение случайных горизонтальных или вертикальных отражений изображения.</li>
        <li><b>rescale:</b> Масштабирование значений пикселей. <br>Например, rescale=1./255 нормализует значения пикселей в диапазон [0, 1].</li>
        <li><b>brightness_range:</b> Задает диапазон для случайного изменения яркости изображения.</li>
        <li><b>channel_shift_range:</b> Задает диапазон для случайного изменения значений цветовых каналов.</li>
        <li><b>fill_mode:</b> Стратегия заполнения новых пикселей, которые появляются после применения трансформаций, таких как сдвиги или повороты. Возможные значения включают 'constant', 'nearest', 'reflect', 'wrap'.</li>
      </ol><br>
      <p><b>Применение аугментации в процессе обучения</b></p>
      <p>Часто аугментация изображений применяется непосредственно в процессе обучения модели. ImageDataGenerator позволяет автоматически генерировать батчи аугментированных данных и подавать их в модель в реальном времени. Это значительно упрощает процесс обучения и позволяет эффективно использовать вычислительные ресурсы.</p>
      <br>
      <p>Аугментация изображений является важной техникой в машинном обучении, которая помогает улучшить качество моделей и их способность обобщать данные. ImageDataGenerator в Keras предоставляет удобный и гибкий способ реализации аугментации изображений, который легко интегрируется в процесс обучения. Понимание и правильное применение этого инструмента являются ключевыми навыками для специалистов в области компьютерного зрения и машинного обучения.</p>
    </div>
  </details>

  <!-- 19 -->
  <details class="details">
    <summary class="details__title">Инструмент Callback'ов. Встроенные Callback'и keras'а.</summary>
    <div class="details__content">
      <p>Callbacks (обратные вызовы) в Keras — это мощный инструмент, позволяющий пользователям выполнять определенные действия на разных этапах обучения модели. Они обеспечивают гибкость и контроль над процессом обучения, позволяя выполнять операции до или после эпох, батчей, а также в начале или конце обучения. Callbacks полезны для мониторинга, логирования, изменения параметров модели и выполнения других вспомогательных задач без изменения основного кода обучения.</p>
      <br>
      <p><b>Что такое Callback'и?</b></p>
      <p>Callback'и — это объекты, которые передаются в методы обучения моделей, такие как fit(), fit_generator() и evaluate(). Они предоставляют возможности вмешательства в процесс обучения на различных стадиях:</p>
      <ul>
        <li>В начале и в конце обучения</li>
        <li>В начале и в конце каждой эпохи</li>
        <li>До и после обработки каждого батча</li>
        <li>При возникновении определенных условий (например, улучшение качества модели)</li>
      </ul>
      <p>Основное преимущество использования Callback'ов заключается в возможности автоматизации и оптимизации процесса обучения, что делает их незаменимым инструментом для глубинного обучения.</p>
      <br>
      <ol><b>Всего их</b>
        <li>Base Callback class</li>
        <li>ModelCheckpoint</li>
        <li>BackupAndRestore</li>
        <li>TensorBoard</li>
        <li>EarlyStopping</li>
        <li>LearningRateScheduler</li>
        <li>ReduceLROnPlateau</li>
        <li>RemoteMonitor</li>
        <li>LambdaCallback</li>
        <li>TerminateOnNaN</li>
        <li>CSVLogger</li>
        <li>ProgbarLogger</li>
        <li>SwapEMAWeights</li>
      </ol>
      <br>
      <ol><b>Встроенные Callback'и Keras</b><br>Keras предоставляет несколько встроенных Callback'ов, которые покрывают широкий спектр задач. <br>Рассмотрим основные из них:
        <li>
          <b>ModelCheckpoint</b>
          <ul>
            <li><b>Назначение:</b> Сохранение модели или ее весов на диск в ходе обучения.</li>
            <li>
              <b>Основные параметры:</b>
              <ul>
                <li><b>filepath:</b> Путь для сохранения файла.</li>
                <li><b>monitor:</b> Метрика для мониторинга (например, 'val_loss').</li>
                <li><b>save_best_only:</b> Сохранять только лучшую модель на основе выбранной метрики.</li>
                <li><b>mode:</b> 'auto', 'min' или 'max' (режим выбора лучшего значения метрики).</li>
                <li><b>save_weights_only:</b> Сохранять только веса модели.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>EarlyStopping</b>
          <ul>
            <li><b>Назначение:</b> Остановка обучения при отсутствии улучшений выбранной метрики.</li>
            <li>
              <b>Основные параметры:</b>
              <ul>
                <li><b>monitor:</b> Метрика для мониторинга.</li>
                <li><b>patience:</b> Количество эпох без улучшений, после которых обучение будет остановлено.</li>
                <li><b>mode:</b> 'auto', 'min' или 'max'.</li>
                <li><b>restore_best_weights:</b> Восстановить веса модели с наилучшей эпохи.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>ReduceLROnPlateau</b>
          <ul>
            <li><b>Назначение:</b> Снижение скорости обучения при остановке улучшений метрики.</li>
            <li>
              <b>Основные параметры:</b>
              <ul>
                <li><b>monitor:</b> Метрика для мониторинга.</li>
                <li><b>factor:</b> Множитель для уменьшения скорости обучения.</li>
                <li><b>patience:</b> Количество эпох без улучшений.</li>
                <li><b>mode:</b> 'auto', 'min' или 'max'.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>TensorBoard</b>
          <ul>
            <li><b>Назначение:</b> Логирование метрик и параметров модели для визуализации с помощью TensorBoard.</li>
            <li>
              <b>Основные параметры:</b>
              <ul>
                <li><b>log_dir:</b> Директория для сохранения логов.</li>
                <li><b>histogram_freq:</b> Частота вычисления и логирования гистограмм слоев модели.</li>
                <li><b>write_graph:</b> Логировать граф вычислений модели.</li>
                <li><b>write_images:</b> Логировать изображения весов модели.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>CSVLogger</b>
          <ul>
            <li><b>Назначение:</b> Сохранение логов обучения в CSV файл.</li>
            <li>
              <b>Основные параметры:</b>
              <ul>
                <li><b>filename:</b> Имя файла для записи логов.</li>
                <li><b>separator:</b> Разделитель полей в CSV файле.</li>
                <li><b>append:</b> Добавлять логи к существующему файлу или перезаписывать его.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>LearningRateScheduler</b>
          <ul>
            <li><b>Назначение:</b> Изменение скорости обучения по заранее заданному расписанию.</li>
            <li>
              <b>Основные параметры:</b>
              <ul>
                <li><b>schedule:</b> Функция, определяющая новое значение скорости обучения для каждой эпохи.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>LambdaCallback</b>
          <ul>
            <li><b>Назначение:</b> Создание кастомных Callback'ов с использованием лямбда-функций.</li>
            <li>
              <b>Основные параметры:</b>
              <ul>
                <li><b>on_epoch_begin, on_epoch_end, on_batch_begin, on_batch_end, on_train_begin, on_train_end:</b> Лямбда-функции для выполнения кода в соответствующих точках процесса обучения.</li>
              </ul>
            </li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Примеры использования Callback'ов</b>
        <li>ModelCheckpoint часто используется для сохранения наилучшей версии модели, основанной на валидационной метрике, чтобы предотвратить потерю лучших результатов в случае переобучения.</li>
        <li>EarlyStopping полезен для сокращения времени обучения, автоматически останавливая процесс, когда улучшения метрики прекращаются, что также помогает избежать переобучения.</li>
        <li>ReduceLROnPlateau часто используется в комбинации с EarlyStopping, чтобы сначала попытаться улучшить результаты за счет снижения скорости обучения перед остановкой процесса обучения.</li>
        <li>TensorBoard является мощным инструментом для визуализации процесса обучения, предоставляя графики метрик, гистограммы весов и архитектуру модели, что позволяет глубже анализировать и понимать поведение модели.</li>
      </ol><br>
      <p>Callbacks в Keras являются критически важными инструментами для контроля и оптимизации процесса обучения моделей глубокого обучения. Они обеспечивают гибкость и автоматизацию, позволяя специалистам эффективно управлять обучением и добиваться лучших результатов. Понимание встроенных Callback'ов и умение их применять являются необходимыми навыками для успешного построения и внедрения моделей машинного обучения.</p>
    </div>
  </details>

  <!-- 20 -->
  <details class="details">
    <summary class="details__title">Архитектура U-Net. Принцип построения. Применения, реализации</summary>
    <div class="details__content">
      <p>U-Net — это архитектура нейронной сети, разработанная специально для задач сегментации изображений. Она была представлена в 2015 году Олафом Роннебергером и его коллегами. U-Net получила широкое распространение в медицине, биологии и других областях, где требуется точная сегментация объектов на изображениях.</p>
      <br>
      <ol><b>Принцип построения</b><br>Архитектура U-Net состоит из двух симметричных частей: энкодера (сжатие) и декодера (развертывание), которые соединены пропусками, что формирует U-образную структуру.
        <li>
          <b>Энкодер (Contracting Path):</b>
          <ul>
            <li>Энкодер состоит из последовательности сверточных слоев, за которыми следуют функции активации (обычно ReLU) и операции максимального пуллинга.</li>
            <li>Основная задача энкодера — извлечение и обобщение высокоуровневых признаков из входного изображения.</li>
            <li>При каждом этапе выполнения пуллинга размер пространственных данных уменьшается, в то время как глубина (количество фильтров) увеличивается.</li>
          </ul>
        </li>
        <li>
          <b>Декодер (Expansive Path):</b>
          <ul>
            <li>Декодер включает в себя транспонированные сверточные слои (deconvolution) или операции апсемплинга, за которыми следуют обычные сверточные слои и функции активации.</li>
            <li>Основная задача декодера — восстановление пространственного разрешения изображения для получения карты сегментации.</li>
            <li>На каждом этапе апсемплинга размеры пространственных данных увеличиваются, а глубина уменьшается.</li>
          </ul>
        </li>
        <li>
          <b>Пропуски (Skip Connections):</b>
          <ul>
            <li>Важной особенностью U-Net являются пропуски (skip connections), которые передают информацию из энкодера на соответствующие уровни декодера.</li>
            <li>Это позволяет объединять пространственные признаки высокого разрешения из начальных слоев с высокоуровневыми признаками из более глубоких слоев.</li>
            <li>Пропуски помогают улучшить качество сегментации, особенно на границах объектов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Применения</b><br>U-Net находит применение в различных областях, требующих точной сегментации изображений:
        <li>
          <b>Медицинская визуализация:</b>
          <ul>
            <li>Сегментация органов и патологий на медицинских снимках (МРТ, КТ, УЗИ).</li>
            <li>Выделение контуров опухолей, сосудов и других анатомических структур.</li>
          </ul>
        </li>
        <li>
          <b>Биологические исследования:</b>
          <ul>
            <li>Анализ микроскопических изображений клеток и тканей.</li>
            <li>Сегментация и классификация клеточных структур.</li>
          </ul>
        </li>
        <li>
          <b>Геоинформационные системы (ГИС):</b>
          <ul>
            <li>Сегментация спутниковых снимков для выделения различных типов поверхностей (водоемы, леса, города).</li>
          </ul>
        </li>
        <li>
          <b>Автоматизация производства:</b>
          <ul>
            <li>Обнаружение дефектов на производственных линиях.</li>
            <li>Сегментация объектов на изображениях с камер наблюдения.</li>
          </ul>
        </li>
        <li>
          <b>Автономные транспортные средства:</b>
          <ul>
            <li>Сегментация дорожной разметки, транспортных средств, пешеходов и других объектов на дорогах.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Реализации</b><br>Реализация U-Net может варьироваться в зависимости от конкретной задачи и доступных данных. Основные аспекты реализации включают:
        <li>
          <b>Подготовка данных:</b>
          <ul>
            <li>Необходимо собрать и аннотировать набор данных с точными масками для каждого класса объектов.</li>
            <li>Обычно данные делятся на обучающую, валидационную и тестовую выборки.</li>
          </ul>
        </li>
        <li>
          <b>Архитектура сети:</b>
          <ul>
            <li>Базовая архитектура U-Net включает в себя сверточные и транспонированные сверточные слои.</li>
            <li>Можно использовать предобученные модели в качестве энкодера (например, VGG, ResNet) для улучшения качества сегментации.</li>
          </ul>
        </li>
        <li>
          <b>Обучение модели:</b>
          <ul>
            <li>Выбор функции потерь зависит от задачи. Для многоклассовой сегментации часто используется кросс-энтропия, для двоичной сегментации — бинарная кросс-энтропия или Dice-коэффициент.</li>
            <li>Важен выбор оптимизатора и стратегии изменения скорости обучения (learning rate).</li>
            <li>Регуляризация (dropout, weight decay) помогает предотвратить переобучение.</li>
          </ul>
        </li>
        <li>
          <b>Аугментация данных:</b>
          <ul>
            <li>Для улучшения обобщающей способности модели применяется аугментация данных: вращения, сдвиги, масштабирование, изменение яркости и контрастности.</li>
          </ul>
        </li>
        <li>
          <b>Оценка и валидация:</b>
          <ul>
            <li>Модель оценивается на валидационной и тестовой выборках с использованием метрик точности (accuracy), Dice-коэффициента, IoU (Intersection over Union) и других.</li>
          </ul>
        </li>
        <li>
          <b>Пост-обработка:</b>
          <ul>
            <li>В некоторых случаях требуется пост-обработка результатов сегментации для удаления шумов и мелких артефактов.</li>
          </ul>
        </li>
      </ol><br>
      <p>U-Net — это мощная и гибкая архитектура нейронной сети, специально разработанная для задач сегментации изображений. Она сочетает в себе преимущества глубокого обучения и классических методов обработки изображений, что делает её эффективной и популярной в различных прикладных областях. Понимание принципов построения U-Net и умение её применять являются ключевыми навыками для специалистов в области компьютерного зрения и анализа изображений.</p>
      <br>
      <ol><b>Модификации и улучшения U-Net</b>
        <li>
          <b>3D U-Net:</b>
          <ul>
            <li><b>Назначение:</b> Адаптация для работы с трехмерными данными, такими как объемные медицинские изображения (например, МРТ и КТ сканы).</li>
            <li><b>Архитектура:</b> Вместо двумерных сверточных слоев и операций пуллинга используются трёхмерные аналоги, что позволяет обрабатывать 3D данные.</li>
            <li><b>Преимущества:</b> Улучшенная сегментация объемных данных за счёт учета пространственной информации во всех трёх измерениях.</li>
          </ul>
        </li>
        <li>
          <b>Attention U-Net:</b>
          <ul>
            <li><b>Назначение:</b> Улучшение сегментации, фокусируясь на более значимых участках изображения.</li>
            <li><b>Архитектура:</b> Добавление механизмов внимания (attention mechanisms) в пропуски между энкодером и декодером. Эти механизмы помогают модели выделять важные регионы изображения, игнорируя нерелевантные.</li>
            <li><b>Преимущества:</b> Повышение точности сегментации, особенно на сложных и шумных данных.</li>
          </ul>
        </li>
        <li>
          <b>ResUNet:</b>
          <ul>
            <li><b>Назначение:</b> Улучшение обучения за счёт использования резидуальных связей.</li>
            <li><b>Архитектура:</b> Включение резидуальных блоков (residual blocks), которые позволяют пропускать информацию через слои без изменений, что помогает избежать проблемы исчезающего градиента.</li>
            <li><b>Преимущества:</b> Более эффективное обучение и улучшенная производительность на глубоких сетях.</li>
          </ul>
        </li>
        <li>
          <b>Nested U-Net (UNet++):</b>
          <ul>
            <li><b>Назначение:</b> Улучшение передачи информации между уровнями энкодера и декодера.</li>
            <li><b>Архитектура:</b> Включение дополнительных сверточных слоев между каждым уровнем энкодера и декодера. Это позволяет более эффективно передавать информацию и улучшать детализацию сегментации.</li>
            <li><b>Преимущества:</b> Улучшенная точность и качество сегментации, особенно для мелких и детализированных объектов.</li>
          </ul>
        </li>
        <li>
          <b>Dense U-Net:</b>
          <ul>
            <li><b>Назначение:</b> Усиление передачи информации между слоями за счет плотных связей.</li>
            <li><b>Архитектура:</b> Использование плотных блоков (Dense Blocks), где каждый слой получает входные данные от всех предыдущих слоев в своем блоке.</li>
            <li><b>Преимущества:</b> Улучшенная передача градиентов и более эффективное использование параметров модели.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Сравнение с другими архитектурами</b>
        <li>
          <b>FCN (Fully Convolutional Network):</b>
          <ul>
            <li><b>Преимущества FCN:</b> Первая архитектура, предложенная для сегментации изображений, использующая только сверточные слои.</li>
            <li><b>Сравнение:</b> U-Net улучшает FCN за счёт использования симметричной архитектуры с пропусками, что позволяет восстановить более детализированные карты сегментации.</li>
          </ul>
        </li>
        <li>
          <b>SegNet:</b>
          <ul>
            <li><b>Преимущества SegNet:</b> Использует энкодер-декодерную архитектуру с индексацией на этапе пуллинга, что помогает лучше восстановить пространственные данные.</li>
            <li><b>Сравнение:</b> U-Net часто показывает лучшие результаты за счёт пропусков, которые обеспечивают передачу контекстной информации на все уровни декодера, в то время как SegNet может терять некоторые детали.</li>
          </ul>
        </li>
        <li>
          <b>Mask R-CNN:</b>
          <ul>
            <li><b>Преимущества Mask R-CNN:</b> Применяется для задач детекции объектов и сегментации, может обрабатывать и сегментировать объекты с различными размерами и формами.</li>
            <li><b>Сравнение:</b> U-Net специализируется на плотной пиксельной сегментации, что делает её предпочтительной для задач, где важна высокая точность сегментации каждого пикселя (например, медицинская сегментация), тогда как Mask R-CNN эффективна для случаев, где важно обнаружение объектов.</li>
          </ul>
        </li>
        <li>
          <b>DeepLab:</b>
          <ul>
            <li><b>Преимущества DeepLab:</b> Использует пространственные пирамидальные пулы (ASPP) для захвата контекста на различных масштабах и условные случайные поля (CRF) для улучшения сегментации границ объектов.</li>
            <li><b>Сравнение:</b> U-Net проще в реализации и требует меньше вычислительных ресурсов, но DeepLab может показывать лучшие результаты на сложных сценах с большим разнообразием объектов и фонов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Проблемы и ограничения</b><br>Несмотря на многочисленные преимущества, U-Net имеет свои ограничения и потенциальные проблемы:
        <li>
          <b>Вычислительная сложность:</b>
          <ul>
            <li><b>Описание:</b> U-Net требует значительных вычислительных ресурсов для обучения, особенно на больших и высокоразрешённых наборах данных.</li>
            <li><b>Последствия:</b> Это может ограничивать её применение в условиях ограниченных вычислительных мощностей и увеличивать время тренировки.</li>
          </ul>
        </li>
        <li>
          <b>Необходимость большого объема размеченных данных:</b>
          <ul>
            <li><b>Описание:</b> Для эффективного обучения U-Net требуется большое количество качественно размеченных данных, что не всегда доступно.</li>
            <li><b>Последствия:</b> Недостаток размеченных данных может привести к плохой обобщающей способности модели и ухудшению качества сегментации.</li>
          </ul>
        </li>
        <li>
          <b>Сложности с сегментацией объектов разного масштаба:</b>
          <ul>
            <li><b>Описание:</b> U-Net может испытывать трудности при сегментации объектов, которые значительно различаются по масштабу.</li>
            <li><b>Последствия:</b> Это может приводить к пропуску мелких объектов или неправильной сегментации крупных объектов.</li>
          </ul>
        </li>
        <li>
          <b>Переобучение:</b>
          <ul>
            <li><b>Описание:</b> Как и другие глубокие сети, U-Net склонна к переобучению на тренировочных данных, особенно при недостатке данных или чрезмерном количестве параметров.</li>
            <li><b>Последствия:</b> Это может снижать её способность обобщать на новые данные.</li>
          </ul>
        </li>
        <li>
          <b>Артефакты на границах сегментации:</b>
          <ul>
            <li><b>Описание:</b> Иногда U-Net может генерировать артефакты на границах сегментированных объектов, что ухудшает визуальное восприятие результатов.</li>
            <li><b>Последствия:</b> Это может требовать дополнительных методов пост-обработки для устранения подобных артефактов.</li>
          </ul>
        </li>
      </ol><br>
      <p>U-Net — это мощная архитектура для задач сегментации изображений, но, как и любая технология, она имеет свои ограничения. Понимание её преимуществ и недостатков позволяет более эффективно применять её в практических задачах и искать пути для дальнейшего совершенствования.</p>
    </div>
  </details>

  <!-- 21 -->
  <details class="details">
    <summary class="details__title">Сегментация изображений.</summary>
    <div class="details__content">
      <p>Сегментация изображений является одной из ключевых задач в области компьютерного зрения. Она включает в себя разделение изображения на несколько сегментов или регионов, каждый из которых соответствует определённому объекту или классу. Это отличается от задач классификации, где изображение целиком относится к одному классу, и от задач детекции, где требуется выделение объектов с помощью ограничивающих прямоугольников. Сегментация позволяет получить более детальную и точную информацию об изображении на уровне пикселей.</p>
      <br>
      <ol><b>Типы сегментации изображений</b><br>Существует несколько типов сегментации, которые решают разные задачи:
        <li>
          <b>Сегментация на основе пороговых значений (Thresholding):</b>
          <ul>
            <li><b>Описание:</b> Этот метод основан на пороговом значении яркости пикселей. Все пиксели, значения которых выше порога, считаются принадлежащими одному классу, а остальные — другому.</li>
            <li><b>Применение:</b> Простой и быстрый метод для задач, где объекты и фон имеют значительные различия в яркости.</li>
          </ul>
        </li>
        <li>
          <b>Кластеризация (Clustering):</b>
          <ul>
            <li><b>K-means:</b> Разделение пикселей на кластеры на основе их цветовых характеристик.</li>
            <li><b>Гауссовские смеси (Gaussian Mixture Models):</b> Использование вероятностного подхода для моделирования распределения пикселей.</li>
            <li><b>Применение:</b> Хорошо работает для изображений с неоднородной текстурой и цветом.</li>
          </ul>
        </li>
        <li>
          <b>Графические методы (Graph-Based Methods):</b>
          <ul>
            <li><b>Описание:</b> Представление изображения в виде графа, где пиксели — это вершины, а ребра — сходства между ними.</li>
            <li><b>Методы:</b> Алгоритмы минимального разреза (Min-Cut), нормализованного разреза (Normalized Cut).</li>
            <li><b>Применение:</b> Эффективны для сложных изображений с множеством объектов и текстур.</li>
          </ul>
        </li>
        <li>
          <b>Методы на основе регионов (Region-Based Methods):</b>
          <ul>
            <li><b>Описание:</b> Начинаются с семян (seeds) и распространяются на соседние пиксели на основе их сходства.</li>
            <li><b>Применение:</b> Региональное разрастание (Region Growing), водораздел (Watershed).</li>
          </ul>
        </li>
        <li>
          <b>Границы и контуры (Edge-Based Methods):</b>
          <ul>
            <li><b>Описание:</b> Выделение контуров объектов на изображении с помощью методов обработки краёв.</li>
            <li><b>Методы:</b> Алгоритмы Канни, Собела.</li>
            <li><b>Применение:</b> Подходит для изображений с чётко выраженными границами объектов.</li>
          </ul>
        </li>
        <li>
          <b>Семантическая сегментация (Semantic Segmentation):</b>
          <ul>
            <li><b>Описание:</b> Присваивание каждому пикселю изображения метки класса.</li>
            <li><b>Применение:</b> Используется глубокие нейронные сети, такие как Fully Convolutional Networks (FCN), U-Net, SegNet, DeepLab.</li>
            <li><b>Пример:</b> Разметка городской сцены на классы, такие как дорога, здания, деревья, автомобили.</li>
          </ul>
        </li>
        <li>
          <b>Инстанс сегментация (Instance Segmentation):</b>
          <ul>
            <li><b>Описание:</b> Присваивание каждому пикселю изображения метки конкретного экземпляра объекта.</li>
            <li><b>Применение:</b> Маскирующая R-CNN (Mask R-CNN).</li>
            <li><b>Пример:</b> Разделение разных автомобилей на парковке.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Глубокие нейронные сети для сегментации</b><br>Современные методы сегментации изображений во многом основываются на использовании глубоких нейронных сетей, которые обеспечивают высокую точность и гибкость.
        <li>
          <b>Fully Convolutional Networks (FCN):</b>
          <ul>
            <li><b>Описание:</b> Пионер в использовании нейронных сетей для сегментации. Заменяет полносвязные слои на сверточные для обработки изображений любой размерности.</li>
            <li><b>Принцип работы:</b> Переводит задачу классификации в задачу плотного предсказания.</li>
          </ul>
        </li>
        <li>
          <b>U-Net:</b>
          <ul>
            <li><b>Описание:</b> Архитектура, разработанная для биомедицинской сегментации. Состоит из симметричного энкодера и декодера с пропусками.</li>
            <li><b>Преимущества:</b> Высокая точность сегментации, особенно на небольших наборах данных.</li>
          </ul>
        </li>
        <li>
          <b>SegNet:</b>
          <ul>
            <li><b>Описание:</b> Использует энкодер-декодерную архитектуру с сохранением индексов пуллинга для восстановления разрешения.</li>
            <li><b>Преимущества:</b> Хорошо восстанавливает пространственную информацию.</li>
          </ul>
        </li>
        <li>
          <b>DeepLab:</b>
          <ul>
            <li><b>Описание:</b> Включает пространственные пирамидальные пулы (ASPP) для захвата контекста на различных масштабах и условные случайные поля (CRF) для улучшения сегментации границ объектов.</li>
            <li><b>Преимущества:</b> Эффективен для сложных сцен с разнообразными объектами и фонами.</li>
          </ul>
        </li>
        <li>
          <b>Mask R-CNN:</b>
          <ul>
            <li><b>Описание:</b> Расширяет Faster R-CNN, добавляя ветвь для предсказания масок объектов.</li>
            <li><b>Преимущества:</b> Способна выполнять как детекцию объектов, так и их сегментацию.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Проблемы и вызовы сегментации изображений</b>
        <li>
          <b>Сложность данных:</b>
          <ul>
            <li><b>Описание:</b> Изображения могут содержать множество объектов, сложные текстуры и фоновые шумы.</li>
            <li><b>Решения:</b> Использование сложных архитектур нейронных сетей и методов предварительной обработки данных.</li>
          </ul>
        </li>
        <li>
          <b>Неоднородность данных:</b>
          <ul>
            <li><b>Описание:</b> Разные изображения могут сильно различаться по своим характеристикам.</li>
            <li><b>Решения:</b> Применение методов аугментации данных и обучение на большом количестве разнообразных данных.</li>
          </ul>
        </li>
        <li>
          <b>Баланс классов:</b>
          <ul>
            <li><b>Описание:</b> Часто встречается дисбаланс между различными классами, что может ухудшить качество сегментации.</li>
            <li><b>Решения:</b> Использование методов балансировки данных, таких как взвешенные функции потерь или методы ресемплинга.</li>
          </ul>
        </li>
        <li>
          <b>Ресурсоемкость:</b>
          <ul>
            <li><b>Описание:</b> Обучение и применение глубоких нейронных сетей требует значительных вычислительных ресурсов.</li>
            <li><b>Решения:</b> Оптимизация архитектур, использование предобученных моделей, распределенное обучение.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Применение сегментации изображений</b><br>Сегментация изображений находит широкое применение в различных областях:
        <li>
          <b>Медицина:</b>
          <ul>
            <li>Примеры: Сегментация органов, опухолей и других анатомических структур на медицинских снимках (МРТ, КТ, УЗИ).</li>
            <li>Преимущества: Повышает точность диагностики и планирования лечения.</li>
          </ul>
        </li>
        <li>
          <b>Автомобильная промышленность:</b>
          <ul>
            <li>Примеры: Сегментация дорожной разметки, транспортных средств и пешеходов для автономных автомобилей.</li>
            <li>Преимущества: Улучшает безопасность и надежность автономного вождения.</li>
          </ul>
        </li>
        <li>
          <b>Геоинформационные системы (ГИС):</b>
          <ul>
            <li>Примеры: Анализ спутниковых снимков для классификации поверхностей, мониторинга изменений в ландшафте.</li>
            <li>Преимущества: Помогает в управлении ресурсами и планировании территории.</li>
          </ul>
        </li>
        <li>
          <b>Производство:</b>
          <ul>
            <li>Примеры: Обнаружение дефектов и контроль качества на производственных линиях.</li>
            <li>Преимущества: Повышает эффективность и снижает затраты на контроль качества.</li>
          </ul>
        </li>
        <li>
          <b>Биология:</b>
          <ul>
            <li>Примеры: Анализ микроскопических изображений для изучения клеток и тканей.</li>
            <li>Преимущества: Улучшает понимание биологических процессов и поддерживает научные исследования.</li>
          </ul>
        </li>
      </ol>
      <br>
      <p>Сегментация изображений — это фундаментальная задача компьютерного зрения, играющая важную роль в различных прикладных областях. Современные методы сегментации, основанные на глубоких нейронных сетях, предоставляют мощные инструменты для анализа и обработки изображений, но при этом требуют значительных вычислительных ресурсов и тщательной подготовки данных. Понимание различных подходов и их применимость к конкретным задачам позволяет эффективно использовать эти технологии и добиваться высоких результатов в исследовательской и прикладной деятельности.</p>
    </div>
  </details>

  <!-- 22 -->
  <details class="details">
    <summary class="details__title">Рекуррентные нейронные сети. Слой LSTM.</summary>
    <div class="details__content">
      <p>Рекуррентные нейронные сети (RNN, Recurrent Neural Networks) представляют собой класс нейронных сетей, которые обладают внутренней памятью и предназначены для обработки последовательных данных. В отличие от традиционных нейронных сетей, RNN могут сохранять информацию о предыдущих состояниях и использовать ее для обработки текущих входных данных. Это делает их особенно полезными для задач, связанных с временными рядами, последовательностями и контекстами. Основная идея RNN заключается в использовании циклических связей, которые позволяют сети сохранять информацию о предыдущих шагах последовательности. Однако стандартные RNN сталкиваются с проблемой затухающих и взрывающихся градиентов, что затрудняет обучение долгосрочных зависимостей.</p>
      <br>
      <ol><b>Проблемы стандартных RNN</b>
        <li>
          <b>Затухание градиентов (Vanishing Gradients):</b>
          <ul>
            <li>Градиенты становятся слишком малыми на длинных последовательностях, что приводит к тому, что сеть "забывает" важную информацию из начала последовательности.</li>
          </ul>
        </li>
        <li>
          <b>Взрывающиеся градиенты (Exploding Gradients):</b>
          <ul>
            <li>Градиенты становятся слишком большими, что приводит к нестабильности сети и затрудняет обучение.</li>
          </ul>
        </li>
      </ol><br>
      <p><b>LSTM: Долгая краткосрочная память (Long Short-Term Memory)</b></p>
      <p>Слой LSTM (Long Short-Term Memory) был предложен для решения вышеупомянутых проблем стандартных RNN. Он был разработан Хохрайтером и Шмидхубером в 1997 году. LSTM включает в себя специальные структуры, называемые ячейками памяти, которые способны эффективно запоминать и извлекать долгосрочные зависимости.</p>
      <br>
      <ol><b>Основные компоненты LSTM:</b>
        <li>
          <b>Ячейка памяти (Cell State):</b>
          <ul>
            <li>Основное хранилище информации, которое может сохранять долгосрочные зависимости.</li>
            <li>Информация в ячейке может изменяться только через строго контролируемые механизмы.</li>
          </ul>
        </li>
        <li>
          <b>Запорные вентили (Gates):</b>
          <ul>
            <li><b>Входной вентиль (Input Gate):</b> Контролирует количество информации, поступающей в ячейку.</li>
            <li><b>Забывающий вентиль (Forget Gate):</b> Решает, какая часть информации из ячейки должна быть забыта.</li>
            <li><b>Вентиль выхода (Output Gate):</b> Определяет, какая информация будет использована для предсказания на текущем шаге.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Принцип работы LSTM</b>
        <li>
          <b>Входной вентиль:</b>
          <ul>
            <li>Определяет, какая часть новой информации будет сохранена в ячейке памяти. Для этого используется сигмоида для определения, какие значения должны пройти, и тангенс гиперболический (tanh), чтобы создать кандидатов на обновление состояния.</li>
          </ul>
        </li>
        <li>
          <b>Забывающий вентиль:</b>
          <ul>
            <li>Определяет, какую часть информации из ячейки памяти следует забыть. Это необходимо для того, чтобы ячейка памяти могла адаптироваться к новым входным данным и не сохраняла устаревшую информацию.</li>
          </ul>
        </li>
        <li>
          <b>Обновление ячейки памяти:</b>
          <ul>
            <li>Комбинирует информацию, прошедшую через входной вентиль, с текущим состоянием ячейки памяти (после применения забывающего вентиля).</li>
          </ul>
        </li>
        <li>
          <b>Вентиль выхода:</b>
          <ul>
            <li>Определяет, какая часть информации из ячейки памяти будет использована для предсказания текущего состояния. Это позволяет сети принимать решения на основе как текущей, так и долгосрочной информации.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Применение LSTM</b><br>LSTM находят широкое применение в различных задачах, связанных с последовательными данными:
        <li>
          <b>Обработка текста:</b>
          <ul>
            <li><b>Пример:</b> Языковое моделирование, машинный перевод, генерация текста.</li>
            <li><b>Преимущества:</b> Способность моделировать долгосрочные зависимости в тексте.</li>
          </ul>
        </li>
        <li>
          <b>Анализ временных рядов:</b>
          <ul>
            <li><b>Пример:</b> Прогнозирование финансовых данных, мониторинг здоровья пациентов.</li>
            <li><b>Преимущества:</b> Возможность учитывать как краткосрочные, так и долгосрочные паттерны.</li>
          </ul>
        </li>
        <li>
          <b>Распознавание речи:</b>
          <ul>
            <li><b>Пример:</b> Преобразование речи в текст, распознавание команд.</li>
            <li><b>Преимущества:</b> Эффективное управление изменениями во времени и шумом.</li>
          </ul>
        </li>
        <li>
          <b>Видео анализ:</b>
          <ul>
            <li><b>Пример:</b> Анализ действий в видеопотоках, классификация видео</li>
            <li><b>Преимущества:</b> Способность моделировать динамические изменения во времени.</li>
          </ul>
        </li>
        <li>
          <b>Моделирование последовательностей событий:</b>
          <ul>
            <li><b>Пример:</b> Обработка последовательностей событий в биологических системах или социальных сетях.</li>
            <li><b>Преимущества:</b> Учет как временных интервалов, так и контекстных зависимостей.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Проблемы и ограничения LSTM</b><br>Несмотря на преимущества, LSTM имеют свои ограничения:
        <li>
          <b>Трудоемкость вычислений:</b>
          <ul>
            <li>Требуют значительных вычислительных ресурсов и времени для обучения.</li>
          </ul>
        </li>
        <li>
          <b>Трудность в обучении на очень длинных последовательностях:</b>
          <ul>
            <li>Хотя LSTM лучше стандартных RNN в этом отношении, очень длинные зависимости все еще могут представлять проблему.</li>
          </ul>
        </li>
        <li>
          <b>Параметрическая сложность:</b>
          <ul>
            <li>Большое количество параметров увеличивает риск переобучения и требует тщательной настройки гиперпараметров.</li>
          </ul>
        </li>
      </ol><br><br>
      <ul>
        <b>Варианты и улучшения LSTM</b>
        <li>
          <b>Bidirectional LSTM (BiLSTM):</b>
          <ul>
            <li>Позволяет учитывать информацию как из прошлого, так и из будущего, обрабатывая последовательность в обоих направлениях.</li>
          </ul>
        </li>
        <li>
          <b>Gated Recurrent Unit (GRU):</b>
          <ul>
            <li>Упрощенная версия LSTM, которая включает только два вентиля (входной и забывающий), что снижает вычислительную сложность и улучшает эффективность.</li>
          </ul>
        </li>
      </ul>
      <br>
      <p>LSTM представляет собой мощный инструмент для работы с последовательными данными, предлагая эффективное решение проблем затухания и взрывания градиентов, которые характерны для стандартных RNN. С их помощью можно решать широкий спектр задач, от обработки текста и временных рядов до анализа видео и распознавания речи. Несмотря на свои преимущества, LSTM требует значительных вычислительных ресурсов и тщательной настройки для достижения наилучших результатов.</p>
      <br><p><b>Инициализация весов</b></p>
      <p>Правильная инициализация весов является критически важной для обучения LSTM. Обычно используются методы, такие как инициализация Ксавье (Xavier initialization) или инициализация Хе (He initialization), которые помогают в более стабильном старте процесса обучения и предотвращают проблемы, связанные с затуханием или взрывом градиентов.</p>
      <br>
      <ol>
        <b>Регуляризация</b><br>Для предотвращения переобучения при использовании LSTM могут применяться различные методы регуляризации:
        <li>
          <b>Dropout:</b>
          <ul>
            <li>Применение Dropout на выходах скрытых слоев LSTM помогает снизить риск переобучения, отключая случайные нейроны на каждом этапе обучения.</li>
          </ul>
        </li>
        <li>
          <b>L2-регуляризация:</b>
          <ul>
            <li>Добавление L2-регуляризации к функции потерь для контроля величины весов и предотвращения их чрезмерного увеличения.</li>
          </ul>
        </li>
      </ol><br>
      <p><b>Многослойные LSTM</b></p>
      <p>Использование нескольких слоев LSTM может улучшить способность модели к захвату сложных паттернов в данных. Однако это увеличивает вычислительные затраты и требует осторожного подхода к регуляризации и инициализации.</p>
      <ol>
        <b>Визуализация и интерпретация</b>
        <li>
          <b>Attention Mechanism:</b>
          <ul>
            <li>Визуализация внимания помогает понять, какие части входных данных наиболее важны для модели на каждом временном шаге. Это может быть особенно полезно для интерпретации моделей, работающих с текстом или временными рядами.</li>
          </ul>
        </li>
        <li>
          <b>Explaining Model Predictions:</b>
          <ul>
            <li>Использование методов объяснения, таких как SHAP (SHapley Additive exPlanations) или LIME (Local Interpretable Model-agnostic Explanations), помогает понять, как LSTM принимает решения и какие признаки наиболее важны для прогнозов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Гибридные модели</b><br>LSTM могут комбинироваться с другими типами нейронных сетей для решения сложных задач:
        <li>
          <b>CNN + LSTM:</b>
          <ul>
            <li>Комбинирование сверточных нейронных сетей (CNN) для извлечения пространственных признаков из данных (например, изображений) с LSTM для обработки временных аспектов.</li>
          </ul>
        </li>
        <li>
          <b>LSTM + Attention:</b>
          <ul>
            <li>Добавление механизма внимания к LSTM улучшает способность модели фокусироваться на значимых частях последовательности, что особенно полезно в задачах машинного перевода и обобщения текста.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Применение LSTM в промышленности</b>
        <li>
          <b>Финансовые прогнозы:</b>
          <ul>
            <li>Использование LSTM для прогнозирования цен на акции, анализ временных рядов финансовых данных и обнаружение аномалий.</li>
          </ul>
        </li>
        <li>
          <b>Интернет вещей (IoT):</b>
          <ul>
            <li>Применение LSTM для анализа временных рядов данных, поступающих от сенсоров, и прогнозирования технического обслуживания оборудования.</li>
          </ul>
        </li>
        <li>
          <b>Медицина:</b>
          <ul>
            <li>Прогнозирование состояния пациентов на основе временных рядов биомедицинских данных, анализ ЭКГ и ЭЭГ для диагностики заболеваний.</li>
          </ul>
        </li>
        <li>
          <b>Автоматизация и робототехника:</b>
          <ul>
            <li>Использование LSTM для прогнозирования движений, управления роботами и анализа временных рядов данных от сенсоров.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Адаптивные и онлайн-обучение</b>
        <li>
          <b>Online Learning:</b>
          <ul>
            <li>LSTM могут быть адаптированы для онлайн-обучения, где модель обучается и обновляется в реальном времени по мере поступления новых данных.</li>
          </ul>
        </li>
        <li>
          <b>Transfer Learning:</b>
          <ul>
            <li>Применение методов трансферного обучения для переноса знаний, полученных на одном наборе данных, на другой, что позволяет значительно сократить время и ресурсы, необходимые для обучения.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Оптимизация и ускорение</b>
        <li>
          <b>Параллелизация:</b>
          <ul>
            <li>Использование GPU для ускорения обучения LSTM. Современные библиотеки, такие как TensorFlow и PyTorch, поддерживают эффективное распределение вычислений на GPU.</li>
          </ul>
        </li>
        <li>
          <b>Аппаратные ускорители:</b>
          <ul>
            <li>Применение специализированных аппаратных решений, таких как TPU (Tensor Processing Unit) от Google, для дальнейшего ускорения процесса обучения и инференса.</li>
          </ul>
        </li>
      </ol>
    </div>
  </details>

  <!-- 23 -->
  <details class="details">
    <summary class="details__title">Создание и разработка телеграм-бота.</summary>
    <div class="details__content">
      <p>Телеграм-боты – это программы, которые взаимодействуют с пользователями через интерфейс мессенджера Telegram. Боты могут выполнять различные задачи, такие как предоставление информации, автоматизация процессов, развлечение пользователей и даже выполнение сложных бизнес-операций. Разработка телеграм-ботов включает несколько ключевых шагов: регистрация бота, настройка вебхуков или лонг-поллинга, программирование логики и разворачивание бота.</p>
      <br>
      <p><b>Шаг 1: Регистрация бота</b></p>
      <ol>
        <b>Создание бота в Telegram:</b>
        <ul>
          <li>Для регистрации нового бота необходимо использовать @BotFather – официальный бот Telegram для управления ботами.</li>
          <li>После запуска @BotFather нужно использовать команду /newbot, следуя указаниям, ввести имя и уникальный юзернейм для бота.</li>
          <li>@BotFather выдаст токен доступа, который необходим для взаимодействия с Bot API. Этот токен следует хранить в безопасности и не передавать третьим лицам.</li>
        </ul>
      </ol>
      <br><p><b>Шаг 2: Настройка окружения</b></p>
      <ol><b>Выбор языка программирования и библиотеки:</b>
        <li>
          Для разработки телеграм-ботов можно использовать различные языки программирования. <br>Наиболее популярные библиотеки включают:
          <ul>
            <li><b>Python:</b> python-telegram-bot, telepot, aiogram</li>
            <li><b>JavaScript:</b> node-telegram-bot-api</li>
            <li><b>Java:</b> telegrambots</li>
            <li><b>Go:</b> tgbotapi</li>
          </ul>
        </li>
        <li>
          <b>Установка библиотеки:</b>
          <ul>
            <li>
              Например, для Python можно установить библиотеку python-telegram-bot командой: <br><code>pip install python-telegram-bot</code></li>
          </ul>
        </li>
      </ol>
      <br><p><b>Шаг 3: Разработка логики бота</b></p>
      <ol>
        <li>
          <b>Основные компоненты бота:</b>
          <ul>
            <li>Обработчики сообщений (Message Handlers): Определяют, как бот будет реагировать на различные типы сообщений (текст, фото, видео и т.д.).</li>
            <li>Команды (Commands): Специальные сообщения, начинающиеся с /, например /start, которые вызывают определенные функции бота.</li>
            <li>Inline Mode: Позволяет пользователям взаимодействовать с ботом, не переходя в его чат напрямую.</li>
            <li>Callback Queries: Обрабатывают нажатия кнопок, встроенных в сообщения.</li>
          </ul>
        </li>
        <li>
          <b>Пример базового обработчика команд:</b>
          <ul>
            <li>
              <b>В Python с использованием библиотеки python-telegram-bot</b><br>
              <code>
                from telegram import Update <br>
                from telegram.ext import Updater, CommandHandler, CallbackContext <br>
                <br>              
                def start(update: Update, context: CallbackContext) -> None: <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;update.message.reply_text('Привет! Я ваш Телеграм-бот.') <br>
                <br>              
                updater = Updater('YOUR TOKEN HERE') <br>
                <br>              
                dispatcher = updater.dispatcher <br>
                dispatcher.add_handler(CommandHandler("start", start)) <br>
                <br>              
                updater.start_polling() <br>
                updater.idle()
              </code>
            </li>
          </ul>
        </li>
      </ol>
      <br><p><b>Шаг 4: Вебхуки и лонг-поллинг</b></p>
      <ol>
        <li><b>Лонг-поллинг (Long Polling):</b>
          <ul>
            <li>Метод, при котором бот постоянно запрашивает обновления от сервера Telegram. Это простой способ разработки и развертывания бота, подходящий для небольших проектов.</li>
          </ul>
        </li>
        <li><b>Вебхуки (Webhooks):</b>
          <ul>
            <li>Метод, при котором сервер Telegram отправляет обновления боту по указанному URL. Требует настройки веб-сервера для приема запросов и является более эффективным и масштабируемым способом.</li>
          </ul>
        </li>
      </ol>
      <br><p><b>Шаг 5: Развертывание бота</b></p>
      <ol>
        <li><b>Выбор платформы для хостинга:</b>
          <ul>
            <li><b>Heroku:</b> Популярный сервис для развертывания веб-приложений, поддерживающий различные языки программирования</li>
            <li><b>AWS:</b> Облачная платформа с широким спектром услуг, включая виртуальные серверы и базы данных.</li>
            <li><b>Google Cloud Platform (GCP):</b> Облачная платформа с мощными инструментами для разработки и развертывания приложений.</li>
            <li><b>Microsoft Azure:</b> Облачная платформа от Microsoft с поддержкой множества языков и сервисов.</li>
          </ul>
        </li>
        <li><b>Настройка и развертывание:</b>
          <ul>
            <li>Загрузка кода бота на выбранный хостинг.</li>
            <li>Настройка переменных окружения, включая токен доступа.</li>
            <li>Конфигурация вебхуков или лонг-поллинга в зависимости от выбранного метода.</li>
          </ul>
        </li>
      </ol>
      <br><p><b>Шаг 6: Безопасность и поддержка</b></p>
      <ol>
        <li><b>Безопасность:</b>
          <ul>
            <li><b>Хранение токена доступа:</b> Токен доступа должен храниться в защищенном месте, например, в переменных окружения.</li>
            <li><b>SSL/TLS:</b> Использование HTTPS для вебхуков обеспечивает защиту данных.</li>
            <li><b>Проверка входных данных:</b> Всегда проверяйте и валидируйте входные данные, чтобы избежать атак на бот.</li>
          </ul>
        </li>
        <li><b>Логирование и мониторинг:</b>
          <ul>
            <li>Настройка логирования для отслеживания активности и выявления ошибок.</li>
            <li>Использование инструментов мониторинга для наблюдения за производительностью бота и своевременного реагирования на инциденты.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Примеры использования телеграм-ботов</b>
        <li><b>Бизнес-боты:</b>
          <ul>
            <li>Автоматизация взаимодействия с клиентами, предоставление информации о продуктах и услугах, принятие заказов и бронирований.</li>
          </ul>
        </li>
        <li><b>Информационные боты:</b>
          <ul>
            <li>Рассылка новостей, уведомлений о погоде, курсов валют, спортивных результатов и других актуальных данных.</li>
          </ul>
        </li>
        <li><b>Образовательные боты:</b>
          <ul>
            <li>Организация курсов, проведение опросов и тестов, предоставление учебных материалов.</li>
          </ul>
        </li>
        <li><b>Развлекательные боты:</b>
          <ul>
            <li>Игры, викторины, генерация мемов и другие развлекательные функции.</li>
          </ul>
        </li>
        <li><b>Поддержка пользователей:</b>
          <ul>
            <li>Автоматизация службы поддержки, ответы на часто задаваемые вопросы, помощь в решении проблем.</li>
          </ul>
        </li>
      </ol>
      <p>Создание телеграм-бота требует понимания основ программирования, работы с API и навыков развертывания приложений. Боты могут значительно упростить многие процессы, автоматизировать задачи и улучшить взаимодействие с пользователями. При правильной реализации и поддержке, телеграм-боты могут стать мощным инструментом для бизнеса, образования и развлечений.</p>
      <br>
      <p><b>(Дополнительно)</b></p>
      <br>
      <ol>
        <b>Интерактивность и UX/UI Дизайн</b>
        <li>
          <b>Интерактивные элементы:</b>
          <ul>
            <li>
              <b>Клавиатуры:</b> Телеграм-боты могут использовать кастомные клавиатуры, чтобы упростить взаимодействие с пользователем. Важно продумать их структуру для улучшения UX.
              <ul>
                <li><b>Inline клавиатуры:</b> Встроены в сообщения и предоставляют кнопки для быстрого ответа или вызова определенной функции.</li>
                <li><b>Reply клавиатуры:</b> Отображаются под полем ввода и могут быть использованы для предустановленных ответов.
                </li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>Меню и навигация:</b>
          <ul>
            <li><b>Командное меню:</b> Важно предоставить пользователям интуитивно понятное меню команд, чтобы они могли легко найти нужные функции.</li>
            <li><b>Навигационные команды:</b> Разработайте команды для навигации по боту, такие как /help, /settings, /start, чтобы пользователи могли легко получить помощь или изменить настройки.</li>
          </ul>
        </li>
        <li>
          <b>Обработка мультимедийных данных:</b>
          <ul>
            <li>Телеграм-боты могут принимать и обрабатывать текстовые сообщения, изображения, видео, аудиофайлы и документы. Это открывает широкий спектр возможностей для интерактивных приложений, например, ботов для распознавания изображений или обработки аудиозаписей.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Интеграция с внешними сервисами</b>
        <li><b>API и внешние системы:</b>
          <ul>
            <li>Боты могут интегрироваться с различными внешними системами и API для получения данных в реальном времени. Например, интеграция с API погоды для предоставления текущей метеоинформации.</li>
            <li>Web Scraping: Использование методов веб-скрейпинга для получения данных с сайтов, которые не предоставляют API.</li>
          </ul>
        </li>
        <li><b>Базы данных:</b>
          <ul>
            <li>Хранение данных пользователей и их взаимодействий с ботом в базах данных. Для этого могут использоваться реляционные базы данных (например, PostgreSQL, MySQL) или NoSQL базы данных (например, MongoDB, Redis).</li>
          </ul>
        </li>
        <li><b>Облачные сервисы:</b>
          <ul>
            <li>Использование облачных сервисов для хранения данных, выполнения вычислений и обработки запросов. Например, Google Cloud, AWS, Microsoft Azure.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Обработка естественного языка (NLP)</b>
        <li><b>Интеграция с NLP библиотеками:</b>
          <ul>
            <li>Использование библиотек и сервисов для обработки естественного языка, таких как SpaCy, NLTK, или облачные решения, например, Dialogflow от Google или IBM Watson.</li>
          </ul>
        </li>
        <li><b>Chatbot Frameworks:</b>
          <ul>
            <li>Использование фреймворков для создания чат-ботов, таких как Rasa или Microsoft Bot Framework, которые предоставляют инструменты для построения более сложных и интерактивных ботов с использованием NLP.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Тестирование и отладка</b>
        <li><b>Автоматическое тестирование:</b>
          <ul>
            <li>Разработка автоматических тестов для проверки функциональности бота. Это может включать тестирование команд, обработки сообщений и взаимодействий с внешними сервисами.</li>
          </ul>
        </li>
        <li><b>Отладка:</b>
          <ul>
            <li>Логирование всех операций бота, включая входящие сообщения и ответы. Использование отладочных инструментов для мониторинга работы бота в реальном времени.</li>
          </ul>
        </li>
        <li><b>Юнит-тестирование:</b>
          <ul>
            <li>Написание юнит-тестов для отдельных компонентов бота с целью выявления и исправления ошибок на ранних этапах разработки.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Масштабируемость и производительность</b>
        <li><b>Кеширование:</b>
          <ul>
            <li>Использование кеширования для повышения производительности. Например, Redis или Memcached для хранения временных данных и уменьшения количества обращений к базе данных.</li>
          </ul>
        </li>
        <li><b>Масштабируемость:</b>
          <ul>
            <li>Развертывание бота на кластере серверов для обработки большого объема запросов. Использование оркестрации контейнеров с помощью Kubernetes или Docker Swarm для управления масштабируемостью.</li>
          </ul>
        </li>
        <li><b>Оптимизация производительности:</b>
          <ul>
            <li>Анализ производительности и оптимизация кода. Использование профайлеров для выявления узких мест и оптимизации работы бота.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Совместимость и доступность</b>
        <li><b>Мультиязычность:</b>
          <ul>
            <li>Реализация поддержки нескольких языков для бота. Это включает создание локализаций и возможность переключения между языками на лету.</li>
          </ul>
        </li>
        <li><b>Доступность:</b>
          <ul>
            <li>Учет аспектов доступности для пользователей с ограниченными возможностями. Это может включать поддержку текстового ввода вместо голосовых команд и предоставление альтернативных текстов для изображений.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Этические аспекты и конфиденциальность</b>
        <li><b>Конфиденциальность данных:</b>
          <ul>
            <li>Соблюдение правил и регуляций по защите данных, таких как GDPR. Убедитесь, что данные пользователей хранятся и обрабатываются безопасно и в соответствии с законодательством.</li>
          </ul>
        </li>
        <li><b>Этические аспекты:</b>
          <ul>
            <li>Разработка бота с учетом этических норм. Это включает в себя избегание дискриминационных практик и обеспечение того, чтобы бот не использовался для мошенничества или распространения вредоносного контента.</li>
          </ul>
        </li>
        <li><b>Согласие пользователей:</b>
          <ul>
            <li>Получение явного согласия пользователей на сбор и обработку их данных. Обеспечение прозрачности в отношении того, как и для чего используются данные.</li>
          </ul>
        </li>
      </ol>
    </div>
  </details>

  <!-- 24 -->
  <details class="details">
    <summary class="details__title">Функции и кнопки телеграм-бота. Взаимодействие с ботом.</summary>
    <div class="details__content">
      <p>Функции и кнопки телеграм-бота играют ключевую роль в взаимодействии с пользователями, делая бота более интерактивным и удобным в использовании. Они позволяют создавать структурированные диалоги, предоставлять быстрый доступ к различным функциям и улучшать пользовательский опыт.</p>
      <ol>
        <b>Основные функции телеграм-бота</b>
        <li><b>Обработка команд:</b>
          <ul>
            <li>Телеграм-боты поддерживают команды, начинающиеся с символа "/", такие как /start, /help, /settings. Эти команды активируют определенные функции или отправляют пользователю предопределенные сообщения.</li>
            <li>
              <b>Примеры:</b>
              <ul>
                <li>/start - Приветственное сообщение и инструкции по использованию бота.</li>
                <li>/help - Список доступных команд и функций бота.</li>
                <li>/settings - Настройки пользователя, такие как язык или уведомления.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li><b>Обработка текстовых сообщений:</b>
          <ul>
            <li>Боты могут обрабатывать текстовые сообщения от пользователей, анализировать их содержание и отвечать на основе запроса.</li>
            <li>Использование библиотек для обработки естественного языка (NLP) может значительно улучшить понимание и реагирование на запросы пользователей.</li>
          </ul>
        </li>
        <li><b>Работа с мультимедиа:</b>
          <ul>
            <li>Боты могут отправлять и принимать фотографии, видео, аудиофайлы, документы и другие типы медиафайлов.</li>
            <li>
              <b>Примеры использования:</b>
              <ul>
                <li>Отправка пользователю изображения с графиком или инфографикой.</li>
                <li>Получение фотографии для анализа (например, распознавание текста или объектов).</li>
              </ul>
            </li>
          </ul>
        </li>
        <li><b>Интерактивные элементы:</b>
          <ul>
            <li><b>Inline клавиатуры:</b> Кнопки, встроенные в сообщения, которые можно использовать для выполнения различных действий без необходимости вводить текстовые команды.</li>
            <li><b>Reply клавиатуры:</b> Кнопки, которые отображаются под полем ввода и позволяют пользователю быстро выбирать варианты ответа.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Типы кнопок и их использование</b>
        <li><b>Inline клавиатуры:</b>
          <ul>
            <li>Inline клавиатуры позволяют добавлять кнопки непосредственно в сообщение. Эти кнопки могут выполнять различные действия, такие как отправка callback-запросов или открытие URL-адресов.</li>
            <li>
              <b>Примеры использования:</b>
              <ul>
                <li>Вопросы с несколькими вариантами ответов.</li>
                <li>Кнопки для навигации по меню или запуску определенных функций.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li><b>Reply клавиатуры:</b>
          <ul>
            <li>Клавиатуры, которые отображаются под полем ввода текста и предоставляют пользователю предустановленные варианты ответов.</li>
            <li>
              <b>Примеры использования:</b>
              <ul>
                <li>Быстрый выбор предопределенных команд или опций.</li>
                <li>Упрощение взаимодействия для пользователей, предоставляя готовые варианты ответа.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li><b>Callback-кнопки:</b>
          <ul>
            <li>Кнопки, которые отправляют данные обратно на сервер при нажатии. Сервер может обрабатывать эти данные и отправлять соответствующий ответ.</li>
            <li>
              <b>Примеры использования:</b>
              <ul>
                <li>Подтверждение действий (например, "Подтвердить" или "Отменить").</li>
                <li>Интерактивные опросы или голосования.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li><b>URL-кнопки:</b>
          <ul>
            <li>Кнопки, которые открывают указанный URL-адрес при нажатии.</li>
            <li>
              <b>Примеры использования:</b>
              <ul>
                <li>Перенаправление на сайт для получения дополнительной информации.</li>
                <li>Открытие внешних ресурсов или сервисов.</li>
              </ul>
            </li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Взаимодействие с ботом</b>
        <li><b>Процесс взаимодействия:</b>
          <ul>
            <li>Пользователь отправляет сообщение или команду боту.</li>
            <li>Бот обрабатывает входящее сообщение и определяет, какое действие нужно выполнить.</li>
            <li>В зависимости от контекста и содержимого сообщения бот отправляет ответное сообщение, выполняет команду или предлагает варианты действий через кнопки.</li>
          </ul>
        </li>
        <li><b>Примеры сценариев взаимодействия:</b>
          <ul>
            <li>Информационные боты: Пользователь отправляет запрос на получение информации (например, погода, курсы валют), бот обрабатывает запрос и отправляет соответствующий ответ.</li>
            <li>Боты для заказов: Пользователь выбирает товар из списка, добавляет его в корзину и подтверждает заказ через встроенные кнопки.</li>
            <li>Образовательные боты: Пользователь получает учебные материалы, проходит тесты или викторины, используя интерактивные кнопки для ответов.</li>
          </ul>
        </li>
        <li><b>Контекстное взаимодействие:</b>
          <ul>
            <li>Боты могут отслеживать контекст общения и адаптировать свои ответы в зависимости от предыдущих сообщений пользователя.</li>
            <li>Это позволяет создавать более сложные сценарии взаимодействия, такие как опросы, анкеты или диалоги с несколькими этапами.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Технические аспекты реализации кнопок и функций</b>
        <li><b>Настройка Inline клавиатур:</b>
          <ul>
            <li>Создание и отправка inline клавиатур с помощью методов библиотеки Telegram API. Это включает создание объектов клавиатуры и кнопок, а затем их привязку к сообщениям.</li>
          </ul>
        </li>
        <li><b>Обработка callback-запросов:</b>
          <ul>
            <li>Callback-запросы обрабатываются ботом, который определяет действие, связанное с нажатием кнопки, и выполняет соответствующую функцию.</li>
          </ul>
        </li>
        <li><b>Создание и настройка Reply клавиатур:</b>
          <ul>
            <li>Reply клавиатуры создаются и настраиваются через Telegram API. Они позволяют пользователю быстро выбирать предопределенные варианты ответов.</li>
          </ul>
        </li>
        <li><b>Обработка мультимедиа:</b>
          <ul>
            <li>Телеграм-боты могут отправлять и принимать различные типы мультимедийных данных, используя методы API для загрузки и отправки файлов.</li>
          </ul>
        </li>
      </ol><br>
      <p>Функции и кнопки телеграм-бота значительно расширяют возможности взаимодействия с пользователями, делая ботов более интерактивными и удобными. Понимание и правильное использование этих инструментов позволяет создавать эффективные и полезные телеграм-боты, которые могут решать широкий спектр задач, от предоставления информации до автоматизации бизнес-процессов.</p>
    </div>
  </details>

  <!-- 25 -->
  <details class="details">
    <summary class="details__title">Методы распознавания и генерации речи.</summary>
    <div class="details__content">
      <p>Распознавание и генерация речи являются ключевыми задачами в области обработки естественного языка и искусственного интеллекта. Они играют важную роль в создании голосовых помощников, систем автоматического перевода, голосового управления и других приложений.</p>
      <p><b>Распознавание речи</b></p>
      <p>Распознавание речи (ASR, Automatic Speech Recognition) — это процесс преобразования устной речи в текст. Современные системы ASR используют сложные алгоритмы машинного обучения и глубокие нейронные сети для достижения высокой точности</p>
      <br>
      <ol>
        <b>Основные этапы распознавания речи</b>
        <li><b>Предварительная обработка сигнала:</b>
          <ul>
            <li><b>Шумоподавление:</b> Удаление фонового шума для улучшения качества сигнала.</li>
            <li><b>Нормализация </b>громкости: Приведение уровня громкости к стандартному значению.</li>
            <li><b>Фильтрация:</b> Удаление ненужных частотных компонентов.</li>
          </ul>
        </li>
        <li><b>Извлечение признаков:</b>
          <ul>
            <li><b>MFCC (Mel-frequency cepstral coefficients):</b> Один из наиболее распространенных методов извлечения признаков, который преобразует сигнал в набор коэффициентов, характеризующих его спектральные свойства.</li>
            <li><b>Spectrogram:</b> Визуализация частотных компонентов сигнала во времени, часто используемая в современных нейронных сетях.</li>
          </ul>
        </li>
        <li><b>Модели акустики:</b>
          <ul>
            <li><b>Глубокие нейронные сети (DNN):</b> Используются для моделирования отношения между акустическими сигналами и фонемами.</li>
            <li><b>Рекуррентные нейронные сети (RNN):</b> Способны учитывать временные зависимости в звуковых сигналах.</li>
            <li><b>Трансформеры:</b> Современные архитектуры, такие как Wav2Vec 2.0 от Facebook, используют трансформеры для обработки речевых сигналов.</li>
          </ul>
        </li>
        <li><b>Языковые модели:</b>
          <ul>
            <li><b>N-gram модели:</b> Примитивные статистические модели, которые оценивают вероятность последовательности слов.</li>
            <li><b>Рекуррентные нейронные сети (RNN) и LSTM:</b> Более продвинутые модели, способные учитывать контекст и зависимость между словами.</li>
            <li><b>Трансформеры:</b> Используются в современных системах для моделирования языкового контекста с высокой точностью.</li>
          </ul>
        </li>
        <li><b>Декодирование:</b>
          <ul>
            <li>Преобразование последовательности акустических признаков в текст с использованием языковых моделей и алгоритмов поиска, таких как Viterbi или Beam Search.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Примеры технологий и инструментов распознавания речи</b>
        <li><b>Google Speech-to-Text:</b> Облачный сервис от Google, предоставляющий API для распознавания речи с высокой точностью.</li>
        <li><b>IBM Watson Speech to Text:</b> Решение от IBM, предоставляющее возможности распознавания речи и анализа аудиозаписей.</li>
        <li><b>Kaldi:</b> Открытая платформа для построения систем распознавания речи, широко используемая в научных исследованиях.</li>
        <li><b>CMU Sphinx:</b> Один из старейших и наиболее популярных инструментов для распознавания речи.</li>
      </ol><br>
      <p><b>Генерация речи</b></p>
      <p>Генерация речи (TTS, Text-to-Speech) — это процесс преобразования текста в синтетическую речь. Современные системы TTS стремятся производить речь, максимально приближенную к естественной, с правильной интонацией и акцентом.</p>
      <br>
      <ol>
        <b>Основные этапы генерации речи</b>
        <li><b>Предварительная обработка текста:</b>
          <ul>
            <li><b>Токенизация:</b> Разделение текста на отдельные слова или токены.</li>
            <li><b>Нормализация:</b> Преобразование чисел, сокращений и других специальных символов в текстовую форму.</li>
            <li><b>Разметка ударений:</b> Определение правильного ударения в словах для сохранения интонации.</li>
          </ul>
        </li>
        <li><b>Лингвистический анализ:</b>
          <ul>
            <li><b>Синтаксический анализ:</b> Определение грамматической структуры предложения.</li>
            <li><b>Семантический анализ:</b> Определение смысла и контекста текста.</li>
          </ul>
        </li>
        <li><b>Акустическая модель:</b>
          <ul>
            <li><b>Глубокие нейронные сети (DNN):</b> Используются для преобразования текста в последовательность фонем с учетом интонации и акцента.</li>
            <li><b>Рекуррентные нейронные сети (RNN):</b> Способны моделировать временные зависимости и интонационные паттерны.</li>
            <li><b>Трансформеры:</b> Современные архитектуры, такие как Tacotron и Transformer TTS, используют трансформеры для синтеза высококачественной речи.</li>
          </ul>
        </li>
        <li><b>Вокодеры:</b>
          <ul>
            <li><b>Griffin-Lim Algorithm:</b> Один из традиционных алгоритмов преобразования спектрограмм в аудиосигнал.</li>
            <li><b>WaveNet:</b> Глубокая нейронная сеть от Google, которая генерирует аудиосигнал с высокой точностью.</li>
            <li><b>WaveGlow и HiFi-GAN:</b> Современные вокодеры, обеспечивающие высокое качество синтезируемой речи.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Примеры технологий и инструментов генерации речи</b>
        <li><b>Google Text-to-Speech:</b> Облачный сервис от Google, предоставляющий API для генерации высококачественной речи.</li>
        <li><b>Amazon Polly:</b> Сервис от AWS, предлагающий возможности синтеза речи с поддержкой множества языков и голосов.</li>
        <li><b>Microsoft Azure Text to Speech:</b> Решение от Microsoft для генерации речи с высокой степенью натуралистичности.</li>
        <li><b>Festival:</b> Открытый фреймворк для синтеза речи, разработанный в Университете Эдинбурга.</li>
        <li><b>Mozilla TTS:</b> Открытый проект от Mozilla для синтеза речи на основе современных нейронных сетей.</li>
      </ol><br><br>
      <ol>
        <b>Применения и перспективы</b><br>Распознавание и генерация речи находят применение в самых разных областях:
        <li><b>Голосовые ассистенты:</b>
          <ul>
            <li>Google Assistant, Amazon Alexa, Apple Siri: Используют ASR и TTS для взаимодействия с пользователями.</li>
          </ul>
        </li>
        <li><b>Автоматические системы перевода:</b>
          <ul>
            <li>Интеграция ASR и TTS для создания систем, которые могут переводить речь в реальном времени.</li>
          </ul>
        </li>
        <li><b>Интерактивные голосовые системы (IVR):</b>
          <ul>
            <li>Используются в колл-центрах для автоматизации обработки звонков.</li>
          </ul>
        </li>
        <li><b>Образование и доступность:</b>
          <ul>
            <li>Системы TTS помогают людям с нарушениями зрения, а ASR может использоваться для создания субтитров в реальном времени.</li>
          </ul>
        </li>
        <li><b>Медицинские приложения:</b>
          <ul>
            <li>Распознавание речи для записи медицинских осмотров и консультаций.</li>
            <li>Генерация речи для автоматических напоминаний и инструкций пациентам.</li>
          </ul>
        </li>
      </ol><br>
      <p>Распознавание и генерация речи — это сложные, но чрезвычайно важные задачи, которые продолжают развиваться благодаря достижениям в области машинного обучения и глубоких нейронных сетей. Современные технологии предоставляют инструменты для создания высокоточных и натуралистичных систем, которые могут значительно улучшить взаимодействие человека с машинами и открыть новые возможности в различных областях применения.</p>

    </div>
  </details>

  <!-- 26 -->
  <details class="details">
    <summary class="details__title">ChatGPT. Основы дообучения. Роли ChatGPT.</summary>
    <div class="details__content">
      <p>ChatGPT, разработанный OpenAI, является одной из самых продвинутых моделей для обработки естественного языка (NLP), основанной на архитектуре трансформеров. В основе ChatGPT лежит архитектура GPT (Generative Pre-trained Transformer), которая использует глубокое обучение для генерации текста на основе заданного ввода.</p>
      <br>
      <ol>
        <b>Основы архитектуры GPT</b>
        <li><b>Архитектура трансформера:</b>
          <ul>
            <li>Трансформер состоит из энкодеров и декодеров, но GPT использует только декодер.</li>
            <li>Трансформеры применяют механизм внимания (attention mechanism), который позволяет модели уделять внимание различным частям входного текста, улучшая понимание контекста.</li>
          </ul>
        </li>
        <li><b>Предварительное обучение (Pre-training):</b>
          <ul>
            <li>Модель обучается на большом объеме текстовых данных, чтобы предсказывать следующее слово в предложении. Это помогает модели понять структуру языка и различные паттерны текста.</li>
            <li>В процессе предварительного обучения используются огромные текстовые корпуса, такие как статьи, книги и другие письменные материалы.</li>
          </ul>
        </li>
        <li><b>Дообучение (Fine-tuning):</b>
          <ul>
            <li>После предварительного обучения модель дообучается на более специализированных данных с использованием методов надзора (supervised learning) или активного обучения (reinforcement learning).</li>
            <li>В дообучении используются специализированные датасеты, которые могут быть аннотированы людьми для конкретных задач, таких как вопросы-ответы, диалоговые системы или другие приложения.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Основы дообучения ChatGPT</b><br>Дообучение (fine-tuning) модели ChatGPT включает несколько ключевых шагов:
        <li><b>Сбор и подготовка данных:</b>
          <ul>
            <li>Данные для дообучения должны быть релевантны и высококачественны. Они могут включать диалоги, транскрипты, статьи и любые другие тексты, соответствующие задачам дообучения.</li>
            <li>Данные могут быть аннотированы для конкретных целей, таких как классификация, генерация текста или ответы на вопросы.</li>
          </ul>
        </li>
        <li><b>Аннотация данных:</b>
          <ul>
            <li>Данные могут быть размечены вручную экспертами для создания эталонных ответов, которые затем используются в процессе дообучения.</li>
            <li>Используются различные техники, такие как метки (labels), для указания модели, что она должна делать в каждом конкретном случае.</li>
          </ul>
        </li>
        <li><b>Процесс дообучения:</b>
          <ul>
            <li>В процессе дообучения модель обучается на новых данных, корректируя свои веса и параметры для улучшения производительности на конкретных задачах.</li>
            <li>Используются методы градиентного спуска (gradient descent) и обратного распространения ошибки (backpropagation) для обновления параметров модели.</li>
          </ul>
        </li>
        <li><b>Оценка и валидация:</b>
          <ul>
            <li>После дообучения модель проверяется на тестовых данных для оценки ее производительности.</li>
            <li>Метрики, такие как точность (accuracy), полнота (recall), F-мера (F1-score), используются для оценки качества модели.</li>
            <li>При необходимости модель может быть дополнительно дообучена (fine-tuned) для улучшения производительности.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <ol>
        <b>Роли ChatGPT</b><br>ChatGPT выполняет различные роли в зависимости от задачи и области применения:
        <li><b>Виртуальный ассистент:</b>
          <ul>
            <li>ChatGPT может использоваться в качестве виртуального ассистента для ответов на вопросы, предоставления информации и помощи пользователям в различных задачах.</li>
            <li>Примеры: Alexa, Siri, Google Assistant.</li>
          </ul>
        </li>
        <li><b>Образовательные приложения:</b>
          <ul>
            <li>Модель может использоваться для создания интерактивных образовательных приложений, таких как учебные пособия, помощь в изучении языков и предоставление образовательных материалов.</li>
            <li>Примеры: Duolingo, интерактивные учебные пособия.</li>
          </ul>
        </li>
        <li><b>Поддержка клиентов:</b>
          <ul>
            <li>ChatGPT может быть использован для автоматизации поддержки клиентов, обработки запросов, решения проблем и предоставления информации.</li>
            <li>Примеры: чат-боты в интернет-магазинах, банковских системах, службах поддержки.</li>
          </ul>
        </li>
        <li><b>Медицинские приложения:</b>
          <ul>
            <li>Модель может быть использована для предоставления информации о здоровье, помощи в диагностике и предоставления рекомендаций по лечению.</li>
            <li>Примеры: приложения для консультаций с врачами, системы поддержки принятия решений в медицине.</li>
          </ul>
        </li>
        <li><b>Творческие приложения</b>
          <ul>
            <li>ChatGPT может использоваться для создания контента, написания статей, сценариев, историй и других творческих задач.</li>
            <li>
              Примеры:
              <ul>
                <li>Контент-маркетинг: Создание блогов, статей, постов для социальных сетей и маркетинговых материалов.</li>
                <li>Литература: Написание рассказов, романов, стихов и других литературных произведений.</li>
                <li>Сценарии и диалоги: Разработка сценариев для фильмов, сериалов, видеоигр и театральных постановок.</li>
              </ul>
            </li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Применение ChatGPT в различных индустриях</b>
        <li><b>Индустрия развлечений:</b>
          <ul>
            <li>ChatGPT может генерировать диалоги для персонажей в видеоиграх, фильмах и телевизионных шоу, создавая более живые и интерактивные истории.</li>
          </ul>
        </li>
        <li><b>Финансовый сектор:</b>
          <ul>
            <li>Модель может предоставлять аналитические отчеты, прогнозы и советы по инвестициям, а также автоматизировать взаимодействие с клиентами в банках и страховых компаниях.</li>
          </ul>
        </li>
        <li><b>Электронная коммерция:</b>
          <ul>
            <li>ChatGPT может помочь в создании описаний продуктов, автоматизации поддержки клиентов, а также предоставлении рекомендаций по продуктам на основе анализа предпочтений пользователей</li>
          </ul>
        </li>
        <li><b>Медицина:</b>
          <ul>
            <li>Модель может использоваться для предоставления информации о заболеваниях, симптомах и лечении, а также для помощи врачам в диагностике и принятии решений.</li>
          </ul>
        </li>
        <li><b>Образование:</b>
          <ul>
            <li>ChatGPT может выступать в роли виртуального репетитора, помогать студентам с учебными материалами и предоставлять интерактивные образовательные ресурсы.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Этические и социальные аспекты</b><br>Использование ChatGPT также связано с рядом этических и социальных вопросов:
        <li><b>Конфиденциальность и безопасность данных:</b>
          <ul>
            <li>Важно обеспечить защиту личных данных пользователей и предотвратить утечку информации.</li>
          </ul>
        </li>
        <li><b>Биас и дискриминация:</b>
          <ul>
            <li>Модель может унаследовать предвзятости из данных, на которых она обучалась. Необходимо разрабатывать методы для минимизации таких предвзятостей и обеспечения справедливого использования модели.</li>
          </ul>
        </li>
        <li><b>Ответственность и контроль:</b>
          <ul>
            <li>Важно определить, кто несет ответственность за действия и решения, принятые на основе рекомендаций модели. Также необходимо разработать механизмы контроля за использованием модели.</li>
          </ul>
        </li>
        <li><b>Прозрачность и объяснимость:</b>
          <ul>
            <li>Пользователи должны понимать, как работает модель, и иметь возможность получать объяснения по поводу принимаемых ею решений</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Будущее ChatGPT</b><br>удущее ChatGPT и подобных моделей связано с дальнейшими улучшениями в области:
        <li>
          <b>Улучшение качества генерации текста:</b>
          <ul>
            <li>Развитие методов обучения и архитектур моделей для повышения качества и натуральности генерируемого текста.</li>
          </ul>
        </li>
        <li>
          <b>Мультизадачность и адаптивность:</b>
          <ul>
            <li>Способность модели выполнять широкий спектр задач и адаптироваться к новым задачам и контекстам без необходимости повторного обучения с нуля.</li>
          </ul>
        </li>
        <li>
          <b>Интеграция с другими технологиями:</b>
          <ul>
            <li>Интеграция ChatGPT с системами компьютерного зрения, анализа данных и другими ИИ-технологиями для создания более комплексных и функциональных решений.</li>
          </ul>
        </li>
        <li>
          <b>Этические и правовые нормы:</b>
          <ul>
            <li>Разработка и внедрение этических норм и правовых регуляций для использования ИИ в различных сферах жизни.</li>
          </ul>
        </li>
      </ol><br>
      <p>В заключение, ChatGPT является мощным инструментом для автоматизации и улучшения взаимодействия с пользователями в различных областях. Развитие и дообучение таких моделей открывает новые возможности, но также требует внимания к этическим и социальным аспектам их применения.</p>
    </div>
  </details>

  <!-- 27 -->
  <details class="details">
    <summary class="details__title">Обнаружение объектов. Принцип построения архитектуры YOLO.</summary>
    <div class="details__content">
      <p>Обнаружение объектов (Object Detection) — это задача компьютерного зрения, которая включает в себя идентификацию и локализацию объектов различных классов на изображении. В отличие от задачи классификации, которая просто определяет класс объекта на изображении, обнаружение объектов также определяет координаты рамки (bounding box) для каждого обнаруженного объекта.</p>
      <br>
      <p><b>Принципы построения архитектуры YOLO</b></p>
      <p>YOLO (You Only Look Once) — это один из самых известных и эффективных методов обнаружения объектов, предложенный Джозефом Редмоном и Али Фархади. Основная идея YOLO заключается в том, чтобы рассматривать обнаружение объектов как задачу регрессии, выполняемую единожды по всему изображению, в отличие от других методов, которые сканируют изображение несколькими проходами.</p>
      <br>
      <ol>
        <b>Основные концепции и принципы YOLO</b>
        <li><b>Единичный проход (Single Shot):</b>
          <ul>
            <li>YOLO делит изображение на SxS сетку. Каждая ячейка этой сетки предсказывает B ограничивающих рамок и оценки уверенности для этих рамок</li>
            <li>Предсказания включают координаты центра рамки (x, y), ее ширину и высоту (w, h), а также вероятность того, что рамка содержит объект.</li>
          </ul>
        </li>
        <li><b>Совместное предсказание классов и рамок:</b>
          <ul>
            <li>Вместо разделения задачи обнаружения объектов на две отдельные задачи (классификация и локализация), YOLO предсказывает классы объектов и рамки одновременно.</li>
            <li>Это позволяет модели более эффективно учитывать пространственные контексты объектов.</li>
          </ul>
        </li>
        <li><b>Конфигурация и архитектура:</b>
          <ul>
            <li>YOLO использует полностью сверточную нейронную сеть (FCNN), состоящую из нескольких сверточных слоев, за которыми следуют полностью связанные слои.</li>
            <li>Последний слой сети предсказывает выходной тензор, который включает координаты рамок, их размеры, оценки уверенности и вероятности классов.</li>
          </ul>
        </li>
        <li><b>Обучение модели:</b>
          <ul>
            <li>Модель обучается на больших размеченных наборах данных, таких как COCO или PASCAL VOC, с использованием функции потерь, которая учитывает ошибки в координатах рамок, их размерах и классификации объектов.</li>
            <li>Используются техники аугментации данных для повышения устойчивости модели к различным условиям.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Преимущества и особенности YOLO</b>
        <li>
          <b>Высокая скорость:</b>
          <ul>
            <li>YOLO является одним из самых быстрых методов обнаружения объектов, так как он выполняет предсказания за один проход по изображению.</li>
            <li>Это делает его подходящим для реальных приложений, требующих обработки видео в режиме реального времени.</li>
          </ul>
        </li>
        <li>
          <b>Конечный результат с точной локализацией:</b>
          <ul>
            <li>YOLO показывает хорошее соотношение между точностью и скоростью. Модель достигает высокой точности локализации объектов с меньшими ошибками.</li>
          </ul>
        </li>
        <li>
          <b>Универсальность:</b>
          <ul>
            <li>YOLO может быть обучен на различных наборах данных и применяться для обнаружения широкого спектра объектов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Этапы работы YOLO</b>
        <li>
          <b>Разбиение изображения на сетку:</b>
          <ul>
            <li>Изображение делится на сетку SxS. Каждая ячейка отвечает за предсказание объектов, центр которых находится внутри этой ячейки.</li>
          </ul>
        </li>
        <li>
          <b>Предсказание ограничивающих рамок и классов объектов:</b>
          <ul>
            <li>Для каждой ячейки предсказываются координаты B рамок, их размеры, оценки уверенности и вероятности классов.</li>
          </ul>
        </li>
        <li>
          <b>Объединение предсказаний (Non-Max Suppression):</b>
          <ul>
            <li>Используется метод подавления не максимальных значений (Non-Max Suppression) для устранения избыточных рамок и оставления только наиболее уверенных предсказаний.</li>
          </ul>
        </li>
        <li>
          <b>Постобработка результатов:</b>
          <ul>
            <li>Предсказания обрабатываются для получения окончательных координат рамок и классов объектов с наибольшей вероятностью.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Применение YOLO</b>
        <li>
          <b>Безопасность и мониторинг:</b>
          <ul>
            <li>YOLO используется в системах видеонаблюдения для обнаружения и отслеживания объектов, таких как люди или транспортные средства.</li>
          </ul>
        </li>
        <li>
          <b>Автономные транспортные средства:</b>
          <ul>
            <li>В автономных автомобилях YOLO применяется для обнаружения дорожных знаков, пешеходов и других транспортных средств.</li>
          </ul>
        </li>
        <li>
          <b>Медицинская диагностика:</b>
          <ul>
            <li>В медицинских приложениях YOLO может использоваться для обнаружения аномалий на медицинских изображениях, таких как рентгенограммы или МРТ.</li>
          </ul>
        </li>
        <li>
          <b>Робототехника:</b>
          <ul>
            <li>В робототехнике YOLO помогает роботам распознавать и взаимодействовать с объектами в окружающей среде.</li>
          </ul>
        </li>
      </ol><br>
      <p>YOLO представляет собой мощный и эффективный инструмент для обнаружения объектов, способный работать в режиме реального времени. Благодаря своей архитектуре, объединяющей предсказание рамок и классов объектов в один проход, YOLO обеспечивает высокую производительность и точность. Применение YOLO охватывает широкий спектр задач, от безопасности и мониторинга до медицинской диагностики и автономных транспортных средств.</p>
    </div>
  </details>

  <!-- 28 -->
  <details class="details">
    <summary class="details__title">Методы работы с изображениями и видео.</summary>
    <div class="details__content">
      <p>Работа с изображениями и видео включает множество методов, направленных на анализ, обработку, улучшение и извлечение информации. В области компьютерного зрения и машинного обучения используются различные подходы и технологии для решения задач, связанных с изображениями и видео.</p>
      <br>
      <ol>
        <b>Методы работы с изображениями</b>
        <li>
          <b>Основные операции на изображениях:</b>
          <ul>
            <li>Чтение и запись изображений: Использование библиотек, таких как OpenCV, PIL (Python Imaging Library) и scikit-image для загрузки и сохранения изображений.</li>
            <li>Преобразования: Изменение размера, вращение, обрезка и отражение изображений.</li>
            <li>Фильтрация и обработка изображений: Применение фильтров для сглаживания, улучшения контрастности, удаления шума и выделения крае</li>
          </ul>
        </li>
        <li>
          <b>Преобразования изображений:</b>
          <ul>
            <li>Преобразование Фурье: Применяется для анализа частотных характеристик изображения и фильтрации в частотной области.</li>
            <li>Преобразование Хафа: Используется для обнаружения прямых линий и окружностей.</li>
          </ul>
        </li>
        <li>
          <b>Цветовые пространства:</b>
          <ul>
            <li>RGB, HSV, Lab: Различные цветовые пространства для представления и обработки изображений. Преобразование между цветовыми пространствами позволяет решать различные задачи, такие как выделение объектов на основе цвета.</li>
          </ul>
        </li>
        <li>
          <b>Методы сегментации изображений:</b>
          <ul>
            <li>Пороговая сегментация: Разделение изображения на области на основе значений интенсивности.</li>
            <li>Сегментация на основе кластеризации: Методы, такие как k-средние и методы на основе Гауссовых смесей.</li>
            <li>Сегментация на основе глубокого обучения: Использование нейронных сетей, таких как U-Net и Mask R-CNN, для точной сегментации объектов.</li>
          </ul>
        </li>
        <li>
          <b>Методы обнаружения и распознавания объектов:</b>
          <ul>
            <li>Классические методы: Метод Виолы-Джонса для обнаружения лиц, HOG (гистограммы ориентированных градиентов) для обнаружения объектов.</li>
            <li>Глубокое обучение: Модели, такие как YOLO, SSD (Single Shot MultiBox Detector) и Faster R-CNN для обнаружения объектов в реальном времени.</li>
          </ul>
        </li>
        <li>
          <b>Обработка изображений с помощью нейронных сетей:</b>
          <ul>
            <li>Сверточные нейронные сети (CNN): Используются для классификации изображений, обнаружения объектов и сегментации.</li>
            <li>Глубокие генеративные модели: GAN (Generative Adversarial Networks) для создания новых изображений, улучшения качества и стиля изображений.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Методы работы с видео</b>
        <li>
          <b>Основные операции с видео:</b>
          <ul>
            <li>Чтение и запись видео: Использование OpenCV для захвата кадров из видеопотока и сохранения обработанного видео.</li>
            <li>Обработка видеокадров в реальном времени: Применение алгоритмов обработки изображений к каждому кадру видеопотока.</li>
          </ul>
        </li>
        <li>
          <b>Извлечение признаков и отслеживание объектов:</b>
          <ul>
            <li>Отслеживание объектов: Использование алгоритмов, таких как KLT-трекер (Kanade-Lucas-Tomasi), CSRT (Discriminative Correlation Filter with Channel and Spatial Reliability) и медианный поток (MedianFlow) для отслеживания движущихся объектов.</li>
            <li>Оптический поток: Методы, такие как метод Лукаса-Канаде и метод Фарнебека для оценки движения объектов между последовательными кадрами.</li>
          </ul>
        </li>
        <li>
          <b>Анализ движения:</b>
          <ul>
            <li>Детекция движущихся объектов: Вычитание фона, методы, такие как Gaussian Mixture Models (GMM) и Vibe для выделения движущихся объектов на статическом фоне.</li>
            <li>Определение направления и скорости движения: Анализ траекторий движения объектов для предсказания их поведения.</li>
          </ul>
        </li>
        <li>
          <b>Видеоаналитика на основе глубокого обучения:</b>
          <ul>
            <li>Детекция и классификация объектов в видео: Использование глубоких сверточных сетей для анализа каждого кадра видео.</li>
            <li>Рекуррентные нейронные сети (RNN): LSTM и GRU для анализа временных зависимостей и прогнозирования событий в видеопотоке.</li>
          </ul>
        </li>
        <li>
          <b>Видеоаннотация и маркировка данных:</b>
          <ul>
            <li>Разметка объектов и действий: Использование инструментов для аннотирования видео с целью создания обучающих наборов данных для моделей машинного обучения.</li>
            <li>Автоматическая аннотация: Применение моделей машинного обучения для автоматического добавления меток к объектам и действиям в видео.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Примеры применения методов работы с изображениями и видео</b>
        <li>
          <b>Безопасность и видеонаблюдение:</b>
          <ul>
            <li>Обнаружение подозрительных действий и идентификация лиц в режиме реального времени.</li>
          </ul>
        </li>
        <li>
          <b>Медицинская диагностика:</b>
          <ul>
            <li>Анализ медицинских изображений, таких как МРТ и рентгеновские снимки, для выявления патологий.</li>
          </ul>
        </li>
        <li>
          <b>Автономные транспортные средства:</b>
          <ul>
            <li>Обнаружение и отслеживание других транспортных средств, пешеходов и дорожных знаков.</li>
          </ul>
        </li>
        <li>
          <b>Развлечения и медиа:</b>
          <ul>
            <li>Применение эффектов и фильтров к видео, улучшение качества видео.</li>
          </ul>
        </li>
        <li>
          <b>Промышленное зрение:</b>
          <ul>
            <li>Контроль качества продукции, обнаружение дефектов на производственных линиях.</li>
          </ul>
        </li>
      </ol><br>
      <p>Методы работы с изображениями и видео являются ключевыми компонентами в области компьютерного зрения и машинного обучения. Эти методы находят широкое применение в различных отраслях, от безопасности и медицины до автономного транспорта и развлечений. Развитие технологий глубокого обучения продолжает улучшать качество и эффективность обработки изображений и видео, открывая новые возможности для инноваций и практических применений.</p>
    </div>
  </details>

  <!-- 29 -->
  <details class="details">
    <summary class="details__title">Структура файлов и папок в задаче Object Detection.</summary>
    <div class="details__content">
      <p>Структура файлов и папок в задаче Object Detection играет ключевую роль в организации данных и упрощении процесса разработки, тренировки и тестирования моделей. Грамотно организованная структура позволяет эффективно управлять данными, легко находить необходимые файлы и поддерживать чистоту и порядок в проекте. Это особенно важно при работе с большими наборами данных и сложными моделями глубокого обучения.</p>
      <br>
      <ol>
        <b>Общие принципы организации файлов и папок</b>
        <li>
          <b>Четкая иерархия:</b>
          <ul>
            <li>Разделение данных на логические категории, такие как исходные изображения, разметка, результаты предсказаний и модели.</li>
            <li>Упорядочивание папок и файлов по их назначению, что облегчает навигацию и поиск.</li>
          </ul>
        </li>
        <li>
          <b>Разделение данных на обучающие, валидационные и тестовые выборки:</b>
          <ul>
            <li>Это позволяет эффективно тренировать модели и оценивать их производительность на новых данных.</li>
          </ul>
        </li>
        <li>
          <b>Использование стандартных именований:</b>
          <ul>
            <li>Единый формат именования файлов и папок для предотвращения путаницы и обеспечения совместимости с существующими фреймворками и инструментами.</li>
          </ul>
        </li>
        <li>
          <b>Документирование:</b>
          <ul>
            <li>Наличие README-файлов и другой документации, описывающей структуру проекта, что облегчает его понимание и поддержку.</li>
          </ul>
        </li>
      </ol>
      <br>
      <p><b>Типичная структура проекта Object Detection</b></p>
      <p>Рассмотрим стандартную структуру файлов и папок в задаче Object Detection. Пример структуры может выглядеть следующим образом:</p>
      <br>
      <code>
        Object_Detection_Project/ <br>
        │ <br>
        ├── data/ <br>
        │   ├── train/ <br>
        │   │   ├── images/ <br>
        │   │   │   ├── image1.jpg <br>
        │   │   │   ├── image2.jpg <br>
        │   │   │   └── ... <br>
        │   │   ├── annotations/ <br>
        │   │   │   ├── image1.xml (или .json) <br>
        │   │   │   ├── image2.xml <br>
        │   │   │   └── ... <br>
        │   ├── val/ <br>
        │   │   ├── images/ <br>
        │   │   └── annotations/ <br>
        │   ├── test/ <br>
        │   │   ├── images/ <br>
        │   │   └── annotations/ <br>
        │   └── labels/ <br>
        │       └── label_map.pbtxt <br>
        │ <br>
        ├── models/ <br>
        │   ├── my_model/ <br>
        │   │   ├── pipeline.config <br>
        │   │   ├── checkpoint/ <br>
        │   │   └── saved_model/ <br>
        │   └── pre-trained/ <br>
        │       └── model_name/ <br>
        │ <br>
        ├── scripts/ <br>
        │   ├── preprocess_data.py <br>
        │   ├── train_model.py <br>
        │   ├── evaluate_model.py <br>
        │   └── inference.py <br>
        │ <br>
        ├── outputs/ <br>
        │   ├── predictions/ <br>
        │   │   ├── image1_prediction.jpg <br>
        │   │   ├── image2_prediction.jpg <br>
        │   │   └── ... <br>
        │   ├── logs/ <br>
        │   │   └── training.log <br>
        │   └── metrics/ <br>
        │       └── eval_metrics.json <br>
        │ <br>
        └── README.md <br>
      </code>
        <br>
        <ol>
          <b>Детальный разбор структуры</b>
          <li>
            <b>data/:</b>
            <ul>
              <li>
                <b>train/, val/, test/:</b> Эти папки содержат данные, разделенные на обучающую, валидационную и тестовую выборки. Такое разделение необходимо для корректной тренировки модели и объективной оценки её качества.
                <ul>
                  <li><b>images/:</b> Папка с исходными изображениями. Все изображения должны быть в одном формате (например, JPEG или PNG) и иметь логичные и уникальные имена.</li>
                  <li><b>annotations/:</b> Разметка для каждого изображения. Обычно это файлы в формате XML (PASCAL VOC) или JSON (COCO), содержащие информацию о координатах объектов на изображении и их классах.</li>
                </ul>
              </li>
              <li><b>labels/:</b> Файл label_map.pbtxt, который содержит карту меток (label map) — соответствие между числовыми идентификаторами и текстовыми метками классов. Этот файл необходим для корректной интерпретации предсказаний модели.</li>
            </ul>
          </li>
          <li>
            <b>models/:</b>
            <ul>
              <li>
                <b>my_model/:</b> Папка для хранения информации о конкретной модели
                <ul>
                  <li><b>pipeline.config:</b> Конфигурационный файл, в котором указаны все параметры тренировки модели, такие как пути к данным, архитектура модели, гиперпараметры и др.</li>
                  <li><b>checkpoint/:</b> Папка с контрольными точками (checkpoints) тренировки модели. Они позволяют восстановить модель на любом этапе обучения.</li>
                  <li><b>saved_model/:</b> Финальная версия обученной модели, готовая к использованию для инференса.</li>
                </ul>
              </li>
              <li><b>pre-trained/:</b> Папка для хранения предварительно обученных моделей, которые можно использовать для дообучения (transfer learning).</li>
            </ul>
          </li>
          <li>
            <b>scripts/:</b>
            <ul>
              <li><b>preprocess_data.py:</b> Скрипт для предобработки данных. Включает в себя задачи по загрузке данных, нормализации изображений, аугментации и подготовке разметки.</li>
              <li><b>train_model.py:</b> Скрипт для тренировки модели. Использует конфигурационный файл pipeline.config и запускает процесс обучения на тренировочных данных.</li>
              <li><b>evaluate_model.py:</b> Скрипт для оценки производительности модели на валидационном или тестовом наборе данных.</li>
              <li><b>inference.py:</b> Скрипт для выполнения предсказаний на новых изображениях с использованием обученной модели.</li>
            </ul>
          </li>
          <li>
            <b>outputs/:</b>
            <ul>
              <li><b>predictions/:</b> Папка для хранения результатов предсказаний модели. Обычно это изображения с нанесенными на них рамками (bounding boxes) и метками классов, которые определила модель.</li>
              <li><b>logs/:</b> Журнал (лог) тренировки модели. Включает информацию о ходе тренировки, таких как потери (loss), точность (accuracy), время выполнения и другие метрики.</li>
              <li><b>metrics/:</b> Папка для хранения метрик, полученных при оценке модели. Это могут быть файлы с метриками, такими как точность (precision), полнота (recall), F1-score и другие.</li>
            </ul>
          </li>
          <li>
            <b>README.md:</b>
            <ul>
              <li>Этот файл содержит описание проекта, инструкции по его запуску, описание структуры файлов и папок, а также любую другую важную информацию, которая может понадобиться разработчикам или пользователям.</li>
            </ul>
          </li>
        </ol>
      <br>
      <p>Правильная структура файлов и папок в задаче Object Detection не только упрощает работу над проектом, но и способствует его дальнейшему развитию и поддержке. Важно уделить внимание организации данных и соблюдению стандартов именования, чтобы обеспечить удобство работы с проектом как для текущих разработчиков, так и для будущих пользователей и исследователей.</p>
      <br>
      <ol>
        <b>Подготовка и трансформация данных</b><br>Иногда для достижения лучших результатов необходимо провести предварительную обработку изображений или разметки перед их использованием в обучении. Это может включать:
        <li>
          <b>Ресайзинг изображений:</b>
          <ul>
            <li>Изображения могут быть приведены к одинаковому размеру, что облегчает работу модели и снижает требования к вычислительным ресурсам.</li>
          </ul>
        </li>
        <li>
          <b>Аугментация данных:</b>
          <ul>
            <li>Применение различных методов аугментации, таких как вращение, сдвиг, изменение яркости, контрастности и др., для увеличения объема данных и улучшения обобщающей способности модели.</li>
          </ul>
        </li>
        <li>
          <b>Нормализация и стандартизация:</b>
          <ul>
            <li>Приведение значений пикселей к определенному диапазону (например, от 0 до 1 или от -1 до 1) для улучшения сходимости модели во время обучения.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Логирование и мониторинг</b><br>Эффективная разработка и обучение моделей Object Detection требует логирования и мониторинга процессов. Это включает:
        <li>
          <b>Логи тренировок:</b>
          <ul>
            <li>Автоматическое сохранение логов, содержащих информацию о процессе тренировки, таких как значение функции потерь, метрики точности и т.д. Эти логи помогают в дальнейшем анализе поведения модели и позволяют вовремя выявить проблемы.</li>
          </ul>
        </li>
        <li>
          <b>Мониторинг в реальном времени:</b>
          <ul>
            <li>Использование инструментов вроде TensorBoard для визуализации процесса тренировки модели. Это позволяет следить за изменением метрик в реальном времени и корректировать гиперпараметры на основе получаемой информации.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Управление несколькими экспериментами</b><br>В процессе разработки моделей Object Detection часто приходится запускать несколько экспериментов с различными гиперпараметрами, архитектурами и набором данных. Для удобства управления экспериментами можно использовать:
        <li>
          <b>Отдельные папки для каждого эксперимента:</b>
          <ul>
            <li>Создание отдельной папки для каждого эксперимента, где будут храниться конфигурационные файлы, чекпоинты моделей и результаты. Это помогает избежать путаницы и легко сравнивать результаты разных экспериментов.</li>
          </ul>
        </li>
        <li>
          <b>Инструменты для управления экспериментами:</b>
          <ul>
            <li>Использование специализированных инструментов, таких как MLflow или Weights & Biases, которые позволяют централизованно управлять экспериментами, сохранять и сравнивать их результаты, а также делиться ими с другими участниками команды.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Организация метаданных и документации</b>
        <li>
          <b>Метаданные проекта:</b>
          <ul>
            <li>Для эффективного управления данными и экспериментов, важно организовать хранение метаданных, таких как информация о датчиках, условиях съемки, времени сбора данных и другой связанной информации. Это может включать описание сенсоров, камер, географических координат и прочих условий, при которых были сделаны снимки.</li>
          </ul>
        </li>
        <li>
          <b>Структурированная документация:</b>
          <ul>
            <li>Документация по проекту должна включать подробные инструкции по настройке окружения, установке необходимых библиотек, структуре данных, процессу подготовки данных и тренировке моделей. Документация должна быть структурирована таким образом, чтобы любой новый член команды мог быстро понять, как работать с проектом.</li>
          </ul>
        </li>
        <li>
          <b>Автоматическая генерация отчетов:</b>
          <ul>
            <li>Инструменты, такие как Jupyter Notebooks, могут быть использованы для генерации отчетов, которые включают визуализацию данных, анализ результатов и шаги по их воспроизведению. Это помогает в отслеживании прогресса и обсуждении результатов в команде.</li>
          </ul>
        </li>
      </ol>
    </div>
  </details>

  <!-- 30 -->
  <details class="details">
    <summary class="details__title">Распознавание текста на изображениях.</summary>
    <div class="details__content">
      <p>Распознавание текста на изображениях (OCR, Optical Character Recognition) — это процесс извлечения текстовой информации из изображений, таких как фотографии, сканы документов, таблички и другие визуальные источники. Эта технология находит широкое применение в различных сферах, включая автоматизацию документооборота, обработку изображений, машинное зрение и искусственный интеллект.</p>
      <br>
      <ol>
        <b>Принципы работы OCR</b><br>Процесс распознавания текста на изображениях можно разделить на несколько ключевых этапов:
        <li>
          <b>Предварительная обработка изображения:</b>
          <ul>
            <li>
              Этот этап включает улучшение качества изображения для улучшения точности распознавания текста. Основные техники включают:
              <ul>
                <li><b>Бинаризация:</b> Преобразование изображения в черно-белый формат, что позволяет упростить дальнейшую обработку.</li>
                <li><b>Шумоподавление:</b> Удаление цифрового шума и артефактов, которые могут возникнуть при сканировании или фотосъемке.</li>
                <li><b>Выравнивание (deskewing):</b> Коррекция наклона текста, который может появиться при неправильном положении документа при сканировании.</li>
                <li><b>Нормализация яркости и контраста:</b> Приведение изображения к стандартным условиям освещенности и контрастности.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>Сегментация:</b>
          <ul>
            <li>На этом этапе изображение разбивается на отдельные блоки, такие как абзацы, строки, слова и символы. Сегментация позволяет выделить текстовые элементы, которые затем будут распознаваться. В некоторых случаях сегментация также включает выделение областей с изображениями, таблицами и графиками, чтобы их исключить из процесса распознавания текста.</li>
          </ul>
        </li>
        <li>
          <b>Распознавание символов:</b>
          <ul>
            <li>
              Основной этап, на котором происходит идентификация отдельных символов. В современных системах OCR используются две основные технологии:
              <ul>
                <li><b>Шаблонное распознавание (template matching): </b>Этот метод предполагает сравнение фрагментов изображения с предварительно известными шаблонами символов. Этот подход хорош для распознавания текста в фиксированных шрифтах, но плохо справляется с произвольными стилями и рукописным текстом.</li>
                <li><b>Распознавание на основе нейронных сетей:</b> В современных системах используются глубокие сверточные нейронные сети (CNN) и рекуррентные нейронные сети (RNN), которые обучены распознавать текстовые паттерны на различных шрифтах и стилях.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <b>Постобработка:</b>
          <ul>
            <li>
              После распознавания символов необходимо провести постобработку, чтобы улучшить результаты и исправить возможные ошибки:
              <ul>
                <li><b>Исправление ошибок распознавания:</b> Применение языковых моделей для исправления орфографических и грамматических ошибок. Например, в случае, если распознанное слово не соответствует словарю, система может предложить наиболее вероятное исправление.</li>
                <li><b>Объединение и форматирование текста:</b> Восстановление оригинальной структуры текста, включая абзацы, заголовки, списки и другие элементы форматирования.</li>
              </ul>
            </li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Технологии и инструменты</b>
        <li><b>Tesseract:</b>
          <ul>
            <li>Один из наиболее известных и популярных open-source движков для OCR, разработанный Google. Tesseract поддерживает множество языков и хорошо интегрируется с различными фреймворками и библиотеками. Однако его точность может варьироваться в зависимости от качества изображения и сложности текста.</li>
          </ul>
        </li>
        <li><b>EasyOCR:</b>
          <ul>
            <li>Более современный инструмент на основе глубокого обучения, который показывает высокую точность на различных типах изображений, включая тексты с различными шрифтами и стилями. EasyOCR поддерживает множество языков и легко интегрируется в Python-проекты.</li>
          </ul>
        </li>
        <li><b>Google Cloud Vision OCR:</b>
          <ul>
            <li>Облачный сервис, предоставляемый Google, который позволяет распознавать текст с изображений с помощью API. Этот инструмент особенно полезен для работы с большими объемами данных и сложными сценариями распознавания, так как он использует мощные модели машинного обучения, обученные на огромных наборах данных.</li>
          </ul>
        </li>
        <li><b>Microsoft Azure Computer Vision:</b>
          <ul>
            <li>Платформа, предоставляющая аналогичные услуги по распознаванию текста на изображениях через API. Она также поддерживает множество языков и предоставляет дополнительные возможности, такие как распознавание рукописного текста и работа с документами в формате PDF.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Применение OCR</b>
        <li>
          <b>Автоматизация документооборота:</b>
          <ul>
            <li>OCR широко используется для автоматического ввода данных из бумажных документов, таких как счета, контракты, формы и т.д. Это позволяет значительно сократить время и ошибки, связанные с ручным вводом данных.</li>
          </ul>
        </li>
        <li>
          <b>Цифровизация архивов:</b>
          <ul>
            <li>OCR применяется для оцифровки больших архивов документов и книг, превращая их в удобные для поиска и хранения цифровые форматы. Это помогает сохранить культурное наследие и сделать его доступным для широкого круга людей.</li>
          </ul>
        </li>
        <li>
          <b>Обработка изображений и видео:</b>
          <ul>
            <li>В системах видеоаналитики OCR используется для распознавания текста на дорожных знаках, номерах автомобилей, баннерах и других объектах. Это полезно для автоматизированного управления трафиком, мониторинга общественных мест и безопасности.</li>
          </ul>
        </li>
        <li>
          <b>Поддержка пользователей с ограниченными возможностями:</b>
          <ul>
            <li>Технологии OCR используются для создания решений, которые помогают людям с нарушениями зрения или слуха. Например, OCR может распознавать текст на изображениях и преобразовывать его в аудио, делая контент доступным для слепых и слабовидящих людей.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Вызовы и ограничения OCR</b>
        <li>
          <b>Качество изображения:</b>
          <ul>
            <li>OCR сильно зависит от качества исходного изображения. Низкое разрешение, плохое освещение, шумы и артефакты могут значительно ухудшить точность распознавания текста.</li>
          </ul>
        </li>
        <li>
          <b>Шрифты и стили:</b>
          <ul>
            <li>Разнообразие шрифтов, стилей и языков может представлять серьезные вызовы для системы распознавания. В некоторых случаях, особенно при работе с рукописным текстом или сложными шрифтами, OCR может дать сбои.</li>
          </ul>
        </li>
        <li>
          <b>Многоязычные тексты:</b>
          <ul>
            <li>Работа с многоязычными документами требует особой обработки, так как переключение между языками в пределах одного документа может привести к ошибкам. Важно иметь модели, способные эффективно переключаться между различными языками и алфавитами.</li>
          </ul>
        </li>
      </ol><br>
      <p><b>Будущее OCR</b></p>
      <p>Современные исследования в области OCR направлены на улучшение точности распознавания текста в сложных условиях и на разнообразных носителях. Это включает использование усовершенствованных моделей машинного обучения, гибридных систем, объединяющих методы традиционного и глубокого обучения, а также интеграцию OCR с другими технологиями, такими как компьютерное зрение и обработка естественного языка. В будущем OCR продолжит расширять свои возможности, предлагая новые методы и подходы для работы с текстами на изображениях, улучшая взаимодействие человека и машины, а также поддерживая автоматизацию и цифровизацию в различных отрасля</p>
    </div>
  </details>

  <!-- 31 -->
  <details class="details">
    <summary class="details__title">AutoML(фреймворки, задачи).</summary>
    <div class="details__content">
      <p>AutoML (Automated Machine Learning) — это набор методов и инструментов, разработанных для автоматизации процесса создания моделей машинного обучения. Основная цель AutoML — сделать разработку моделей доступной для специалистов, не обладающих глубокими знаниями в области машинного обучения, а также повысить эффективность работы опытных инженеров и исследователей.</p>
      <br>
      <ol>
        <b>Задачи AutoML</b>
        <li>
          <b>Предобработка данных:</b>
          <ul>
            <li>Одним из первых этапов работы над задачей машинного обучения является подготовка данных. AutoML автоматически выполняет важные задачи, такие как очистка данных, обработка пропущенных значений, кодирование категориальных переменных и нормализация данных. Автоматизация этого процесса позволяет сократить время подготовки данных и избежать ошибок, которые могут возникнуть при ручной обработке.</li>
          </ul>
        </li>
        <li>
          <b>Выбор признаков (Feature Engineering):</b>
          <ul>
            <li>Feature engineering — это процесс создания новых признаков из существующих данных, которые могут улучшить производительность модели. AutoML может автоматизировать создание и отбор признаков, что позволяет моделям лучше выявлять зависимости и структуры в данных. Некоторые фреймворки AutoML также предлагают методы автоматического выбора оптимального подмножества признаков, что уменьшает риск переобучения и ускоряет обучение моделей.</li>
          </ul>
        </li>
        <li>
          <b>Выбор модели:</b>
          <ul>
            <li>Одной из основных задач AutoML является автоматический подбор наиболее подходящей модели для конкретной задачи. Фреймворки AutoML обычно рассматривают множество различных моделей, включая линейные модели, деревья решений, случайные леса, градиентный бустинг, нейронные сети и другие. Процесс выбора модели включает в себя не только поиск лучшей архитектуры, но и оценку различных гиперпараметров для каждой модели.</li>
          </ul>
        </li>
        <li>
          <b>Оптимизация гиперпараметров:</b>
          <ul>
            <li>Гиперпараметры — это параметры, которые необходимо настроить перед началом обучения модели. Оптимизация гиперпараметров может быть сложным и трудоемким процессом, так как существует множество возможных комбинаций, которые нужно проверить. AutoML автоматизирует процесс поиска оптимальных гиперпараметров, используя такие методы, как сеточный поиск (grid search), случайный поиск (random search), Bayesian optimization и генетические алгоритмы.</li>
          </ul>
        </li>
        <li>
          <b>Оценка и валидация моделей:</b>
          <ul>
            <li>AutoML автоматизирует процесс оценки производительности моделей с использованием таких техник, как кросс-валидация и разбиение данных на обучающую и тестовую выборки. Это помогает избежать проблем с переобучением и обеспечивает объективную оценку качества моделей. AutoML также может автоматически определить наиболее подходящую метрику для задачи (например, точность, F1-score, ROC-AUC для классификации или среднеквадратичную ошибку для регрессии).</li>
          </ul>
        </li>
        <li>
          <b>Объединение моделей (Ensemble Learning):</b>
          <ul>
            <li>Для улучшения качества предсказаний AutoML часто использует методы ансамблевого обучения, такие как бэггинг, бустинг или стекинг. Эти методы позволяют объединять несколько моделей для достижения более точных и устойчивых результатов.</li>
          </ul>
        </li>
        <li>
          <b>Развертывание и мониторинг моделей:</b>
          <ul>
            <li>После создания и обучения модели, AutoML может автоматизировать процесс развертывания модели в продакшн, а также мониторинг её работы на реальных данных. Это включает в себя автоматическую адаптацию моделей к изменениям данных и поддержание их актуальности.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Фреймворки AutoML</b>
        <li>
          <b>AutoKeras</b>
          <ul>
            <li>Основанный на Keras и TensorFlow, AutoKeras предлагает удобный интерфейс для автоматической настройки нейронных сетей. Он может автоматически подбирать архитектуру нейронной сети, а также оптимизировать гиперпараметры. AutoKeras поддерживает задачи классификации, регрессии, обработки изображений и текста</li>
          </ul>
        </li>
        <li>
          <b>TPOT</b>
          <ul>
            <li>TPOT (Tree-based Pipeline Optimization Tool) использует генетические алгоритмы для автоматизации выбора моделей и их гиперпараметров. Этот фреймворк позволяет создавать сложные конвейеры машинного обучения, включая предобработку данных, выбор признаков, оптимизацию гиперпараметров и ансамблирование моделей.</li>
          </ul>
        </li>
        <li>
          <b>H2O.ai:</b>
          <ul>
            <li>H2O.ai — это платформа для построения и развертывания моделей машинного обучения, поддерживающая AutoML. Она предлагает широкий набор моделей, включая градиентный бустинг, случайные леса, глубокие нейронные сети и другие. H2O.ai может автоматически подбирать лучшие модели и оптимизировать их гиперпараметры.</li>
          </ul>
        </li>
        <li>
          <b>Google AutoML:</b>
          <ul>
            <li>Платформа Google AutoML предлагает набор облачных инструментов для автоматизации создания моделей машинного обучения, включая задачи обработки изображений, текста и таблиц. Эти инструменты позволяют пользователям без глубоких знаний в машинном обучении создавать высокоэффективные модели.</li>
          </ul>
        </li>
        <li>
          <b>Auto-sklearn:</b>
          <ul>
            <li>Построенный на базе scikit-learn, Auto-sklearn автоматизирует выбор моделей и оптимизацию гиперпараметров. Он также включает методы мета-обучения, которые позволяют использовать предыдущий опыт для ускорения процесса выбора модели.</li>
          </ul>
        </li>
        <li>
          <b>DataRobot:</b>
          <ul>
            <li>DataRobot — это коммерческая платформа AutoML, которая предлагает комплексное решение для создания, оптимизации и развертывания моделей машинного обучения. DataRobot поддерживает широкий спектр алгоритмов, а также предоставляет мощные инструменты для интерпретации моделей и анализа результатов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ul>
        <b>Преимущества и недостатки AutoML</b>
        <li><b>Преимущества:</b>
          <ul>
            <li><b>Снижение порога входа:</b> AutoML позволяет специалистам с минимальным опытом в машинном обучении создавать высокоэффективные модели.</li>
            <li><b>Экономия времени:</b> Автоматизация задач, таких как предобработка данных и оптимизация гиперпараметров, значительно ускоряет процесс разработки моделей.</li>
            <li><b>Улучшение качества моделей:</b> AutoML использует передовые методы оптимизации и ансамблирования, что позволяет достичь высоких показателей качества.</li>
          </ul>
        </li>
        <li><b>Недостатки:</b>
          <ul>
            <li><b>Отсутствие гибкости:</b> AutoML может не предоставить достаточную гибкость для решения сложных или специфических задач, требующих ручного вмешательства и тонкой настройки.</li>
            <li><b>Требования к ресурсам:</b> Автоматизация оптимизации гиперпараметров и ансамблирования может потребовать значительных вычислительных ресурсов.</li>
            <li><b>Непрозрачность моделей:</b> Автоматически созданные модели могут быть сложны для интерпретации и объяснения, что может затруднить их использование в критически важных приложениях.</li>
          </ul>
        </li>
      </ul><br>
      <p>AutoML представляет собой мощный инструмент, который делает машинное обучение доступным для широкой аудитории и значительно ускоряет процесс разработки моделей. Однако, несмотря на все его преимущества, AutoML не заменяет глубоких знаний и понимания процессов машинного обучения, особенно в случаях, когда требуется высокая гибкость или специфические решения для сложных задач.</p>
    </div>
  </details>

  <!-- 32 -->
  <details class="details">
    <summary class="details__title">Готовые решения для сегментации изображений. Дообучение.</summary>
    <div class="details__content">
      <p>Сегментация изображений — это важная задача в области компьютерного зрения, где цель заключается в разделении изображения на несколько значимых сегментов, таких как объекты или области. Сегментация широко применяется в медицине, автономных системах, робототехнике и многих других областях. В последние годы, благодаря достижениям в области глубокого обучения, появились эффективные архитектуры нейронных сетей, которые могут решать задачи сегментации с высокой точностью.</p>
      <br>
      <ol>
        <b>Готовые решения для сегментации изображений</b><br>Существуют несколько популярных архитектур, специально разработанных для задач сегментации:
        <li>
          <b>U-Net:</b>
          <ul>
            <li><b>Описание:</b> U-Net является одной из самых популярных архитектур для сегментации изображений, особенно в медицинских приложениях. Эта архитектура состоит из симметричной структуры с блоками кодирования и декодирования. В процессе кодирования (downsampling) сеть уменьшает размер изображения, извлекая высокоуровневые признаки, а в процессе декодирования (upsampling) восстанавливает пространственную информацию, используя комбинированные данные с соответствующего уровня кодирования.</li>
            <li><b>Применение:</b> U-Net используется в медицинской сегментации (например, сегментация органа на МРТ или КТ), а также в других областях, где требуется высокоточная сегментация небольших объектов.</li>
          </ul>
        </li>
        <li>
          <b>Mask R-CNN:</b>
          <ul>
            <li><b>Описание:</b> Mask R-CNN расширяет архитектуру Faster R-CNN, добавляя ветвь для сегментации объектов на уровне пикселей. Это делает Mask R-CNN идеальной для задач, где необходимо не только обнаруживать объекты, но и выделять их контуры.</li>
            <li><b>Применение:</b> Масштабная сегментация объектов на изображениях, часто используемая в приложениях, связанных с анализом видео, например, в системах видеонаблюдения и в автономных транспортных средствах.</li>
          </ul>
        </li>
        <li>
          <b>DeepLab (v2, v3, v3+):</b>
          <ul>
            <li><b>Описание:</b> DeepLab — это архитектура, которая использует сверточные нейронные сети с модулем ASPP (Atrous Spatial Pyramid Pooling) для эффективного захвата объектов разного масштаба. В версии DeepLabv3+ добавлен декодер, что улучшает качество сегментации.</li>
            <li><b>Применение:</b> Широко используется для сегментации городской среды, анализа спутниковых изображений, а также в других приложениях, требующих высокоточной сегментации сложных сцен.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol>
        <b>Дообучение моделей для сегментации</b><br>Дообучение (Transfer Learning) — это процесс адаптации предварительно обученной модели к новой задаче или набору данных. Этот процесс особенно полезен в случаях, когда доступно ограниченное количество данных для обучения, что часто встречается в задачах сегментации изображений.
        <li>
          <b>Основные шаги дообучения:</b>
          <ul>
            <li>Инициализация модели: В качестве начальной точки выбирается модель, предварительно обученная на большой и обширной базе данных, такой как ImageNet. Это позволяет модели иметь хорошо обобщенные начальные веса.</li>
            <li>Заморозка слоев: На начальном этапе дообучения часто замораживаются (фиксируются) веса ранних слоев модели, поскольку они уже обучены на извлечение общих признаков (например, краев, текстур). Обучению подвергаются только последние слои, которые более специфичны к задаче сегментации.</li>
            <li>Адаптация архитектуры: Иногда для улучшения сегментации необходимо изменить архитектуру модели, например, добавить дополнительные слои или изменить размерность выходного слоя, чтобы соответствовать числу классов в задаче.</li>
            <li>Тонкая настройка (fine-tuning): На завершающем этапе можно разморозить ранние слои и продолжить обучение модели с очень низкой скоростью обучения (learning rate). Это позволяет модели адаптироваться к новым данным, сохраняя при этом обобщающие способности.</li>
          </ul>
        </li>
        <li>
          <b>Преимущества дообучения:</b>
          <ul>
            <li>Снижение требований к данным: Дообучение позволяет эффективно использовать модели даже на небольших наборах данных, что значительно снижает требования к объемам данных для обучения с нуля.</li>
            <li>Улучшение качества сегментации: Благодаря использованию предварительно обученных весов, модель быстрее и точнее адаптируется к новой задаче, что приводит к улучшению качества сегментации.</li>
            <li>Снижение вычислительных затрат: Поскольку большая часть весов модели уже оптимизирована, процесс дообучения требует меньше времени и вычислительных ресурсов, чем обучение модели с нуля.</li>
          </ul>
        </li>
      </ol><br>
      <p>Использование готовых архитектур для сегментации изображений и их дообучение на специфических наборах данных предоставляет мощные инструменты для решения задач различной сложности. Это позволяет создавать эффективные и точные решения, минимизируя время и ресурсы, затрачиваемые на разработку. В современных приложениях, таких как автономные системы, медицина, и компьютерное зрение, такие подходы позволяют достичь высоких результатов и ускорить процесс внедрения инновационных технологий.</p>
    </div>
  </details>
  <script src="scripts/main.js"></script>
</body>

</html>